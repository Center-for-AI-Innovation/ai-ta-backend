{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example usage of the UIUC.chat public API\n",
    "\n",
    "\n",
    "### Available models\n",
    "\n",
    "model_id must be one of: \n",
    "```text\n",
    "    'gpt-3.5-turbo'\n",
    "    'gpt-3.5-turbo-16k'\n",
    "    'gpt-4'\n",
    "    'gpt-4-1106-preview'\n",
    "    'gpt-4-vision-preview'\n",
    "    'gpt-4-from-canada-east' # Only for use with CAII Azure key\n",
    "```\n",
    "\n",
    "The last model is an Azure model, and we only suport gpt-4 (regular 8k), and only using our one particular azure key (to avoid a larger rewrite to support all the azure variables)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the our library to the Python path\n",
    "current_dir = os.path.dirname(os.path.abspath(''))\n",
    "one_dir_up = os.path.dirname(current_dir) # Go up a directory\n",
    "sys.path.append(one_dir_up)\n",
    "\n",
    "from ai_ta_backend.public_api.uiuc_chat_api import call_chat_endpoint\n",
    "from ai_ta_backend.vector_database import Ingest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kastanday/miniforge3/envs/flask10_py10/lib/python3.10/site-packages/qdrant_client/qdrant_remote.py:116: UserWarning: Api key is used with unsecure connection.\n",
      "  warnings.warn(\"Api key is used with unsecure connection.\")\n",
      "2023-12-13 18:16:06,893:INFO - HTTP Request: POST http://ec2-18-204-198-136.compute-1.amazonaws.com:6333/collections/uiuc-chatbot-quantized/points/search \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens used/limit: 151/6000, tokens in chunk: 25, total prompt cost (of these contexts): 3.7500000000000003e-05. 📄 File: Notion\n",
      "tokens used/limit: 176/6000, tokens in chunk: 718, total prompt cost (of these contexts): 0.001077. 📄 File: WORKS 2023\n",
      "tokens used/limit: 894/6000, tokens in chunk: 17, total prompt cost (of these contexts): 2.55e-05. 📄 File: WordPress\n",
      "tokens used/limit: 911/6000, tokens in chunk: 242, total prompt cost (of these contexts): 0.000363. 📄 File: Fake News Detection Details\n",
      "tokens used/limit: 1153/6000, tokens in chunk: 919, total prompt cost (of these contexts): 0.0013785. 📄 File: Fake News Detection Details\n",
      "tokens used/limit: 2072/6000, tokens in chunk: 848, total prompt cost (of these contexts): 0.0012720000000000001. 📄 File: Books\n",
      "tokens used/limit: 2920/6000, tokens in chunk: 815, total prompt cost (of these contexts): 0.0012225. 📄 File: Publications\n",
      "tokens used/limit: 3735/6000, tokens in chunk: 432, total prompt cost (of these contexts): 0.000648. 📄 File: GitHub\n",
      "tokens used/limit: 4167/6000, tokens in chunk: 86, total prompt cost (of these contexts): 0.000129. 📄 File: Mnemonic medium\n",
      "tokens used/limit: 4253/6000, tokens in chunk: 67, total prompt cost (of these contexts): 0.0001005. 📄 File: Productionizing and scaling Python ML workloads simply\n",
      "tokens used/limit: 4320/6000, tokens in chunk: 345, total prompt cost (of these contexts): 0.0005175000000000001. 📄 File: Abuse\n",
      "tokens used/limit: 4665/6000, tokens in chunk: 711, total prompt cost (of these contexts): 0.0010665. 📄 File: Fake News Detection Details\n",
      "tokens used/limit: 5376/6000, tokens in chunk: 85, total prompt cost (of these contexts): 0.0001275. 📄 File: Fake News Detection Details\n",
      "tokens used/limit: 5461/6000, tokens in chunk: 18, total prompt cost (of these contexts): 2.7e-05. 📄 File: Lightning AI\n",
      "tokens used/limit: 5479/6000, tokens in chunk: 814, total prompt cost (of these contexts): 0.001221. 📄 File: Books\n",
      "Total tokens used: 5479. Docs used: 14 of 80 docs retrieved\n",
      "Course: test-video-ingest-21 ||| search_query: What's in these documents? Use one sentence.\n",
      "⏰ ^^ Runtime of getTopContexts: 1.18 seconds\n",
      "🧠 Final response:\n",
      "The documents contain information on a variety of topics including a workspace tool, guidelines for a workshop submission, a content management system, details on fake news detection, book reviews, a list of publications, a code repository, a mnemonic medium, Python machine learning workloads, reporting abuse on a content platform, and an AI application development platform."
     ]
    }
   ],
   "source": [
    "### Only necessary to changes: \n",
    "user_prompt = \"What's in these documents? Use one sentence.\"\n",
    "course_name = \"test-video-ingest-21\"\n",
    "openai_api_key = '' # Your OpenAI API key\n",
    "###\n",
    "\n",
    "system_prompt = \"You are a helpful assistant.\"\n",
    "token_limit = 6000 # max tokens returned by getTopContexts\n",
    "stream = True\n",
    "\n",
    "ingester = Ingest()\n",
    "found_documents = ingester.getTopContexts(user_prompt, course_name, token_limit)\n",
    "\n",
    "model_response = call_chat_endpoint(\n",
    "  model_id=\"gpt-4-1106-preview\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"system\", \n",
    "      \"content\": [{\"type\": \"text\", \"text\": system_prompt}],\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\", \n",
    "      \"content\": [{\"type\": \"text\", \"text\": user_prompt}],\n",
    "      \"contexts\": found_documents\n",
    "    }\n",
    "  ],\n",
    "  openai_api_key=openai_api_key,\n",
    "  course_name=course_name,\n",
    "  stream=stream\n",
    ")\n",
    "\n",
    "print(\"🧠 Final response:\")\n",
    "if stream:\n",
    "  for message in model_response:\n",
    "    print(message, end='')\n",
    "else: \n",
    "  print(model_response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
