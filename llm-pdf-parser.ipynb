{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)\n",
    "\n",
    "from ai_ta_backend.utils.types import DocumentMetadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random test paper copy/pasted from from ArXiv: https://arxiv.org/html/2404.09995v1\n",
    "raw_text = \"\"\"License: CC BY-NC-ND 4.0\n",
    "arXiv:2404.09995v1 [cs.CV] 15 Apr 2024\n",
    "(eccv) Package eccv Warning: Package 'hyperref' is loaded with option 'pagebackref', which is *not* recommended for camera-ready version\n",
    "\n",
    "1\n",
    "Taming Latent Diffusion Model for Neural Radiance Field Inpainting\n",
    "Chieh Hubert Lin\n",
    "1122\n",
    "Changil Kim\n",
    "11\n",
    "Jia-Bin Huang\n",
    "1133\n",
    "Qinbo Li\n",
    "11\n",
    "Chih Yao Ma\n",
    "11\n",
    "Johannes Kopf\n",
    "11\n",
    "Ming-Hsuan Yang\n",
    "22\n",
    "Hung-Yu Tseng\n",
    "11\n",
    "Abstract\n",
    "Neural Radiance Field (NeRF) is a representation for 3D reconstruction from multi-view images. Despite some recent work showing preliminary success in editing a reconstructed NeRF with diffusion prior, they remain struggling to synthesize reasonable geometry in completely uncovered regions. One major reason is the high diversity of synthetic contents from the diffusion model, which hinders the radiance field from converging to a crisp and deterministic geometry. Moreover, applying latent diffusion models on real data often yields a textural shift incoherent to the image condition due to auto-encoding errors. These two problems are further reinforced with the use of pixel-distance losses. To address these issues, we propose tempering the diffusion model's stochasticity with per-scene customization and mitigating the textural shift with masked adversarial training. During the analyses, we also found the commonly used pixel and perceptual losses are harmful in the NeRF inpainting task. Through rigorous experiments, our framework yields state-of-the-art NeRF inpainting results on various real-world scenes.\n",
    "\n",
    "Refer to caption\n",
    "Figure 1:NeRF inpainting. Given a set of posed images associated with inpainting masks, the proposed framework estimates a NeRF that renders high-quality novel views, where the inpainting region is realistic and contains high-frequency details.\n",
    "1Introduction\n",
    "The recent advancements in neural radiance fields (NeRF) [24, 27, 3] have achieved high-quality 3D reconstruction and novel-view synthesis of scenes captured with a collection of images. The success intrigues an increasing attention on manipulating NeRFs such as 3D scene stylization [38, 8] and NeRF editing [13]. In this work, we focus on the NeRF inpainting problem. As shown in Figure 1, given a set of images of a scene with the inpainting masks, our goal is to estimate a completed NeRF that renders high-quality images at novel viewpoints. The NeRF inpainting task enables a variety of 3D content creation applications such as removing objects from a scene [26, 39], completing non-observed part of the scene, and hallucinating contents in the designated regions.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DocumentMetadata(authors=['Chieh Hubert Lin', 'Changil Kim', 'Jia-Bin Huang', 'Qinbo Li', 'Chih Yao Ma', 'Johannes Kopf', 'Ming-Hsuan Yang', 'Hung-Yu Tseng'], journal_name='arXiv', publication_date=datetime.date(2024, 4, 15), keywords=['Neural Radiance Field', 'NeRF', 'inpainting', 'latent diffusion model', '3D reconstruction', 'multi-view images', 'synthetic contents', 'geometry', 'stochasticity', 'textural shift', 'auto-encoding errors', 'pixel-distance losses', 'per-scene customization', 'masked adversarial training', 'pixel and perceptual losses', 'real-world scenes'], doi='2404.09995v1', title='Taming Latent Diffusion Model for Neural Radiance Field Inpainting', subtitle=None, visible_urls=[], field_of_science='Computer Vision', concise_summary='This paper addresses the challenges in Neural Radiance Field (NeRF) inpainting by proposing a framework that tempers the stochasticity of diffusion models and mitigates textural shifts with masked adversarial training. It also identifies commonly used pixel and perceptual losses as detrimental in NeRF inpainting tasks and demonstrates state-of-the-art results through rigorous experiments.', questions_document_can_answer=['What are the challenges in Neural Radiance Field inpainting?', 'How does the proposed framework improve NeRF inpainting?', 'Why are pixel and perceptual losses harmful in NeRF inpainting tasks?', 'What methods are used to mitigate textural shifts in NeRF inpainting?'])]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import marvin\n",
    "marvin.extract(raw_text, target=DocumentMetadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DocumentMetadata(authors=['Chieh Hubert Lin', 'Changil Kim', 'Jia-Bin Huang', 'Qinbo Li', 'Chih Yao Ma', 'Johannes Kopf', 'Ming-Hsuan Yang', 'Hung-Yu Tseng'], journal_name='arXiv', publication_date=datetime.date(2024, 4, 15), keywords=['Neural Radiance Field', 'NeRF', 'inpainting', 'latent diffusion model', '3D reconstruction', 'multi-view images', 'synthetic contents', 'geometry', 'stochasticity', 'textural shift', 'auto-encoding errors', 'pixel-distance losses', 'per-scene customization', 'masked adversarial training', 'pixel and perceptual losses', 'real-world scenes'], doi='2404.09995v1', title='Taming Latent Diffusion Model for Neural Radiance Field Inpainting', subtitle=None, visible_urls=[], field_of_science='Computer Vision', concise_summary='This paper addresses the challenges in Neural Radiance Field (NeRF) inpainting by proposing a framework that tempers the stochasticity of diffusion models and mitigates textural shifts with masked adversarial training. It also identifies commonly used pixel and perceptual losses as detrimental in NeRF inpainting tasks and demonstrates state-of-the-art results through rigorous experiments.', specific_questions_document_can_answer=['What are the challenges in Neural Radiance Field inpainting?', 'How does the proposed framework improve NeRF inpainting?', 'Why are pixel and perceptual losses harmful in NeRF inpainting tasks?', 'What methods are used to mitigate textural shifts in NeRF inpainting?'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Result\n",
    "res = DocumentMetadata(authors=['Chieh Hubert Lin', 'Changil Kim', 'Jia-Bin Huang', 'Qinbo Li', 'Chih Yao Ma', 'Johannes Kopf', 'Ming-Hsuan Yang', 'Hung-Yu Tseng'], \n",
    "                  journal_name='arXiv', \n",
    "                  publication_date=datetime.date(2024, 4, 15), \n",
    "                  keywords=['Neural Radiance Field', 'NeRF', 'inpainting', 'latent diffusion model', '3D reconstruction', 'multi-view images', 'synthetic contents', 'geometry', 'stochasticity', 'textural shift', 'auto-encoding errors', 'pixel-distance losses', 'per-scene customization', 'masked adversarial training', 'pixel and perceptual losses', 'real-world scenes'], \n",
    "                  doi='2404.09995v1',\n",
    "                  title='Taming Latent Diffusion Model for Neural Radiance Field Inpainting', \n",
    "                  subtitle=None, \n",
    "                  visible_urls=[], \n",
    "                  field_of_science='Computer Vision', \n",
    "                  concise_summary='This paper addresses the challenges in Neural Radiance Field (NeRF) inpainting by proposing a framework that tempers the stochasticity of diffusion models and mitigates textural shifts with masked adversarial training. It also identifies commonly used pixel and perceptual losses as detrimental in NeRF inpainting tasks and demonstrates state-of-the-art results through rigorous experiments.', \n",
    "                  specific_questions_document_can_answer=['What are the challenges in Neural Radiance Field inpainting?', 'How does the proposed framework improve NeRF inpainting?', 'Why are pixel and perceptual losses harmful in NeRF inpainting tasks?', 'What methods are used to mitigate textural shifts in NeRF inpainting?'])\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalServerError",
     "evalue": "Error code: 503 - Service Temporarily Unavailable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalServerError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/kastanday/code/ncsa/ai-ta/ai-ta-backend/llm-pdf-parser.ipynb Cell 5\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kastanday/code/ncsa/ai-ta/ai-ta-backend/llm-pdf-parser.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mopenai\u001b[39;00m \u001b[39mimport\u001b[39;00m OpenAI \u001b[39m# pip install openai>=1.0\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kastanday/code/ncsa/ai-ta/ai-ta-backend/llm-pdf-parser.ipynb#X12sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m client \u001b[39m=\u001b[39m OpenAI(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kastanday/code/ncsa/ai-ta/ai-ta-backend/llm-pdf-parser.ipynb#X12sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     api_key\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mirrelevant\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m# any non-empty string\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kastanday/code/ncsa/ai-ta/ai-ta-backend/llm-pdf-parser.ipynb#X12sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     base_url \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mhttps://api.ncsa.ai/llm/v1\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m## 👈 ONLY CODE CHANGE ##\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kastanday/code/ncsa/ai-ta/ai-ta-backend/llm-pdf-parser.ipynb#X12sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m )\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/kastanday/code/ncsa/ai-ta/ai-ta-backend/llm-pdf-parser.ipynb#X12sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m completion \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39;49mchat\u001b[39m.\u001b[39;49mcompletions\u001b[39m.\u001b[39;49mcreate(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kastanday/code/ncsa/ai-ta/ai-ta-backend/llm-pdf-parser.ipynb#X12sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39m# model=\"teknium/OpenHermes-2.5-Mistral-7B\",\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kastanday/code/ncsa/ai-ta/ai-ta-backend/llm-pdf-parser.ipynb#X12sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39m# model=\"mistralai/Mistral-7B-Instruct-v0.2\", # better than teknium model \u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kastanday/code/ncsa/ai-ta/ai-ta-backend/llm-pdf-parser.ipynb#X12sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     model\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mNousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m# way better than mistral instruct v0.2. Works great! As good as GPT-4 so far.\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kastanday/code/ncsa/ai-ta/ai-ta-backend/llm-pdf-parser.ipynb#X12sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     messages\u001b[39m=\u001b[39;49m[\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kastanday/code/ncsa/ai-ta/ai-ta-backend/llm-pdf-parser.ipynb#X12sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m         \u001b[39m# {\"role\": \"system\", \"content\": \"You are an expert at categorizing scientific papers. Please categorize the following paper.\"},\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kastanday/code/ncsa/ai-ta/ai-ta-backend/llm-pdf-parser.ipynb#X12sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m         {\u001b[39m\"\u001b[39;49m\u001b[39mrole\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39muser\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcontent\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39mYou are an expert at categorizing scientific papers. Please categorize the following paper.\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m\"\u001b[39;49m \u001b[39m+\u001b[39;49m raw_text},\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kastanday/code/ncsa/ai-ta/ai-ta-backend/llm-pdf-parser.ipynb#X12sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     ],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kastanday/code/ncsa/ai-ta/ai-ta-backend/llm-pdf-parser.ipynb#X12sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     extra_body\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mguided_json\u001b[39;49m\u001b[39m\"\u001b[39;49m: DocumentMetadata\u001b[39m.\u001b[39;49mschema()},\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kastanday/code/ncsa/ai-ta/ai-ta-backend/llm-pdf-parser.ipynb#X12sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     temperature\u001b[39m=\u001b[39;49m\u001b[39m0.2\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kastanday/code/ncsa/ai-ta/ai-ta-backend/llm-pdf-parser.ipynb#X12sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     stream\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kastanday/code/ncsa/ai-ta/ai-ta-backend/llm-pdf-parser.ipynb#X12sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kastanday/code/ncsa/ai-ta/ai-ta-backend/llm-pdf-parser.ipynb#X12sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m# ⚡️⚡️ streaming \u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kastanday/code/ncsa/ai-ta/ai-ta-backend/llm-pdf-parser.ipynb#X12sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m final \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/miniforge3/envs/flask9_py10/lib/python3.10/site-packages/openai/_utils/_utils.py:275\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m             msg \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMissing required argument: \u001b[39m\u001b[39m{\u001b[39;00mquote(missing[\u001b[39m0\u001b[39m])\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    274\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 275\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/envs/flask9_py10/lib/python3.10/site-packages/openai/resources/chat/completions.py:667\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, presence_penalty, response_format, seed, stop, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[39m@required_args\u001b[39m([\u001b[39m\"\u001b[39m\u001b[39mmessages\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m], [\u001b[39m\"\u001b[39m\u001b[39mmessages\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mstream\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m    616\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[1;32m    617\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    665\u001b[0m     timeout: \u001b[39mfloat\u001b[39m \u001b[39m|\u001b[39m httpx\u001b[39m.\u001b[39mTimeout \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m|\u001b[39m NotGiven \u001b[39m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    666\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ChatCompletion \u001b[39m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m--> 667\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_post(\n\u001b[1;32m    668\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39m/chat/completions\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    669\u001b[0m         body\u001b[39m=\u001b[39;49mmaybe_transform(\n\u001b[1;32m    670\u001b[0m             {\n\u001b[1;32m    671\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mmessages\u001b[39;49m\u001b[39m\"\u001b[39;49m: messages,\n\u001b[1;32m    672\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mmodel\u001b[39;49m\u001b[39m\"\u001b[39;49m: model,\n\u001b[1;32m    673\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mfrequency_penalty\u001b[39;49m\u001b[39m\"\u001b[39;49m: frequency_penalty,\n\u001b[1;32m    674\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mfunction_call\u001b[39;49m\u001b[39m\"\u001b[39;49m: function_call,\n\u001b[1;32m    675\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mfunctions\u001b[39;49m\u001b[39m\"\u001b[39;49m: functions,\n\u001b[1;32m    676\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mlogit_bias\u001b[39;49m\u001b[39m\"\u001b[39;49m: logit_bias,\n\u001b[1;32m    677\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mlogprobs\u001b[39;49m\u001b[39m\"\u001b[39;49m: logprobs,\n\u001b[1;32m    678\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mmax_tokens\u001b[39;49m\u001b[39m\"\u001b[39;49m: max_tokens,\n\u001b[1;32m    679\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mn\u001b[39;49m\u001b[39m\"\u001b[39;49m: n,\n\u001b[1;32m    680\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mpresence_penalty\u001b[39;49m\u001b[39m\"\u001b[39;49m: presence_penalty,\n\u001b[1;32m    681\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mresponse_format\u001b[39;49m\u001b[39m\"\u001b[39;49m: response_format,\n\u001b[1;32m    682\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mseed\u001b[39;49m\u001b[39m\"\u001b[39;49m: seed,\n\u001b[1;32m    683\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mstop\u001b[39;49m\u001b[39m\"\u001b[39;49m: stop,\n\u001b[1;32m    684\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mstream\u001b[39;49m\u001b[39m\"\u001b[39;49m: stream,\n\u001b[1;32m    685\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtemperature\u001b[39;49m\u001b[39m\"\u001b[39;49m: temperature,\n\u001b[1;32m    686\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtool_choice\u001b[39;49m\u001b[39m\"\u001b[39;49m: tool_choice,\n\u001b[1;32m    687\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtools\u001b[39;49m\u001b[39m\"\u001b[39;49m: tools,\n\u001b[1;32m    688\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtop_logprobs\u001b[39;49m\u001b[39m\"\u001b[39;49m: top_logprobs,\n\u001b[1;32m    689\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtop_p\u001b[39;49m\u001b[39m\"\u001b[39;49m: top_p,\n\u001b[1;32m    690\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39muser\u001b[39;49m\u001b[39m\"\u001b[39;49m: user,\n\u001b[1;32m    691\u001b[0m             },\n\u001b[1;32m    692\u001b[0m             completion_create_params\u001b[39m.\u001b[39;49mCompletionCreateParams,\n\u001b[1;32m    693\u001b[0m         ),\n\u001b[1;32m    694\u001b[0m         options\u001b[39m=\u001b[39;49mmake_request_options(\n\u001b[1;32m    695\u001b[0m             extra_headers\u001b[39m=\u001b[39;49mextra_headers, extra_query\u001b[39m=\u001b[39;49mextra_query, extra_body\u001b[39m=\u001b[39;49mextra_body, timeout\u001b[39m=\u001b[39;49mtimeout\n\u001b[1;32m    696\u001b[0m         ),\n\u001b[1;32m    697\u001b[0m         cast_to\u001b[39m=\u001b[39;49mChatCompletion,\n\u001b[1;32m    698\u001b[0m         stream\u001b[39m=\u001b[39;49mstream \u001b[39mor\u001b[39;49;00m \u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    699\u001b[0m         stream_cls\u001b[39m=\u001b[39;49mStream[ChatCompletionChunk],\n\u001b[1;32m    700\u001b[0m     )\n",
      "File \u001b[0;32m~/miniforge3/envs/flask9_py10/lib/python3.10/site-packages/openai/_base_client.py:1213\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1199\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpost\u001b[39m(\n\u001b[1;32m   1200\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   1201\u001b[0m     path: \u001b[39mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1208\u001b[0m     stream_cls: \u001b[39mtype\u001b[39m[_StreamT] \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1209\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ResponseT \u001b[39m|\u001b[39m _StreamT:\n\u001b[1;32m   1210\u001b[0m     opts \u001b[39m=\u001b[39m FinalRequestOptions\u001b[39m.\u001b[39mconstruct(\n\u001b[1;32m   1211\u001b[0m         method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpost\u001b[39m\u001b[39m\"\u001b[39m, url\u001b[39m=\u001b[39mpath, json_data\u001b[39m=\u001b[39mbody, files\u001b[39m=\u001b[39mto_httpx_files(files), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions\n\u001b[1;32m   1212\u001b[0m     )\n\u001b[0;32m-> 1213\u001b[0m     \u001b[39mreturn\u001b[39;00m cast(ResponseT, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest(cast_to, opts, stream\u001b[39m=\u001b[39;49mstream, stream_cls\u001b[39m=\u001b[39;49mstream_cls))\n",
      "File \u001b[0;32m~/miniforge3/envs/flask9_py10/lib/python3.10/site-packages/openai/_base_client.py:902\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    893\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    894\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    895\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    900\u001b[0m     stream_cls: \u001b[39mtype\u001b[39m[_StreamT] \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    901\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ResponseT \u001b[39m|\u001b[39m _StreamT:\n\u001b[0;32m--> 902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request(\n\u001b[1;32m    903\u001b[0m         cast_to\u001b[39m=\u001b[39;49mcast_to,\n\u001b[1;32m    904\u001b[0m         options\u001b[39m=\u001b[39;49moptions,\n\u001b[1;32m    905\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    906\u001b[0m         stream_cls\u001b[39m=\u001b[39;49mstream_cls,\n\u001b[1;32m    907\u001b[0m         remaining_retries\u001b[39m=\u001b[39;49mremaining_retries,\n\u001b[1;32m    908\u001b[0m     )\n",
      "File \u001b[0;32m~/miniforge3/envs/flask9_py10/lib/python3.10/site-packages/openai/_base_client.py:978\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[39mif\u001b[39;00m retries \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_retry(err\u001b[39m.\u001b[39mresponse):\n\u001b[1;32m    977\u001b[0m     err\u001b[39m.\u001b[39mresponse\u001b[39m.\u001b[39mclose()\n\u001b[0;32m--> 978\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_retry_request(\n\u001b[1;32m    979\u001b[0m         options,\n\u001b[1;32m    980\u001b[0m         cast_to,\n\u001b[1;32m    981\u001b[0m         retries,\n\u001b[1;32m    982\u001b[0m         err\u001b[39m.\u001b[39;49mresponse\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    983\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    984\u001b[0m         stream_cls\u001b[39m=\u001b[39;49mstream_cls,\n\u001b[1;32m    985\u001b[0m     )\n\u001b[1;32m    987\u001b[0m \u001b[39m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m    988\u001b[0m \u001b[39m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[1;32m    989\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m err\u001b[39m.\u001b[39mresponse\u001b[39m.\u001b[39mis_closed:\n",
      "File \u001b[0;32m~/miniforge3/envs/flask9_py10/lib/python3.10/site-packages/openai/_base_client.py:1026\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1022\u001b[0m \u001b[39m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m   1023\u001b[0m \u001b[39m# different thread if necessary.\u001b[39;00m\n\u001b[1;32m   1024\u001b[0m time\u001b[39m.\u001b[39msleep(timeout)\n\u001b[0;32m-> 1026\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request(\n\u001b[1;32m   1027\u001b[0m     options\u001b[39m=\u001b[39;49moptions,\n\u001b[1;32m   1028\u001b[0m     cast_to\u001b[39m=\u001b[39;49mcast_to,\n\u001b[1;32m   1029\u001b[0m     remaining_retries\u001b[39m=\u001b[39;49mremaining,\n\u001b[1;32m   1030\u001b[0m     stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m   1031\u001b[0m     stream_cls\u001b[39m=\u001b[39;49mstream_cls,\n\u001b[1;32m   1032\u001b[0m )\n",
      "File \u001b[0;32m~/miniforge3/envs/flask9_py10/lib/python3.10/site-packages/openai/_base_client.py:978\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[39mif\u001b[39;00m retries \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_retry(err\u001b[39m.\u001b[39mresponse):\n\u001b[1;32m    977\u001b[0m     err\u001b[39m.\u001b[39mresponse\u001b[39m.\u001b[39mclose()\n\u001b[0;32m--> 978\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_retry_request(\n\u001b[1;32m    979\u001b[0m         options,\n\u001b[1;32m    980\u001b[0m         cast_to,\n\u001b[1;32m    981\u001b[0m         retries,\n\u001b[1;32m    982\u001b[0m         err\u001b[39m.\u001b[39;49mresponse\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    983\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    984\u001b[0m         stream_cls\u001b[39m=\u001b[39;49mstream_cls,\n\u001b[1;32m    985\u001b[0m     )\n\u001b[1;32m    987\u001b[0m \u001b[39m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m    988\u001b[0m \u001b[39m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[1;32m    989\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m err\u001b[39m.\u001b[39mresponse\u001b[39m.\u001b[39mis_closed:\n",
      "File \u001b[0;32m~/miniforge3/envs/flask9_py10/lib/python3.10/site-packages/openai/_base_client.py:1026\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1022\u001b[0m \u001b[39m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m   1023\u001b[0m \u001b[39m# different thread if necessary.\u001b[39;00m\n\u001b[1;32m   1024\u001b[0m time\u001b[39m.\u001b[39msleep(timeout)\n\u001b[0;32m-> 1026\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request(\n\u001b[1;32m   1027\u001b[0m     options\u001b[39m=\u001b[39;49moptions,\n\u001b[1;32m   1028\u001b[0m     cast_to\u001b[39m=\u001b[39;49mcast_to,\n\u001b[1;32m   1029\u001b[0m     remaining_retries\u001b[39m=\u001b[39;49mremaining,\n\u001b[1;32m   1030\u001b[0m     stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m   1031\u001b[0m     stream_cls\u001b[39m=\u001b[39;49mstream_cls,\n\u001b[1;32m   1032\u001b[0m )\n",
      "File \u001b[0;32m~/miniforge3/envs/flask9_py10/lib/python3.10/site-packages/openai/_base_client.py:993\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    990\u001b[0m         err\u001b[39m.\u001b[39mresponse\u001b[39m.\u001b[39mread()\n\u001b[1;32m    992\u001b[0m     log\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mRe-raising status error\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 993\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_status_error_from_response(err\u001b[39m.\u001b[39mresponse) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    995\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_response(\n\u001b[1;32m    996\u001b[0m     cast_to\u001b[39m=\u001b[39mcast_to,\n\u001b[1;32m    997\u001b[0m     options\u001b[39m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1000\u001b[0m     stream_cls\u001b[39m=\u001b[39mstream_cls,\n\u001b[1;32m   1001\u001b[0m )\n",
      "\u001b[0;31mInternalServerError\u001b[0m: Error code: 503 - Service Temporarily Unavailable"
     ]
    }
   ],
   "source": [
    "### LLM PARSING\n",
    "from openai import OpenAI # pip install openai>=1.0\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=\"irrelevant\", # any non-empty string\n",
    "    base_url = \"https://api.ncsa.ai/llm/v1\" ## 👈 ONLY CODE CHANGE ##\n",
    ")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO\", # way better than mistral instruct v0.2. Works great! As good as GPT-4 so far.\n",
    "    messages=[\n",
    "        # {\"role\": \"system\", \"content\": \"You are an expert at categorizing scientific papers. Please categorize the following paper.\"},\n",
    "        {\"role\": \"user\", \"content\": \"You are an expert at categorizing scientific papers. Please categorize the following paper.\\n\" + raw_text},\n",
    "    ],\n",
    "    extra_body={\"guided_json\": DocumentMetadata.schema()},\n",
    "    temperature=0.2,\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "# ⚡️⚡️ streaming \n",
    "final = \"\"\n",
    "for chunk in completion:\n",
    "    print(chunk.choices[0].delta.content or \"\", end=\"\")\n",
    "    final += chunk.choices[0].delta.content or \"\"\n",
    "\n",
    "# print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'authors': ['Chieh Hubert Lin',\n",
       "  'Changil Kim',\n",
       "  'Jia-Bin Huang',\n",
       "  'Qinbo Li',\n",
       "  'Chih Yao Ma',\n",
       "  'Johannes Kopf',\n",
       "  'Ming-Hsuan Yang',\n",
       "  'Hung-Yu Tseng'],\n",
       " 'journal_name': 'eccv',\n",
       " 'publication_date': '15 Apr 2024',\n",
       " 'keywords': ['Neural Radiance Field',\n",
       "  'NeRF inpainting',\n",
       "  'latent diffusion model',\n",
       "  'stochasticity',\n",
       "  'textural shift',\n",
       "  'per-scene customization',\n",
       "  'masked adversarial training',\n",
       "  'pixel and perceptual losses'],\n",
       " 'doi': '2404.09995v1',\n",
       " 'title': 'Taming Latent Diffusion Model for Neural Radiance Field Inpainting',\n",
       " 'subtitle': 'Taming Latent Diffusion Model for Neural Radiance Field Inpainting',\n",
       " 'visible_urls': ['https://arxiv.org/abs/2404.09995v1'],\n",
       " 'field_of_science': 'Computer Science',\n",
       " 'concise_summary': 'This paper proposes a framework for NeRF inpainting that addresses issues related to stochasticity and textural shift in the latent diffusion model. The framework uses per-scene customization and masked adversarial training to improve the quality of the inpainted NeRF. The authors also found that commonly used pixel and perceptual losses are not suitable for this task.',\n",
       " 'questions_document_can_answer': ['What is the main focus of this paper?',\n",
       "  'What issues does the proposed framework address in the latent diffusion model?',\n",
       "  'What techniques are used to improve the quality of the inpainted NeRF?',\n",
       "  'What did the authors find about the commonly used pixel and perceptual losses in this task?']}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = DocumentMetadata.parse_raw(final)\n",
    "doc.dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SQLite import insert_doc\n",
    "insert_doc(doc, commit_on_change=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
