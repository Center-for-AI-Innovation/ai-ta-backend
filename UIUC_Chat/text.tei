<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">TRAK: Attributing Model Behavior at Scale</title>
				<funder>
					<orgName type="full">United States Air Force Research Laboratory</orgName>
				</funder>
				<funder ref="#_ZxpHT3g">
					<orgName type="full">United States Air Force Artificial Intelligence Accelerator</orgName>
				</funder>
				<funder ref="#_FKTWTW6 #_gXVzEnK">
					<orgName type="full">National Science Foundation</orgName>
					<orgName type="abbreviated">NSF</orgName>
				</funder>
				<funder ref="#_V3Pndtw">
					<orgName type="full">Defense Advanced Research Projects Agency</orgName>
					<orgName type="abbreviated">DARPA</orgName>
				</funder>
				<funder>
					<orgName type="full">Open Philanthropy</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2023-04-03">3 Apr 2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Sung</forename><forename type="middle">Min</forename><surname>Park</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Kristian</forename><surname>Georgiev</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Andrew</forename><surname>Ilyas</surname></persName>
							<email>ailyas@mit.edu</email>
						</author>
						<author>
							<persName><forename type="first">Guillaume</forename><surname>Leclerc</surname></persName>
							<email>leclerc@mit.edu</email>
						</author>
						<author>
							<persName><forename type="first">Aleksander</forename><forename type="middle">M</forename><surname>Ądry Mit</surname></persName>
						</author>
						<title level="a" type="main">TRAK: Attributing Model Behavior at Scale</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2023-04-03">3 Apr 2023</date>
						</imprint>
					</monogr>
					<idno type="MD5">310C8DE357EB32F055ABD91B82BFA222</idno>
					<idno type="arXiv">arXiv:2303.14186v2[stat.ML]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T22:08+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The goal of data attribution is to trace model predictions back to training data. Despite a long line of work towards this goal, existing approaches to data attribution tend to force users to choose between computational tractability and efficacy. That is, computationally tractable methods can struggle with accurately attributing model predictions in non-convex settings (e.g., in the context of deep neural networks), while methods that are effective in such regimes require training thousands of models, which makes them impractical for large models or datasets.</p><p>In this work, we introduce TRAK (Tracing with the Randomly-projected After Kernel), a data attribution method that is both effective and computationally tractable for large-scale, differentiable models. In particular, by leveraging only a handful of trained models, TRAK can match the performance of attribution methods that require training thousands of models. We demonstrate the utility of TRAK across various modalities and scales: image classifiers trained on ImageNet, vision-language models (CLIP), and language models (BERT and mT5). We provide code for using TRAK (and reproducing our work) at https://github.com/MadryLab/trak.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Training data is a key driver of model behavior in modern machine learning systems. Indeed, model errors, biases, and capabilities can all stem from the training data [IST+19; GDG17; GRM+19]. Furthermore, improving the quality of training data generally improves the performance of the resulting models <ref type="bibr" target="#b31">[HAE16;</ref><ref type="bibr" target="#b55">LIN+22]</ref>. The importance of training data to model behavior has motivated extensive work on data attribution, i.e., the task of tracing model predictions back to the training examples that informed these predictions. Recent work demonstrates, in particular, the utility of data attribution methods in applications such as explaining predictions [KL17; IPE+22], debugging model behavior <ref type="bibr" target="#b52">[KSH22;</ref><ref type="bibr" target="#b84">SPI+22]</ref>, assigning data valuations [GZ19; JDW+19], detecting poisoned or mislabeled data <ref type="bibr" target="#b60">[LZL+22;</ref><ref type="bibr" target="#b34">HL22a]</ref>, and curating data [KKG+19; LDZ+21; JWS+21].</p><p>However, a recurring tradeoff in the space of data attribution methods is that of computational demand versus efficacy. On the one hand, methods such as influence approximation [KL17; SZV+22] or gradient agreement scoring <ref type="bibr" target="#b69">[PLS+20]</ref> are computationally attractive but can be unreliable in non-convex settings [BPF21; IPE+22; ABL+22]. On the other hand, sampling-based methods such as empirical influence functions <ref type="bibr" target="#b26">[FZ20]</ref>, Shapley value estimators [GZ19; JDW+19] or datamodels <ref type="bibr" target="#b42">[IPE+22]</ref> are more successful at accurately attributing predictions to training data but require training thousands (or tens of thousands) of models to be effective. We thus ask:</p><p>Are there data attribution methods that are both scalable and effective in large-scale non-convex settings? ResNet-9 on CIFAR-10 TRAK Datamodel <ref type="bibr" target="#b42">[IPE+22]</ref> Emp. Influence <ref type="bibr" target="#b26">[FZ20]</ref> IF-Arnoldi [SZV+22] IF <ref type="bibr" target="#b50">[KL17]</ref> Representation Sim.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>GAS [HL22]</head><p>TracIn <ref type="bibr" target="#b69">[PLS+20]</ref> 10 1 10 2 10 3 10 4 10 5 0 0.2 0.4 0.6</p><p>Computation time (mins) on 1xA100 (← more efficient)</p><p>BERT-base on QNLI Figure <ref type="figure" target="#fig_6">1</ref>: Our data attribution method TRAK achieves state-of-the-art tradeoffs between speed and efficacy. Here, we benchmark its performance relative to prior methods on CIFAR-10-trained ResNet-9 models and QNLI-trained BERT-BASE models. The x-axis indicates the time (in minutes) it takes to run each method on a single A100 GPU (see Appendix A.4 for details). The y-axis indicates the method's efficacy as measured by its ability to make accurate counterfactual predictions (see Definition 2.3 for the precise metric); error bars indicate 95% bootstrap confidence intervals.</p><p>To properly answer this question, we first need a unifying metric for evaluating data attribution methods. To this end, we adopt the view that a data attribution method is useful insofar as it can make accurate counterfactual predictions, i.e., answer questions of the form "what would happen if I trained the model on a given subset S of my training set?" This perspective motivates a benchmark-inspired by the datamodeling framework <ref type="bibr" target="#b42">[IPE+22]</ref>-that measures the correlation between true model outputs and attribution-derived predictions for those outputs.</p><p>With this benchmark in hand, in Section 3 we consider our motivating question and introduce TRAK (Tracing with the Randomly-projected After Kernel), a new data attribution method for parametric, differentiable models. The key idea behind TRAK is to first approximate models with a kernel machine (e.g., through the empirical neural tangent kernel <ref type="bibr" target="#b45">[JGH18]</ref>) and then to leverage our understanding of the resulting kernel domain to derive data attribution scores.</p><p>We demonstrate that TRAK retains the efficacy of sampling-based attribution methods while being several orders of magnitude cheaper computationally. For example (Figure <ref type="figure" target="#fig_6">1</ref>), on CIFAR-10 (image classification) and QNLI (natural language inference), TRAK can be as effective as datamodels <ref type="bibr" target="#b42">[IPE+22]</ref> while being 100-1000x faster to compute. Furthermore, TRAK is as fast as existing gradient-based methods such as TracIn <ref type="bibr" target="#b69">[PLS+20]</ref> or variations of influence functions [KL17; SZV+22], while being significantly more predictive of model behavior.</p><p>As a result, TRAK enables us to study the connection between model predictions and training data in large-scale settings. For example, we use TRAK to study predictions of ImageNet classifiers (Section 4); to understand the shared image-text embedding space of CLIP models <ref type="bibr" target="#b74">[RKH+21]</ref> trained on MS COCO <ref type="bibr" target="#b58">[LMB+14]</ref> (Section 5.1); and to fact-trace language models (a 300M-parameter mT5-small model [RSR+20; XCR+21]) finetuned on FTRACE-TREX (Section 5.2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Motivation and Setup</head><p>We begin with a focus on the supervised learning regime. We will denote by S = {z 1 , . . . , z n } an ordered training set of examples, where each z i = (x i , y i ) ∈ Z is an input-label pair. We represent machine learning models (implicitly) using a model output function f (z; θ), which maps an example of interest z and model parameters θ to a real number. There are a variety of model output functions that one can employ-for example, the loss L(z; θ) of the model on the example z is a natural choice. Ultimately, though, the appropriate model output function to use will depend on the setting that we are studying.</p><p>Throughout this work, we also assume that models are trained to minimize the empirical training loss, i.e., that the parameters of these models are given by θ (S) := arg min</p><formula xml:id="formula_0">θ ∑ z i ∈S L(z i ; θ),<label>(1)</label></formula><p>where, again, L(z i ; θ) is the model training loss on example z i . We write θ as a function of S as we will later consider varying S-but when S is clear from the context, we omit it and just write θ . In this paper, our overarching goal is to trace model predictions back to the composition of training data. This goal-which we refer to as data attribution-is not new. Prior work has approached it using methods such as influence functions and their many variants [HRR+11; KL17; FZ20; HL22a]; sampling-based estimators such as Shapley values <ref type="bibr" target="#b56">[LL17]</ref>, empirical influences <ref type="bibr" target="#b26">[FZ20]</ref>, and datamodels <ref type="bibr" target="#b42">[IPE+22]</ref>; as well as various other approaches [YKY+18; PLS+20; HL22b]. Each of these methods implements a similar interface: given a model and an output of interest (e.g., loss for a given prediction), a data attribution method computes a score for each training input indicating its importance to the output of interest. Definition 2.1 below makes this interface precise: Definition 2.1 (Data attribution). Consider an ordered training set of examples S = {z 1 , . . . , z n } and a model output function f (z; θ). A data attribution method τ(z, S) is a function τ : Z × Z n → R n that, for any example z ∈ Z and a training set S, assigns a (real-valued) score to each training input z i ∈ S indicating its importance<ref type="foot" target="#foot_0">1</ref> to the model output f (z; θ (S)). When the second argument S is clear from the context, we will omit the second argument and simply write τ(z).</p><p>Example 2.2 (Influence functions as an attribution method). An example of a data attribution method is the influence function approach, a concept from robust statistics. For a specific model output function f (z; θ) on an example of interest z, an influence function assigns a score to each training example z i that approximates the effect on the output f (z; θ) of infinitesimally up-weighting that training example. A classic result from <ref type="bibr" target="#b19">[CW82]</ref> shows that this score can be computed as</p><formula xml:id="formula_1">τ IF (z) i = ∇ θ f (z; θ ) • H -1 θ • ∇ θ L(z i ; θ )</formula><p>, where, again, θ are the parameters that minimize the empirical risk, L(z i ; θ ) is the training loss of example z i , and H θ is the Hessian ∇ 2 θ 1 n ∑ z i ∈S L(z i ; θ ) of the total training loss.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Evaluating attribution methods.</head><p>Given the variety of existing data attribution methods, we need a method to evaluate them in a consistent way. One popular approach is to simply manually inspect the training examples that the method identifies as most important for a given prediction or set of predictions. Such manual inspection can be a useful sanity check, but is also often subjective and unreliable. For example, in computer vision, visual similarity between two images does not fully capture the influence of one on the other in terms of model behavior <ref type="bibr" target="#b42">[IPE+22]</ref>.</p><p>A more objective alternative is to treat the scores from a data attribution method as estimates of some ground-truth parameters-such as leave-one-out influences [KL17; BPF21; KAT+19] or Shapley values <ref type="bibr" target="#b56">[LL17]</ref>-and then measure the accuracy of these estimates. This approach to evaluation is not only more quantitative than visual inspection but also inherits all favorable properties of the ground-truth parameter being considered (e.g., additivity of Shapley values <ref type="bibr" target="#b82">[Sha51]</ref>). However, getting access to these ground-truth parameters can be prohibitively expensive in large-scale settings.</p><p>Finally, yet another possibility is to measure the utility of data attribution scores for an auxiliary task such as identifying mislabeled data <ref type="bibr" target="#b50">[KL17;</ref><ref type="bibr" target="#b34">HL22a]</ref> or active learning <ref type="bibr" target="#b47">[JWS+21]</ref>. This approach can indeed be a useful proxy for evaluating data attribution methods, but the resulting metrics may be too sensitive to the particulars of the auxiliary task and thus make comparisons across different problems and settings difficult.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">The linear datamodeling score (LDS)</head><p>Motivated by the above shortcomings of existing methodologies, we propose a new metric for evaluating data attribution methods. At the heart of our metric is the perspective that an effective data attribution method should be able to make accurate counterfactual predictions about model outputs. In other words, if a method can accurately quantify the importance of individual training examples to model outputs, it should also be able to predict how model outputs change when the training set is modified in a particular way.</p><p>Inspired by Ilyas et al. <ref type="bibr" target="#b42">[IPE+22]</ref>, we cast this counterfactual estimation task as that of predicting the model output function f (z; θ (S )) given different subsets of the training set S . More precisely, consider-for a fixed example of interest z ∈ Z-the model output f (z; θ (S )) arising from training on a subset S ⊂ S of the training set S (see (1)).<ref type="foot" target="#foot_2">2</ref> Since z is fixed and the learning algorithm θ (•) is fixed, we can view this model output as a function of S alone. A good data attribution method should help us predict the former from the latter.</p><p>To operationalize this idea, we first need a way of converting a given data attribution method τ(•) into a counterfactual predictor. We observe that the vast majority of data attribution methods are additive-that is, they define the importance of a group of training examples to be the sum of the importances of the examples in the group. 3 Motivated by this observation, we define an attribution method's prediction of the model output for a subset S ⊂ S as the sum of the corresponding scores: Definition 2.3 (Attribution-based output predictions). Consider a training set S, a model output function f (z; θ), and a corresponding data attribution method τ (see Definition 2.1). The attributionbased output prediction of the model output f (z; θ (S )) is defined as</p><formula xml:id="formula_2">g τ (z, S ; S) := ∑ i : z i ∈S τ(z, S) i = τ(z, S) • 1 S ,<label>(2)</label></formula><p>where 1 S is the indicator vector of the subset S of S (i.e., (1</p><formula xml:id="formula_3">S ) i = 1{z i ∈ S }).</formula><p>Intuitively, Definition 2.3 turns any data attribution method into a counterfactual predictor. Specifically, for a given counterfactual training set S ⊂ S, the attribution method's prediction is simply the sum of the scores of the examples contained in S . Now that we have defined how to derive predictions from an attribution method, we can evaluate these predictions using the linear datamodeling score, defined as follows: Definition 2.4 (Linear datamodeling score). Consider a training set S, a model output function f (z; θ), and a corresponding data attribution method τ (see Definition 2.1). Let {S 1 , . . . , S m : S i ⊂ S} be m randomly sampled subsets of the training set S, each of size α • n for some α ∈ (0, 1). The linear datamodeling score (LDS) of a data attribution τ for a specific example z ∈ Z is given by</p><formula xml:id="formula_4">LDS(τ, z) := ρ({ f (z; θ (S j )) : j ∈ [m]}, {g τ (z, S j ; S) : j ∈ [m]}),</formula><p>where ρ denotes Spearman rank correlation <ref type="bibr" target="#b83">[Spe04]</ref>. The attribution method's LDS for an entire test set is then simply the average per-example score.</p><p>Note that the linear datamodeling score defined above is quantitative, simple to compute, <ref type="foot" target="#foot_4">4</ref> and not tied to a specific task or modality.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">An oracle for data attribution</head><p>Definition 2.4 immediately suggests an "optimal" approach to data attribution (at least, in terms of optimizing LDS). This approach simply samples random subsets {S 1 , . . . S m } of the training set; trains a model on each subset (yielding {θ (S 1 ), . . . , θ (S m )}); evaluates each corresponding model output function f (z; θ (S j )); and then fits scores τ(z) that predict f (z; θ (S i )) from the indicator vector 1 S i using (regularized) empirical risk minimization. Indeed, Ilyas et al. <ref type="bibr" target="#b42">[IPE+22]</ref> take exactly this approach-the resulting datamodel-based attribution for an example z is then given by τ DM (z) := min</p><formula xml:id="formula_5">β∈R n 1 m m ∑ i=1 β 1 S i -f (z; θ (S i )) 2 + λ β 1 .</formula><p>(3)</p><p>The attributions τ DM (z) turn out to indeed perform well according to Definition 2.4-that is, they yield counterfactual predictions that are highly correlated with true model outputs (see Figure <ref type="figure" target="#fig_6">1</ref>). Unfortunately, however, estimating accurate linear predictors (3) may require tens (or even hundreds) of thousands of samples (S j , f (z; θ (S j ))). In light of the above, we can view the approach of Ilyas et al. <ref type="bibr" target="#b42">[IPE+22]</ref> as an "oracle" of sorts-it makes accurate counterfactual predictions (and as a result has found downstream utility [IPE+22; SPI+22; CJ22]), but is (often prohibitively) costly to compute.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Data attribution methods beyond sampling</head><p>How might we be able to circumvent the estimation cost of sampling-based attributions? Let us start by examining the existing data attribution methods-specifically, the ones that use only one (or a few) trained models-and evaluate them on our LDS benchmark.</p><p>Simulating re-training with influence functions. The bottleneck of the "oracle" datamodels attribution method (3) <ref type="bibr" target="#b42">[IPE+22]</ref> is that obtaining each sample (S j , f (z; S j )) requires re-training our model of interest from scratch on each subset S j . An alternative approach could be to simulate the effect of this re-training by making some structural assumptions about the model being studiede.g., that its loss is locally well-approximated by a quadratic. This idea has inspired a long line of work around influence function estimation [KL17; PLS+20; SZV+22]. The resulting influence function attributions (Example 2.2) accurately approximate linear models and other simple models, but can perform poorly in non-convex settings (e.g., in the context of deep neural networks) [BPF21; IPE+22; BNL+22]. Indeed, as we can see in Figure <ref type="figure" target="#fig_6">1</ref> (and as we later study in Section 4), estimators based on influence functions [KL17; SZV+22; HL22a] significantly underperform on our LDS benchmark (Definition 2.4) when evaluated on neural networks on standard vision and natural language tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Heuristic measures of example importance.</head><p>There are also approaches that use more heuristic measures of training example importance for data attribution. These include methods based on, e.g., representation space similarity [ZIE+18; HYH+21] or gradient agreement <ref type="bibr" target="#b34">[HL22a]</ref>. While such methods often yield qualitatively compelling results, our experiments (again, see Figure <ref type="figure" target="#fig_6">1</ref>) indicate that, similarly to influence-based estimators, they are unable to make meaningful counterfactual predictions about model outputs in the large-scale, non-convex settings we evaluate them on.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">TRAK: Tracing with the Randomly-Projected After Kernel</head><p>We now present TRAK, a new data attribution method which is designed to be both effective and scalable in large-scale differentiable settings. (Recall from Definition 2.1 that a data attribution function is a function mapping examples z to a vector of per-training example scores in R n .)</p><p>As a warm-up, and to illustrate the core primitive behind TRAK, we first study the simple case of logistic regression (Section 3.1). In this setting, data attribution is well-understood-in particular, there is a canonical attribution method <ref type="bibr" target="#b70">[Pre81]</ref> that is both easy-to-compute and highly effective [WCZ+16; KAT+19]. In Section 3.2, using this canonical attribution method as a primitive, we derive our data attribution method τ TRAK (•) (Equation (17), also summarized in Algorithm 1 in Section 3.4) which operates by reducing complex models back to the logistic regression case.<ref type="foot" target="#foot_5">5</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Warmup: Data attribution for logistic regression</head><p>Consider the case where the model being studied is (a generalized form of) binary logistic regression. In particular, adapting our notation from Section 2, we consider a training set of n examples</p><formula xml:id="formula_6">S = {z 1 , . . . , z n : z i = (x i ∈ R d , b i ∈ R, y i ∈ {-1, 1})},</formula><p>where each example comprises an input x i ∈ R d , a bias b i ∈ R, and a label y i ∈ {-1, 1}. The final model parameters θ (S) then minimize the log-loss over the training set, i.e., θ (S)</p><formula xml:id="formula_7">:= arg min θ ∑ (x i ,y i )∈S log 1 + exp(-y i • (θ x i + b i )) . (<label>4</label></formula><formula xml:id="formula_8">)</formula><p>(Note that when the bias terms b i are identically zero, we recover ordinary logistic regression.) The natural choice of model output function in this case is then the "raw logit" function:</p><formula xml:id="formula_9">f (z; θ) := θ x + b, where z = (x, b, y).<label>(5)</label></formula><p>Data attribution in this simple setting is a well-studied problem. In particular, the one-step Newton approximation [Pre81; WCZ+16; RM18; KAT+19], which we present as a data attribution method τ NS below, is a standard tool for analyzing and understanding logistic regression models in terms of their training data. (We present the theoretical basis for this method in Appendix C.1.) Definition 3.1 (One-step Newton approximation <ref type="bibr" target="#b70">[Pre81]</ref>). For logistic regression, we define the Newton step data attribution method τ NS as the approximate leave-one-out influence <ref type="bibr" target="#b70">[Pre81]</ref> of training examples z i = (x i , b i , y i ) on the model output function (5). That is,</p><formula xml:id="formula_10">τ NS (z) i := x (X RX) -1 x i 1 -x i (X RX) -1 x i • p i (1 -p i ) (1 -p i ) ≈ f (z; θ (S)) -f (z; θ (S \ z i ))<label>(6)</label></formula><p>where X ∈ R n×k is the matrix of stacked inputs x i ,</p><formula xml:id="formula_11">p i := (1 + exp(-y i • f (z i ; θ ))) -1 is the predicted correct-class probability at θ and R is a diagonal n × n matrix with R ii = p i (1 -p i ).</formula><p>If our model class of interest was binary logistic regression, we could simply apply Definition 3.1 to perform data attribution. As we discuss, however, our goal is precisely to scale data attribution beyond such convex settings. To this end, we next derive our data attribution method TRAK (Tracing with the Randomly-projected After Kernel) which leverages τ NS (Definition 3.1) as a primitive.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">TRAK for binary (non-linear) classifiers</head><p>We now present our method (TRAK) for scaling data attribution to non-convex differentiable settings. More precisely, following Definition 2.1, we describe how to compute a function τ TRAK : Z → R n that maps examples of interest z to vectors of per-training example importance scores in R n . The key primitive here will be Definition 3.1 from above-in particular, we will show how to adapt our problem into one to which we can apply the approximation (6).</p><p>For ease of exposition, we will first show how to compute τ TRAK in the context of binary classifiers trained with the negative log-likelihood loss. We later generalize TRAK to other types of models (e.g., to multi-class classifiers in Section 3.3, to contrastive models in Section 5.1, and to language models in Section 5.2). In this setting, let the model output function f (z; θ) be the raw output (i.e., the logit) of a binary classifier with parameters θ. <ref type="foot" target="#foot_6">6</ref> The final parameters of the model can thus be written as</p><formula xml:id="formula_12">θ (S) = arg min θ ∑ (x i ,y i )∈S log [1 + exp (-y i • f (z i ; θ))] .<label>(7)</label></formula><p>Note that unlike in Section 3.1, we do not assume that the model itself is linear-e.g., the model might be a deep neural network parameterized by weights θ.</p><p>We implement TRAK as a sequence of five steps:</p><p>1. Linearizing the model output function (via Taylor approximation), which reduces the model of interest to a linear function in parameter space. Prior work (around, e.g., the empirical neural tangent kernel) suggests that this approximation can be relatively accurate, especially for overparameterized neural networks [JGH18; WHS22; Lon21; MWY+22].</p><p>2. Reducing the dimensionality of the linearized model using random projections. Specifically, we take advantage of the Johnson-Lindenstrauss lemma <ref type="bibr" target="#b46">[JL84]</ref>, which guarantees that this projection preserves the model-relevant information.</p><p>3. Estimating attribution scores by leveraging the attribution method described in Definition 3.1.</p><p>4. Ensembling results over several models, each trained on a random subset of the original training set S.</p><p>5. Sparsifying the attribution scores using soft-thresholding.</p><p>We discuss these steps in more depth below.</p><p>(Step 1) Linearizing the model. Recall that our goal here is to apply the data attribution method τ NS from Definition 3.1. The main roadblock to applying Definition 3.1 in our setting is that we are studying a non-linear model-that is, our model output function may not be a linear function of θ.</p><p>We address this issue by approximating f (z; θ) with its Taylor expansion centered around the final model parameters θ . In particular, for any θ, we replace f (z; θ) with f (z; θ)</p><formula xml:id="formula_13">:= f (z; θ ) + ∇ θ f (z; θ ) (θ -θ ).<label>(8)</label></formula><p>This approximation suggests a change in perspective-rather than viewing f (z; θ) as a non-linear model acting on inputs x, we can view it as a linear model acting on inputs ∇ θ f (z; θ ). In particular, rewriting the loss minimization (7) while replacing f (z; θ) with f (z; θ) yields</p><formula xml:id="formula_14">θ (S) = arg min θ ∑ (x i ,y i )∈S log 1 + exp -y i • θ ∇ θ f (z i ; θ ) + f (z i ; θ ) -∇ θ f (z i ; θ ) θ . (9)</formula><p>Now, Equation (9) should look familiar-specifically, if we define the variables</p><formula xml:id="formula_15">g i := ∇ θ f (z i ; θ ) and b i := f (z i ; θ ) -∇ θ f (z i ; θ ) θ , then (9) becomes θ (S) = arg min θ ∑ (g i ,b i ,y i ) log 1 + exp -y i • θ g i + b i .<label>(10)</label></formula><p>Comparing (10) to (4) (from Section 3.1) makes it clear that we can view θ as the solution to a (generalized) logistic regression, in which the inputs x i are gradients g i := ∇ θ f (z i ; θ ) of the model, the bias terms are b i := f (z i ; θ ) -∇ θ f (z i ; θ ) θ and the labels y i remain the same.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Note:</head><p>In the context of neural networks, we can view Step 1 as replacing the binary classifier with its empirical neural tangent kernel (eNTK) approximation [JGH18; ABP22; WHS22]. We discuss how TRAK connects to the eNTK in more detail in Section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>(Step 2) Reducing dimensionality with random projections. The linear approximation from</head><p>Step 1 dramatically simplifies our model class of interest from a highly non-linear classifier to simple logistic regression. Still, the resulting logistic regression can be extremely high dimensional.</p><p>In particular, the input dimension of the linear model ( <ref type="formula" target="#formula_13">8</ref>) is the number of parameters of the original model (which can be on the order of millions or billions), not the dimensionality of the inputs x i .</p><p>To reduce the dimensionality of this problem, we leverage a classic result of Johnson and Lindenstrauss <ref type="bibr" target="#b46">[JL84]</ref>. This result guarantees that multiplying each gradient g i = ∇ θ f (z i ; θ ) ∈ R p by a random matrix P ∼ N (0, 1) p×k for k p preserves inner products g i g j with high probability<ref type="foot" target="#foot_7">7</ref> (while significantly reducing the dimension). Thus, we define the "feature map" φ : Z → R k as</p><formula xml:id="formula_16">φ(z) := P ∇ θ f (z; θ ),<label>(11)</label></formula><p>i.e., a function taking an example z to its corresponding projected gradient, and from now on replace g i with</p><formula xml:id="formula_17">φ i := φ(z i ) = P g i = P ∇ θ f (z i ; θ ). (<label>12</label></formula><formula xml:id="formula_18">)</formula><formula xml:id="formula_19">(</formula><p>Step 3) Estimating influences. Now that we have simplified our original model of interest to a logistic regression problem of tractable dimension, we can finally adapt Definition 3.1. To this end, recall that the training "inputs" are now the (projected) gradients φ i (see (12)). We thus replace the matrix X in (6) with the matrix Φ := [φ 1 ; . . . , φ n ] ∈ R n×k of stacked projected gradients. We also find empirically that both the denominator in (6) and the diagonal matrix R have little effect on the resulting estimates, and so we omit them from our adapted estimator. Our estimator for attribution scores for an example of interest z thus becomes:</p><formula xml:id="formula_20">τ(z, S) := φ(z) (Φ Φ) -1 Φ Q, (<label>13</label></formula><formula xml:id="formula_21">)</formula><p>where we recall from (11) that φ(z) = P ∇ θ f (z; θ ), and where we define</p><formula xml:id="formula_22">Q := diag({1 -p i }) = diag (1 + exp(y i • f (z i ; θ ))) -1<label>(14)</label></formula><p>to be the n × n diagonal matrix of "one minus correct-class probability" terms.<ref type="foot" target="#foot_8">8</ref> </p><p>Remark. An alternative way to motivate our single-model estimator (Equation ( <ref type="formula" target="#formula_20">13</ref>)) is to compute the influence function <ref type="bibr" target="#b50">[KL17]</ref> using the generalized Gauss-Newton approximation to the Hessian [SEG+17; Mar20 To "smooth out" the impact of such seed-based differences, we aggregate the estimator (13) across multiple trained models (for computational efficiency, one can also use different checkpoints from the same model-see Appendix E.3). In particular, we adopt the natural idea of just averaging τ(z, S) from (13) directly, with two small modifications:</p><p>(a) Rather than computing M copies of (13) and averaging the results, we separately compute and average M copies of Q (i.e., ( <ref type="formula" target="#formula_22">14</ref>)) and M copies of φ(z) (Φ Φ) -1 Φ (i.e., the remaining terms in (13)). We then take the product of these averaged matrices.</p><p>(b) Rather than training M copies of the same model θ (S), we sample M random subsets of S (S 1 , . . . , S M ), and use the resulting models θ (S 1 ), . . . , θ (S M ) to compute attribution scores.</p><p>The first modification (a) is mainly for numerical stability, while the second modification (b) is meant to better handle duplicated training examples (and, more generally, features that are highly "redundant" in the training data). We study the effect of these modifications empirically in Appendix E. At this point, our estimator is of the form:</p><formula xml:id="formula_23">τ M (z, S) := 1 M M ∑ i=1 Q m • 1 M M ∑ i=1 φ m (z) (Φ m Φ m ) -1 Φ m ,<label>(15)</label></formula><p>where S 1 , . . . , S M are M randomly selected subsets of the training set S; Φ m are the corresponding projected gradients from the model θ (S m ); φ m (z) is the featurized example z under model θ (S m ); and Q m is the corresponding matrix of probabilities as defined in Equation ( <ref type="formula" target="#formula_22">14</ref>).</p><p>(Step 5) Inducing sparsity via soft-thresholding. In the last step, we post-process the attribution scores from Step 4 via soft thresholding, a common denoising method in statistics <ref type="bibr" target="#b23">[Don95]</ref> for when an underlying signal is known to be sparse. Within our particular context, Ilyas et al. <ref type="bibr" target="#b42">[IPE+22]</ref> find that for neural networks attribution scores are often sparse-that is, each test example depends on only a few examples from the training set. Motivated by this observation, we apply the soft thresholding operator S(•; λ) defined for any τ ∈ R n as:</p><formula xml:id="formula_24">S(τ; λ) = (τ i -λ) • 1{τ i &gt; λ} + (τ i + λ) • 1{τ i &lt; -λ}. (<label>16</label></formula><formula xml:id="formula_25">)</formula><p>We choose the soft threshold parameter λ via cross-validation. That is, given a set of trained models, we first estimate attribution scores (15), then sample a range of values for λ, compute corresponding attribution scores by applying (16), and finally select the value of λ that yields that highest linear datamodeling score (Definition 2.4) on the set of trained models. After applying soft-thresholding, our final estimator becomes</p><formula xml:id="formula_26">τ TRAK (z, S) := S 1 M M ∑ i=1 Q m • 1 M M ∑ i=1 φ m (z) (Φ m Φ m ) -1 Φ m , λ<label>(17)</label></formula><p>where, again, λ is selected via cross-validation (see Appendix A.2 for details).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Extending to multi-class classification</head><p>In the previous section, we instantiated TRAK for binary classifiers; we now show how to extend TRAK to the multi-class setting. Recall that our key insight in the binary case was to linearize the model output function f (z; θ) around the optimal parameters θ (S) (see (8)). Our choice of output function (i.e., the raw logit of the classifier) allowed us to then cast the original (non-convex) learning problem of interest as an instance of binary logistic regression with inputs ∇ θ f (z; θ ). That is, we made the approximation</p><formula xml:id="formula_27">θ (S) ≈ arg min θ ∑ z i ∈S log 1 + exp -y i • ∇ θ f (z i ; θ ) θ + b i , (<label>18</label></formula><formula xml:id="formula_28">)</formula><p>and then leveraged Definition 3.1.</p><p>To apply this same approach to the c-class setting (for c &gt; 2), one possibility is to first transform the problem into c 2 binary classification problems, then apply the approach from Section 3.2 directly. (For example, Malladi et al. <ref type="bibr" target="#b66">[MWY+22]</ref> use this transformation to apply the neural tangent kernel to c-way classification problems.) In large-scale settings, however, it is often expensive or infeasible to study of all c 2 subproblems, e.g., ImageNet has c = 1000 classes.</p><p>We thus take a different approach. In short, we leverage the fact that we always have labels available (even for test examples) to reduce the multi-class classification problem to a single logistic regression. More specifically, for an example z = (x, y), we define the model output function</p><formula xml:id="formula_29">f (z; θ) := log p(z; θ) 1 -p(z; θ) , (<label>19</label></formula><formula xml:id="formula_30">)</formula><p>where p(z; θ) is the softmax probability assigned to the correct class.</p><p>A crucial property of the model output function ( <ref type="formula" target="#formula_29">19</ref>) is that it allows us to rewrite the loss function for c-way classification as</p><formula xml:id="formula_31">L(z; θ) = -log(p(z; θ)) (20) = log [1 + exp (-f (z; θ))] ,<label>(21)</label></formula><p>where the first line is the definition of cross-entropy loss, and the second line comes from (19). As a result, if we linearize f (z; θ) as in Step 1 above (Section 3.2), we can make the approximation</p><formula xml:id="formula_32">θ (S) ≈ arg min θ ∑ z i ∈S log 1 + exp -∇ θ f (z i ; θ ) θ + b i .</formula><p>This approximation is identical to the one we made for the binary case (see ( <ref type="formula" target="#formula_27">18</ref>)). We can thus treat the multi-class problem as a single binary logistic regression with inputs ∇ θ f (z i ; θ )<ref type="foot" target="#foot_9">9</ref> and then apply Steps 2-5 from Section 3.2 directly to this binary problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Implementing TRAK</head><p>We summarize our final algorithm for computing the data attribution method τ TRAK in the general multi-class case (see also Equation ( <ref type="formula" target="#formula_26">17</ref>)) in Algorithm 1. The output of the algorithm is an attribution matrix T, whose rows are given by τ TRAK (z, S). To make Algorithm 1 efficient even for very large models, we implemented a highly optimized random projector, which we discuss in Appendix B.</p><p>Algorithm 1 TRAK for multi-class classifiers (as implemented)</p><formula xml:id="formula_33">1: Input: Learning algorithm A, dataset S of size n, sampling fraction α ∈ (0, 1], correct-class likelihood function p(z; θ), projection dimension k ∈ N 2: Output: Matrix of attribution scores T ∈ R n×n 3: f (z; θ) := log( p(z;θ) 1-p(z;θ) ) Margin function f θ 4: for m ∈ {1, . . . , M} do 5: Sample random S ⊂ S of size α • n 6: θ m ← A(S )</formula><p>Train a model on S 7:</p><p>P ∼ N (0, 1) p×k Sample projection matrix 8:</p><formula xml:id="formula_34">Q (m) ← 0 n×n 9:</formula><p>for i ∈ {1, . . . , n} do 10:</p><formula xml:id="formula_35">φ i ← P ∇ θ f (z i ; θ m )</formula><p>Compute gradient at θ m and project to k dimensions 11:</p><formula xml:id="formula_36">Q (m) ii ← 1 -p(z i ; θ ) Compute weighting term 12:</formula><p>end for 13:</p><formula xml:id="formula_37">Φ m ← [φ 1 ; • • • ; φ n ] 14: end for 15: T ← 1 m M ∑ m=1 Φ m (Φ m Φ m ) -1 Φ m 1 m M ∑ m=1 Q (m) 16: return SOFT-THRESHOLD(T)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Evaluating TRAK</head><p>We now evaluate TRAK (see Equation ( <ref type="formula" target="#formula_26">17</ref>) and Algorithm 1 in Section 3.4) in a variety of vision and natural language settings. To this end, we compare TRAK with existing data attribution methods and show that it achieves significantly better tradeoffs between efficacy and computational efficiency.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experimental setup</head><p>We evaluate and study TRAK with the following experimental setup. Datasets, models, and baselines. We use ResNet-9 classifiers trained on the CIFAR dataset (CIFAR-10, and a two-class subset called CIFAR-2); ResNet-18 <ref type="bibr" target="#b41">[HZR+15]</ref> classifiers trained on the 1000-class ImageNet <ref type="bibr" target="#b73">[RDS+15]</ref> dataset, and pre-trained BERT [DCL+19] models finetuned on the QNLI (Question-answering Natural Language Inference) classification task from the GLUE benchmark <ref type="bibr" target="#b94">[WSM+18]</ref>. We provide further details on these choices of dataset and task in Appendix A.1.</p><p>To put TRAK's performance into context, we also evaluate a variety of existing attribution methods, including influence functions <ref type="bibr" target="#b50">[KL17]</ref>; a variant based on the Arnoldi iteration <ref type="bibr" target="#b86">[SZV+22]</ref>; TracIn <ref type="bibr" target="#b69">[PLS+20]</ref>; gradient aggregated similarity (GAS) <ref type="bibr" target="#b35">[HL22b]</ref>; representation similarity <ref type="bibr" target="#b39">[HYH+21]</ref>; empirical influences <ref type="bibr" target="#b26">[FZ20]</ref>; and datamodels <ref type="bibr" target="#b42">[IPE+22]</ref>. (See Appendix A.3 for more details.)</p><p>Evaluation with linear datamodeling scores. For each method and each dataset we consider, we compute its linear datamodeling score (LDS) as described in Definition 2.4. Specifically, let τ be a given data attribution method (as framed in Definition 2.1), and let g τ (z, S ; S) be its corresponding attribution-derived prediction function (see Definition 2.3). Then, to evaluate τ:</p><p>1. We sample 100 different random subsets {S j ⊂ S : j ∈ [100]} of the training set S, and train five models on each one of these subsets. Each subset S j is sampled to be 50% of the size of S, but we also consider other subsampling ratios in Appendix D.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2.</head><p>For each example of interest z (i.e., for each example in the test set of the dataset we are studying), we approximate the expectation of the model output E[ f (z; θ i (S j ))] for each training subset S j (where the expectation is taken over the learning algorithm's randomness) by averaging across the corresponding five models {θ i (S j )} 5 i=1 . 3. We then compute the linear datamodeling score for each example of interest z as the Spearman rank correlation <ref type="bibr" target="#b83">[Spe04]</ref> between the averaged model outputs computed in the previous step and the attribution-derived predictions g τ (z, S j ; S) of model outputs. That is, we compute:</p><formula xml:id="formula_38">Spearman-ρ 1 5 5 ∑ i=1 f (z; θ i (S j )) : j ∈ [100] averaged model outputs , {g τ (z, S j ; S) : j ∈ [100]}</formula><p>attributed-derived predictions of model outputs 4. Finally, we average the LDS (Definition 2.4) across 2,000 examples of interest, sampled uniformly at random from the validation set, and report this score along with the 95% bootstrap confidence intervals corresponding to the random re-sampling from the subsets S j .</p><p>Computational cost. We quantify the computational cost of each attribution method using two metrics. The first one is the total wall-time of computing attribution scores on a single A100 GPU. This metric is intuitive and useful, but depends on implementation details and hardware. We thus also study a second metric, namely, the total number of trained models used. This metric is hardware and implementation-agnostic; it is motivated by an observation that for large models, the time it takes to compute attribution scores will be dominated by the time it takes to train the models needed for attribution. <ref type="foot" target="#foot_10">10</ref> We find that for both metrics, our results lead to similar conclusions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Results</head><p>Across all models and datasets that we consider, TRAK attains a significantly better tradeoff between efficacy (as measured by the LDS) and computational efficiency than all the other attribution methods that we examine (see Figures <ref type="figure" target="#fig_11">1</ref> and<ref type="figure">2</ref> and Table <ref type="table">D</ref>.2). Indeed, TRAK attains efficacy comparable to datamodels (which achieves the best performance among existing methods when unconstrained) with a computational footprint that is (on average) over 100x smaller.  Understanding the roots of TRAK's performance. In Appendix E, we study the roots of TRAK's performance through an extensive ablation study. We vary, for example, how we linearize the model of interest (Step 1 in Section 3.2), the dimension k of the random projection we use (Step 2 in Section 3.2), how we apply the Newton step attribution from Definition 3.1 (Step 3 in Section 3.2), and how we aggregate information from independently trained models (Step 4 in Section 3.2). As a byproduct of this investigation, we find two ways of computing TRAK at even lower cost: (a) leveraging models that have not been trained to convergence, and (b) taking advantage of multiple checkpoints from the same model, rather than multiple models from independent training runs. We find (see Tables <ref type="table">5</ref> and<ref type="table">6</ref>, explained further and reproduced in Appendix E) that both of these optimizations can dramatically reduce TRAK's computational cost without significantly degrading its performance. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head># training epochs</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Applications of TRAK</head><p>In Section 4, we evaluated our data attribution method TRAK on standard image classification and NLP tasks and compared its performance to existing attribution methods. We now illustrate the usefulness of TRAK through three additional applications:</p><p>Attributing CLIP models. In Section 5.1, we use TRAK to study image-text embeddings of models trained with the CLIP contrastive loss <ref type="bibr" target="#b74">[RKH+21]</ref>. In particular, we show how leveraging TRAK allows us to identify small subsets of the training set that, when removed, cause the resulting CLIP embeddings to fail to capture a given image-caption pair association.</p><p>Fact tracing language models. Next, in Section 5.2, we use TRAK to provide data attribution for language models <ref type="bibr" target="#b90">[VSP+17]</ref>. Accelerating datamodel applications. Finally, in Section 5.3, we use TRAK to accelerate two downstream applications that leverage datamodel scores. That is, first, we look at the problem of estimating prediction brittleness using datamodel scores <ref type="bibr" target="#b42">[IPE+22]</ref>. Then, we revisit the MODELDIFF algorithm <ref type="bibr" target="#b84">[SPI+22]</ref>, which leverages datamodel scores for learning algorithm comparison, i.e., the task of distinguishing two learning algorithms based on feature priors they instill. For both applications, using TRAK scores in place of datamodel scores reduces the total computational cost by at least a factor of 100 while retaining the same effectiveness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Attributing CLIP models</head><p>Recent works have found that one can leverage natural language supervision to help models learn a rich joint image-text embedding space. In particular, CLIP (Contrastive Language-Image Pre-training) <ref type="bibr" target="#b74">[RKH+21]</ref> representations have become a versatile primitive bridging visual and language domains and is used, for example, for zero-shot classification <ref type="bibr" target="#b74">[RKH+21]</ref> and as text encoders for latent diffusion models <ref type="bibr" target="#b72">[RBL+22]</ref>. While the quality of these representations-as measured by aggregate metrics such as downstream zero-shot accuracy-appears to be driven largely by the properties and scale of the training datasets [FIW+22; SDT+22; CBW+22], we lack a fine-grained understanding of how the composition of the training data contributes to learning well-aligned representations. To that end, we use TRAK to investigate how training data influences the resulting CLIP embeddings at a local level. That is, we want to be able to pin-point training examples that cause a model to learn a given specific image-caption pair association.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.1">Computing TRAK for CLIP</head><p>Similarly to the classification setting we were considering so far, we need to first choose an appropriate model output function (see, e.g., Equation ( <ref type="formula" target="#formula_29">19</ref>)) to compute attribution scores with TRAK. This choice will be motivated by the CLIP training loss (which we review below) and will reduce our setting back to the classification case.</p><p>The CLIP loss. A CLIP model with parameters θ takes in an image-caption pair (x, y) and outputs an image embedding φ(x; θ) and a text embedding ψ(y; θ). Given a (random) batch of training examples B = {(x 1 , y 1 ), ..., (x n , y n )}, the CLIP training loss computes all n × n pairwise cosine similarities between the image and text embeddings</p><formula xml:id="formula_39">S ij := φ(x i ; θ) • ψ(y j ; θ),</formula><p>and aims to maximize the cosine similarities S ii of correct pairs while minimizing the cosine similarities S ij , for i = j, of incorrect pairs. More specifically, the training loss of example (x i , y i ) ∈ B is defined as the following symmetric cross entropy over the similarity scores S ij :</p><formula xml:id="formula_40">L(x i , y i ; θ) = -log exp(S ii ) ∑ 1≤j≤n exp(S ij ) -log exp(S ii ) ∑ 1≤j≤n exp(S ji ) , (<label>22</label></formula><formula xml:id="formula_41">)</formula><p>where the first term corresponds to matching each image x i to its correct caption y i , and the second term corresponds to matching each caption to its correct image. In effect, we are solving two classification problems: one where the images are inputs and captions (from the same batch) are labels, and vice versa.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Reducing to classification.</head><p>Recall that in the classification setting we trained the model with the cross entropy loss (i.e.,log p(z; θ), where p(z; θ) is the correct-class probability), and used the model output function f (z; θ) = log p(z; θ)/(1p(z; θ)) (Equation ( <ref type="formula" target="#formula_29">19</ref>)), i.e., the logit transform of the correct-class probability to compute TRAK scores.</p><p>To take advantage of the same formula in the CLIP setting, note that our loss (22) can be viewed as having the form</p><formula xml:id="formula_42">L(x i , y i ; θ) = -log p 1 (x i , y i ; θ) -log p 2 (x i , y i ; θ),</formula><p>where p 1 (x i , y i ; θ) corresponds to the probability of matching an image to its corresponding caption based on the cosine similarity, and likewise for p 2 (x i , y i ; θ). A natural choice of model output function in this case, then, is using the sum of the model output functions corresponding to the two classification problems:</p><formula xml:id="formula_43">f (x i , y i ; θ) := log p 1 (x i , y i ; θ) 1 -p 1 (x i , y i ; θ) + log p 2 (x i , y i ; θ) 1 -p 2 (x i , y i ; θ) = -log ∑ 1≤j≤n exp(S ij -S ii ) -log ∑ 1≤j≤n exp(S ji -S ii ).</formula><p>Indeed, this choice allows us once again (see Section 3.3) to reduce our problem to an instance of logistic regression and apply the same formula for influence approximation (Definition 3.1) as before. We can then also compute TRAK scores following the same approach (i.e., using Algorithm 1 in Section 3.4). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.2">Results</head><p>We train image-text models (with a ResNet-50 <ref type="bibr" target="#b41">[HZR+15]</ref> as the image encoder and a Transformer <ref type="bibr" target="#b90">[VSP+17]</ref> as the text encoder) using the CLIP objective on MS COCO <ref type="bibr" target="#b58">[LMB+14]</ref>. To evaluate the effectiveness of TRAK applied to such CLIP models, we perform a qualitative (visual) analysis; and a quantitative (counterfactual) evaluation. In both cases, we compare TRAK with TracIn and CLIP similarity distance<ref type="foot" target="#foot_11">11</ref> baselines.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Visual analysis. Figure 7 displays two target examples of interest along with the corresponding</head><p>training examples having the highest attribution scores (according to TRAK and CLIP similarity distance-see Appendix D.3 for the analysis corresponding to TracIn). For the first example, the nearest neighbor in the CLIP space (the polar bear) turns out to have a negative attribution score according to TRAK. For the second example, the most helpful TRAK examples are the ones for which the captions contain the phrase "a couple of animals" but where the images do not necessarily feature giraffes (possibly because the target caption does not mention "giraffe" either). On the other hand, the most helpful examples according to CLIP similarity distance all feature giraffes. These differences suggest that TRAK attribution scores may capture significantly different traits from CLIP similarity distance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Counterfactual evaluation. We next investigate to what extent training examples identified by</head><p>each attribution method affect the CLIP model's ability to learn a given image-caption association. Specifically, we say that a CLIP model has learned a given association between an image and a caption whenever their corresponding image and caption embeddings have high cosine similarity relative to other image-caption pairs. To evaluate each attribution method (i.e., TRAK, TracIn, and CLIP similarity distance), for a given target image-caption pair, we remove from the training set the k examples with the most positive attribution scores a given attribution method produces, and then re-train a model from scratch (averaging over ten training runs to reduce stochasticity). Finally, we examine the decrease in cosine similarity between the embeddings of target image and caption pair, and average this result over different target pairs. Our results (Figure <ref type="figure" target="#fig_3">8</ref>) indicate that removing training inputs identified by TRAK can significantly degrade the model's ability to learn the target image-caption pair. Indeed, removing just k = 400 target-specific training puts (i.e., less than 0.5% of the train set) decreases the (average) CLIP similarity distance between the target image and caption embeddings by 0.36. In contrast, removing the same number of nearest neighbors in CLIP space results in a much smaller effect size (a 0. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Fact tracing for large language models (mT5)</head><p>As large language models are deployed in a variety of contexts, e.g., as conversation agents <ref type="bibr" target="#b88">[TDH+22]</ref> or knowledge bases <ref type="bibr" target="#b71">[PRR+19]</ref>, there is an emerging need to be able to attribute models' outputs back to specific data sources <ref type="bibr" target="#b14">[BTV+22]</ref>. To that end, we study fact tracing [ABL+22], i.e., the task of identifying the training examples that cause a language model to generate a given "fact."</p><p>A benchmark for fact tracing. Akyurek et al. <ref type="bibr" target="#b1">[ABL+22]</ref> develop a testbed for the fact tracing problem by way of a dataset (and corresponding evaluation methodology) called FTRACE-TREX. We provide a high-level overview of FTRACE-TREX here, and describe it in more depth in Appendix F.1. The FTRACE-TREX dataset consists of a set of "abstracts" and a set of "queries," both of which pertain to the same database of "facts." Akyurek et al. <ref type="bibr" target="#b1">[ABL+22]</ref> annotate each abstract with a set of facts it expresses, and each query with the (single) fact that it asks about. As a part of the task setup, one finetunes a pre-trained language model on the set of abstracts using masked language modeling,<ref type="foot" target="#foot_12">12</ref> and then evaluates this model's correctness on each query in the query set. This step defines a set of "novel facts," i.e., queries that the model answers correctly only after finetuning.</p><p>With the above setup in place, we can define the FTRACE-TREX fact tracing benchmark. Akyurek et al. <ref type="bibr" target="#b1">[ABL+22]</ref> reason that each novel fact (as identified above) should have been learned (during finetuning) from the abstracts that express the same fact. The benchmark thus evaluates a given data attribution method's ability to retrieve, for each novel fact, the abstracts in the training set that express the same fact. (Such abstracts are called the ground-truth proponents of the query.)</p><p>In particular, observe that applying a data attribution method τ(•) to a particular query (treating the set of abstracts as the training set) yields scores that we can use as a ranking over the set of the abstracts. Akyurek et al. <ref type="bibr" target="#b1">[ABL+22]</ref> compute the mean reciprocal rank (MRR) of the ground-truth proponents in this ranking (see Appendix F.1), a standard metric from information retrieval, to quantify the efficacy of τ(•) at fact tracing. We evaluate TRAK on this benchmark, along with two baselines from <ref type="bibr" target="#b1">[ABL+22]</ref>, TracIn <ref type="bibr" target="#b69">[PLS+20]</ref> and the information retrieval method BM25 <ref type="bibr" target="#b78">[RWJ+95]</ref>.</p><p>Computing TRAK scores for language models. To apply TRAK to this setting, we need to choose an appropriate model output function, as we did before for the classification setting (see Section 3.3) and for CLIP (see Section 5.1). To this end, we observe that the masked language modeling objective has a natural interpretation as a sequence of v-way classification problems over the masked tokens, where v is the vocabulary size. Thus, inspired by our analysis of the multi-class classification setting from Section 3.3, we choose the model output function for this setting to be the sum of the "canonical" model output function (19) for each of the v-way classification problems (see Appendix F.3 for more details).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.1">Results and discussion</head><p>We find that while TRAK significantly outperforms TracIn on the FTRACE-TREX benchmark (0.42 vs. 0.09 using the aforementioned MRR score), neither method matches the performance of the information retrieval baseline BM25 (0.77 MRR). <ref type="foot" target="#foot_13">13</ref>To understand the possible roots of TRAK's underperformance relative to BM25 on FTRACE-TREX, we carry out a counterfactual analysis. <ref type="foot" target="#foot_14">14</ref> Specifically, for a subset S of the FTRACE-TREX query set, we create three corresponding counterfactual training sets. Each such training set corresponds to removing one of three collections of abstracts from the FTRACE-TREX abstract set:</p><p>(a) the most important abstracts for model performance on S , as estimated by TRAK;</p><p>(b) the abstracts that are most similar to the queries in S according to BM25;</p><p>(c) the corresponding "ground-truth proponents" for the queries in S as per FTRACE-TREX.</p><p>We then measure the average decrease in performance on S when a model is finetuned on these counterfactual datasets compared finetuning on the full training set. Intuition would suggest that performance would decrease the most when models are trained on the counterfactual training set (c); in particular, there is ostensibly no direct evidence for any of the facts corresponding to the queries in S anywhere in that set.</p><p>We find (see Figure <ref type="figure" target="#fig_4">9</ref>), however, that it is only the TRAK-based counterfactual training set that causes a large change in model behavior. That is, removing abstracts identified with TRAK leads to a 34% decrease in accuracy, significantly more than the decreases induced by removing abstracts according to BM25 (10%) or even removing ground-truth proponents (12%). Discussion. Our results demonstrate that while TRAK may not be effective at identifying abstracts that directly express the same fact as a given query (i.e., the ground-truth proponents as defined by FTRACE-TREX), it can successfully identify the abstracts that are most responsible for the finetuned model learning a given fact. In particular, TRAK's subpar performance on the attribution benchmark is an artifact of the FTRACE-TREX benchmark rather than a flaw of TRAK itself.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ground</head><p>There are several potential explanations for this phenomenon, many of which Akyurek et al.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>[ABL+22] already discuss in their work:</head><p>• There may be errors in the FTRACE-TREX benchmark. (Although, given the drastic difference between the TRAK scores and the ground-truth labels in their ability to identify counterfactually important abstracts, such data errors are unlikely to be the sole culprit.)</p><p>• Models may be answering queries by combining facts from the training set. For example, neither "The largest pyramid is in Giza" nor "Giza is a city in Egypt" would be ground-truth proponents for the query "Which country is home to the largest pyramid?" in FTRACE-TREX, but a model that learns both of these facts may still be able to correctly answer that query.</p><p>• Alternatively, models may be learning from the syntactic rather than semantic structure of abstracts. For example, a model may correctly answer that a person from Korea is called a "Korean" by learning from an abstract which says "A person from Bulgaria is Bulgarian."</p><p>More broadly, our results highlight a difference between fact tracing and behavior tracing. In other words, finding a data source that supports a given model-generated text is a different task than identifying the actual data sources that caused the model to generate this text in the first place. While we may be able to address the former problem with model-independent techniques such as information retrieval or web search, the latter requires methods that remain faithful to (and thus, dependent on) the model being studied. Our results here indicate that TRAK can be an effective tool for the latter problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Accelerating datamodel applications</head><p>Our evaluation thus far has demonstrated that data attribution scores computed with TRAK can predict how a given model's output changes as a function of the composition of the corresponding model's training set. While the capability to make such predictions is useful in its own right, prior work has shown that this primitive also enables many downstream applications [KL17; JDW+19; AV20]. For example, prior works leverage datamodel scores to identify brittle predictions <ref type="bibr" target="#b42">[IPE+22]</ref> and to compare different learning algorithms <ref type="bibr" target="#b84">[SPI+22]</ref>. We now show that using TRAK in place of datamodel scores can significantly speed up these downstream applications too.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.1">Estimating prediction brittleness</head><p>Ilyas et al. <ref type="bibr" target="#b42">[IPE+22]</ref> use datamodel scores to provide lower bounds on the brittleness of a given example-that is, given an example of interest z, they identify a subset of the training set whose removal from the training data causes the resulting re-trained model to misclassify z. The brittleness estimation algorithm that Ilyas et al. <ref type="bibr" target="#b42">[IPE+22]</ref> leverage hinges on the fact that the datamodel attribution function τ DM (z) can accurately predict model outputs, i.e., achieve high LDS. Motivated by TRAK's good performance on the linear datamodeling task (see, e.g., Figure <ref type="figure">2</ref>), we examine estimating the brittleness of CIFAR-10 examples using TRAK scores in place of datamodel ones (but otherwise following the procedure of Ilyas et al. <ref type="bibr" target="#b42">[IPE+22]</ref>). Our results (see Figure <ref type="figure" target="#fig_5">10</ref>) indicate that TRAK scores computed from an ensemble of just 100 models are about as effective at estimating brittleness as datamodel scores computed from 50,000 models. Thus, TRAK scores can be a viable (and orders of magnitude faster) alternative to datamodels for estimating prediction brittleness. The number of models used by each attribution method is specified in parentheses, e.g., TRAK (100) indicates that TRAK scores were computed using an ensemble of 100 trained models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.2">Learning algorithm comparisons</head><p>A useful way to leverage datamodels is to view them as data representations. More specifically, following Ilyas et al. <ref type="bibr" target="#b42">[IPE+22]</ref>, for an example of interest z, one can view the datamodel attribution τ DM (z) as an embedding of z into R n , where n is the size of the training dataset. Analyzing examples in such induced datamodel representation spaces turns out to enable uncovering dataset biases and model-specific subpopulations <ref type="bibr" target="#b42">[IPE+22]</ref>. Furthermore, this representation space is not specific to a particular model instance or architecture-it is globally aligned in the sense that for the same example z, the attribution score τ DM (z) i of a given train example i has a consistent interpretation across different learning pipelines. Shah et al. <ref type="bibr" target="#b84">[SPI+22]</ref> leverage the properties of the datamodel representation space to perform model-agnostic learning algorithm comparison (called MODELDIFF): given two learning algorithms, they show how to use datamodels to identify distinguishing features, i.e., features that are used by one learning algorithm but not the other.</p><p>Once again, motivated by TRAK's good performance on the LDS metric, we investigate whether TRAK scores can substitute for datamodel scores in this context. To this end, we revisit one of the case studies from Shah et al. <ref type="bibr" target="#b84">[SPI+22]</ref>-the one that compares image classifiers trained with and without data augmentation, and identifies features that distinguish these two classes of models. When applied to this case study, MODELDIFF computed with TRAK scores recovers similar distinguishing features to the ones originally found by Shah et al. <ref type="bibr" target="#b84">[SPI+22]</ref> (using datamodel scores)-see Figure <ref type="figure">D</ref>.6 for more details. Also, employing TRAK scores in place of datamodel scores reduces the total computational cost by a factor of 100, showing, once again, that TRAK can dramatically accelerate downstream tasks that rely on accurate attribution scores.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Related work</head><p>In this section, we highlight and discuss how TRAK connects to prior works on training data attribution, the neural tangent kernel, and kernel approximation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Training data attribution.</head><p>There is a sizable body of work on data attribution methods. Here we discuss approaches most similar to ours, but we refer the reader back to Section 2 for an overview of prior work on data attribution methods and to <ref type="bibr" target="#b35">[HL22b]</ref> for an even more extensive survey.</p><p>In the setting of generalized linear models, Wojnowicz et al. <ref type="bibr" target="#b91">[WCZ+16]</ref> speed up classical influence estimation (Definition 3.1) by leveraging random projections. Also, Khanna et al. <ref type="bibr" target="#b49">[KKG+19]</ref> employ a similar estimator based on the Fisher matrix for data attribution and subset selection. Their experiments are limited though to small neural networks and linear models. Most similarly to our approach, Achille et al. <ref type="bibr" target="#b5">[AGR+21]</ref> leverage the linearized model for approximating influence functions (among other applications). However, their approach introduces several changes to the model of interest (such as modifying activations, loss, and regularization) and focuses on finetuning in smaller-scale settings, whereas TRAK can be applied directly to the original model (and at scale).</p><p>Similarly to us, prior works also investigate the tradeoffs between scalability and efficacy of data attribution methods. For instance, Jia et al. <ref type="bibr" target="#b47">[JWS+21]</ref> study these tradeoffs by proposing new metrics and comparing according to them leave-one-out methods (e.g., influence functions) and Shapley values. They put forth, in particular, a new estimator for Shapley values that is based on approximating the original model with a k-nearest neighbors model over the pre-trained embeddings-this can be viewed as an alternative to working with the linearized model.</p><p>As discussed in Section 2, a major line of work uses Hessian-based influence functions for data attribution [KL17; KAT+19; BPF21]. In particular, the influence function effectively computes-up to an error that can be bounded-the one-step Newton approximation with respect to the full model parameters <ref type="bibr" target="#b48">[KAT+19]</ref>. Recall that TRAK also leverages the one-step Newton approximation in order to estimate leave-one-out influences for logistic regression (see Section 3). However, in contrast to the influence function approach, the Hessian matrix we leverage (the matrix X RX in Definition 3.1) is positive semi-definite as it is computed with respect to the linearized model rather than the original model. As a result, computing TRAK does not require the use of additional regularization (beyond the one implicitly induced by our use of random projections), which is practically necessary in the influence function approach. Prior works also leverage a similar Hessian matrix based on the generalized Gauss-Newton matrix <ref type="bibr" target="#b12">[BNL+22]</ref> or the equivalent Fisher information matrix <ref type="bibr" target="#b87">[TBG+21]</ref>, which are guaranteed to be positive semi-definite.</p><p>Neural tangent kernel. The neural tangent kernel (NTK) <ref type="bibr" target="#b45">[JGH18]</ref> and its generalizations <ref type="bibr" target="#b97">[YL21]</ref> are widely studied as a tool for theoretically analyzing generalization <ref type="bibr" target="#b4">[ADH+19]</ref>, optimization <ref type="bibr" target="#b93">[WLL+19]</ref>, and robustness [GCL+19] of (overparameterized) neural networks. While these works focus on neural networks in the their large or infinite-width limit, a line of recent works [MLL20; AGR+21; Lon21; ABP22; WHS22; MWY+22; ABS+23; MGF22] studies instead the finite-width empirical NTK (eNTK). Our TRAK estimator is partly motivated by the observation from this line of work that kernel regression with the eNTK provides a good approximation to the original model.</p><p>While we leverage the eNTK approximation for data attribution, prior works leveraged the NTK and eNTK for various other applications, such as studying generalization <ref type="bibr" target="#b8">[BHL22]</ref>, sample selection for active learning <ref type="bibr" target="#b40">[HZK+22]</ref>, model selection <ref type="bibr" target="#b20">[DAR+21]</ref>, federated learning <ref type="bibr" target="#b98">[YWK+22]</ref>, and fast domain adaptation <ref type="bibr" target="#b65">[MTM+21]</ref>. Our reduction to the linear case (Step 1 in Section 3.2) is analogous to the approach of Bachmann et al. <ref type="bibr" target="#b8">[BHL22]</ref> that leverages formulas for the leave-one-out error of kernel methods coupled with the NTK approximation to estimate the generalization error. Another related work is that of Zhang and Zhang <ref type="bibr" target="#b101">[ZZ22]</ref>, who theoretically characterize the accuracy of the Hessian-based influence function in the NTK regime (i.e., large-width limit).</p><p>Finally, although the work on NTK popularized the idea of leveraging gradients as features, similar ideas can be traced back to works on the Fisher kernel and related ideas <ref type="bibr" target="#b99">[ZDS17]</ref>.</p><p>Kernel methods and random projections. Our application of random projections to improve computational efficiency of kernel approximation is a widely used idea in kernel methods <ref type="bibr" target="#b10">[Blu06;</ref><ref type="bibr" target="#b76">RR07]</ref>. Aside from computational advantages, this technique can also provide insight into empirical phenomena. For example, Malladi et al. <ref type="bibr" target="#b66">[MWY+22]</ref> use the kernel view along with random projections as a lens to explain the efficacy of subspace-based finetuning methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Discussion &amp; Conclusion</head><p>In our work, we formalize the problem of data attribution and introduce a new method, TRAK, that is effective and efficiently scalable. We then demonstrate the usefulness of TRAK in a variety of large-scale settings: image classifiers trained on CIFAR and ImageNet, language models (BERT and mT5), and image-text models (CLIP).</p><p>Still, TRAK is not without limitations: in particular, it requires the model to be differentiable, and its effectiveness also depends on the suitability of the linear approximation. That said, the success of the applying the NTK on language modeling tasks <ref type="bibr" target="#b66">[MWY+22]</ref> as well as our own experiments both suggest that this approximation is likely to continue to work for larger models. TRAK presents a unique opportunity to reap the benefits of data attribution in previously untenable domains, such as large generative models. In Appendix G, we further discuss possible avenues for future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Experimental Setup</head><p>A.1 Datasets and models CIFAR. We construct the CIFAR-2 dataset as the subset of CIFAR-10 [Kri09] consisting of only the "cat" and "dog" classes. We initially used CIFAR-2 as the main test bed when designing TRAK, as it is a binary classification task and also smaller in size. On both CIFAR-2 and CIFAR-10, we train a ResNet-9 architecture. <ref type="foot" target="#foot_15">15</ref> For CIFAR-2, we use (max) learning rate 0.4, momentum 0.9, weight decay 5e-4, and train for 100 epochs using a cyclic learning rate schedule with a single peak at epoch 5. For CIFAR-10, we replace the learning rate with 0.5 and train for 24 epochs.</p><p>Our code release includes a notebook<ref type="foot" target="#foot_16">16</ref> that can reproduce the CIFAR-2 results end-to-end.</p><p>ImageNet. We use the full 1000-class ImageNet dataset and train a modified ResNet-18 architecture. Models are trained from scratch for 15 epochs, cyclic learning rate with peak at epoch 2 and initial learning rate 5.2, momentum 0.8, weight decay 4e-5, and label smoothing 0.05.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>QNLI.</head><p>We finetune a pre-trained BERT model (bert-base-cased<ref type="foot" target="#foot_17">17</ref> ) on the QNLI (Questionanswering Natural Language Inference) task from the GLUE benchmark. We use the default training script<ref type="foot" target="#foot_18">18</ref> from HuggingFace with a few modifications: we use SGD (20 epochs, learning rate starting at 1e-3) instead of AdamW, and we remove the last tanh non-linearity before the classification layer. Removing the last non-linearity prevents the model outputs in saturating, resulting in higher LDS. (That said, we find that TRAK scores can be still computed on the models with non-linearity; this was only for improving evaluation.) We restrict the training set to 50,000 examples, approximately half of the full training set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CLIP on MS COCO.</head><p>We use an open-source implementation <ref type="foot" target="#foot_19">19</ref> of CLIP. The model uses a ResNet-50 for the image encoder and a Transformer for the text encoder (for captions). We train for 100 epochs using the Adam optimizer with batch size 600, a cosine learning rate schedule with starting learning rate 0.001, weight decay 0.1, and momentum 0.9. All images are resized to a resolution of 224 × 224. We use random resize crop, random horizontal flip, and Gaussian blur as data augmentations.</p><p>In the counterfactual evaluation, we consider a normalized notion of cosine similarity, r = r/(r 95r 5 ), where r is the raw correlation between image and caption embeddings and r α is the α-percentile of image-caption similarities across the entire dataset. Results remain similar with other choices of metric.</p><p>Fact tracing mT5 on FTRACE-TREX. We follow the setup exactly as in Akyurek et al. <ref type="bibr" target="#b1">[ABL+22]</ref> as we describe in Section 5.2, other than using a smaller architecture (mt5-small). See Appendix F for more details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MODELDIFF on LIVING17. The LIVING17 dataset [STM21] is an image classification dataset derived from the ImageNet dataset and consists of 17 classes, each comprised of four original ImageNet classes.</head><p>We train the standard ResNet-18 architecture on the above dataset, either using standard data augmentation (random resized cropping and random horizontal flips) or with no data augmentation (only center cropping, same as used on when evaluating). The goal of the case study from Shah et al. <ref type="bibr" target="#b84">[SPI+22]</ref> is to distinguish the above two learning algorithms in terms of the feature priors of the resulting trained models. To run MODELDIFF, follow the setup in Shah et al. <ref type="bibr" target="#b84">[SPI+22]</ref> exactly; we refer to the work for more details of the case study and implementation details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 TRAK hyperparameters</head><p>TRAK only has two hyperparmeters: the projection dimension k and the number of models M. The following hyperparameters were used unless specified otherwise: </p><formula xml:id="formula_44">Dataset</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Soft-thresholding.</head><p>An optional hyperparameter is needed if we use soft-thresholding (Step 5).</p><p>Among the four tasks we evaluate the LDS on, we find that soft-thresholding is only helpful for the non-binary classification tasks (i.e., CIFAR-10 and ImageNet, but not CIFAR-2 and QNLI); intuitively, this may be due to the fact that the underlying model output function depends on fewer examples (i.e., the attribution vector is sparser) when there are more classes.</p><p>For both CIFAR-10 and ImageNet, we use a single sparsity threshold-i.e., for each test example, we choose the soft-thresholding parameter λ s.t. the resulting TRAK score vector has exactly k nonzero entries, and use the same k for all test examples. To choose k, for CIFAR-10 we cross-validate using the same M models that we used to compute TRAK scores, when M ≥ 20; in other words, we avoid "cheating" by using additional models for cross-validation. For ImageNet, we simply choose k = 1000 since there are on average 1,300 training examples per class.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3 Baselines</head><p>We provide details on baselines used in our evaluation in Section 4. Though most of the existing approximation-based methods only use a single model checkpoint in their original formulation, we average the methods over multiple independent checkpoints to help increase its performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Influence functions. The standard Hessian-based influence functions yield the attribution scores</head><formula xml:id="formula_45">τ(z j ) i = ∇L(z j ; θ ) H -1 θ ∇L(z i ; θ ),</formula><p>where H θ is the empirical Hessian w.r.t. the training set. We use an existing PyTorch implementation<ref type="foot" target="#foot_20">20</ref> that uses the stochastic approximation of inverse-Hessian-vector products using the LISSA [ABH17] algorithm as done in Koh and Liang <ref type="bibr" target="#b50">[KL17]</ref>. As in the original work, we compute the gradients only with respect to the last linear layer; using additional layers caused the inversion algorithm to either diverge or to run out of memory. For hyperparameters, we use similar values as done in prior work; we use r = 1, d = 5000, and damping factor of 0.01. We find that additional repeats (r, the number of independent trials to average each iHvp estimate) does not help, while increasing the depth (d, the number of iterations used by LISSA) helps significantly.</p><p>Influence functions based on the Arnoldi iteration. This variant of influence functions from Schioppa et al. <ref type="bibr" target="#b86">[SZV+22]</ref> is based on approximating the top eigenspace of the Hessian using the Arnoldi iteration <ref type="bibr" target="#b6">[Arn51]</ref>. We use the original implementation in JAX. <ref type="foot" target="#foot_21">21</ref> We normalize the gradients as recommended in the original paper. While much faster than the original formulation in Koh and Liang <ref type="bibr" target="#b50">[KL17]</ref>, we find that the attribution scores not very predictive (according to the LDS).</p><p>TracIn. We use the TracInCP estimator from <ref type="bibr" target="#b69">[PLS+20]</ref>, defined as</p><formula xml:id="formula_46">τ(z j ) i = T ∑ t=1 η t • ∇L(z j ; θ t ) • ∇L(z i ; θ t ),</formula><p>where θ t is the checkpoint from the epoch t and η t is the corresponding learning rate η t . We also average over trajectories of multiple independently trained models, which increases its performance. We approximate the dot products using random projections of dimensions 500-1000 as we do for TRAK, as the estimator is intractable otherwise. We found that increasing the number of samples (epochs) from the training trajectory does not lead to much improvement.</p><p>Gradient Aggregated Similarity (GAS). This is a "renormalized" version of the TracInCP <ref type="bibr" target="#b35">[HL22b]</ref> based on using the cosine similarity instead of raw dot products. In general, its performance is indistinguishable from that of TracIn.</p><p>Representation similarity. We use the signed 2 dot product in representation space (feature embeddings of the penultimate layer), where the sign indicates whether the labels match. We also experimented with cosine similarity but the resulting performance was similar.</p><p>Empirical influences. We use the subsampling-based approximation to leave-one-out influences as used by <ref type="bibr" target="#b26">[FZ20]</ref>, which is a difference-in-means estimator given by</p><formula xml:id="formula_47">τ(z j ) i = E S z i f (z j ; θ) -E S z i f (z j ; θ)</formula><p>where the first (second) expectation is over training subsets that include (exclude) example z i .</p><p>Datamodels. We use the 1 -regularized regression-based estimators from Ilyas et al. <ref type="bibr" target="#b42">[IPE+22]</ref>, using up to 60,000 models for CIFAR-2 and 300,000 models for CIFAR-10 (trained on different random 50% subsets of the full training set).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.4 Hardware and wall-time measurements</head><p>For all of our experiments, we use NVIDIA A100 GPUs each with 40GB of memory and 12 CPU cores. We evaluate the computational cost of attribution methods using two metrics, total wall-time and the total number of trained models used; see Section 4 for motivation behind these metrics. For most attribution methods, one or more of the following components dominate their total runtime:</p><p>• TRAIN_TIME: the time to train one model (from scratch)</p><p>• GRAD_TIME: the time to compute gradients of one model (including computing random projections) for the entire dataset under consideration (both train and test sets). This time may vary depending on size of the projection dimension, but our fast implementation (Appendix B) can handle dimensions of up to 80,000 without much increase in runtime.</p><p>The total compute time for each method was approximated as follows, where M is the number of models used:</p><p>• TRAK: M × (TRAIN_TIME + GRAD_TIME), as we have to compute gradients for each of the trained models.</p><p>• Datamodel [IPE+22] and Empirical Influence [FZ20]: M × TRAIN_TIME. The additional cost of estimating datamodels or influences from the trained models (which simply involves solving a linear system) is negligible compared to the cost of training.</p><p>• LISSA based influence functions [KL17]: These approaches are costly because they use thousands of Hessian-vector product iterations to approximate a single inverse-Hessianvector product (which is needed for each target example). Hence, we computed these attribution scores for a much smaller sample of validation set (50 to 100). We measured the empirical runtime on this small sample and extrapolated to the size of the entire (test) dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>• Influence function based on the Arnoldi iteration [SZV+22]:</head><p>We ran the authors' original code<ref type="foot" target="#foot_22">22</ref> on CIFAR models of the same architecture (after translating them to JAX) and measured the runtime.</p><p>• TracIn [PLS+20] and GAS [HL22a]: M × (TRAIN_TIME + GRAD_TIME × T), where T is the number of checkpoints used per model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B TRAK implementation</head><p>We release an easy-to-use library, trak,<ref type="foot" target="#foot_23">23</ref> , which computes TRAK scores using Algorithm 1. Computing TRAK involves the following four steps: (i) training models (or alternatively, acquiring checkpoints), (ii) computing gradients, (iii) projecting gradients with a random projection matrix (Rademacher or Gaussian), and (iv) aggregating into the final estimator (Equation (15)).</p><p>Step (i) is handled by the user, while steps (ii)-(iv) are handled automatically by our library.</p><p>Step (ii) is implemented using the functorch library to compute per-example gradients. Step (iii) is either implemented using matrix multiplication on GPU or by a faster custom CUDA kernel, which is described below. Step (iv) just involves a few simple matrix operations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.1 Fast random projections on GPU</head><p>One of the most costly operation of TRAK is the random projection of the gradients onto a smaller, more manageable vector space. While CPUs are not equipped to handle this task on large models (e.g., LLMs) at sufficient speed, at least on paper, GPUs have more than enough raw compute.</p><p>In practice, however, challenges arise. First, storing the projection matrix entirely is highly impractical. For example, a matrix for a model with 300 million weights and an output of 1024 dimensions would require in excess of 1TB of storage. One solution is to generate the projection in blocks (across the output dimension). This solution is possible (and offered in our implementation) but is still radically inefficient. Indeed, even if the generation of the matrix is done by block it still has to be read and written once onto the GPU RAM. This severely limits the performance as memory throughput becomes the bottleneck.</p><p>Our approach. Our solution is to generate the coefficients of the projection as needed (in some situations more than once) and never store them. As a result, the bandwidth of the RAM is solely used to retrieve the values of the gradients and write the results at the end. This forces us to use pseudo-randomness but this is actually preferrable since a true random matrix would make experiments impossible to reproduce exactly.</p><p>Our implementation is written in C++/CUDA and targets NVIDIA GPUs of compute capability above or equal 7.0 (V100 and newer). It supports (and achieve better performance) batches of multiple inputs, and either normally distributed coefficients or -1, 1 with equal probabilities. Implementation details. We decompose the input vectors into K blocks, where each block is projected independently to increase parallelism. The final result is obtained by summing each partial projection. To reduce memory usage, we keep K to roughly 100.</p><p>We further increase parallelism by spawning a thread for each entry of the output blocks, but this comes at the cost of reading the input multiple times. To mitigate this issue, we use Shared Memory offered by GPUs to share and reduce the frequency of data being pulled from global memory. We also use Shared Memory to reduce the cost of generating random coefficients, which can be reused for all the inputs of a batch.</p><p>Finally, we take advantage of Tensor Cores to maximize throughput and efficiency, as they were designed to excel at matrix multiplications. These interventions yield a fast and power-efficient implementation of random projection. On our hardware, we achieved speed-ups in excess of 200x compared to our "block-by-block" strategy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Theoretical Justification</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.1 The one-step Newton approximation for leave-one-out influence</head><p>The key formula we use in TRAK is the estimate for the leave-one-out (LOO) influence in logistic regression (Definition 3.1). Here, we reproduce the derivation of this estimate from Pregibon <ref type="bibr" target="#b70">[Pre81]</ref> then extend it to incorporate example-dependent bias terms.</p><p>Convergence condition for logistic regression. Assume that we optimized the logistic regression instance via Newton-Raphson, i.e., the parameters are iteratively updated as</p><formula xml:id="formula_48">θ t+1 ← θ t + H -1 θ t ∇ θ L( θ t )<label>(23)</label></formula><p>where H θ is the Hessian and ∇ θ L( θ) is the gradient associated with the total training loss L( θ) = ∑ z i ∈S L(z i ; θ). In the case of logistic regression, the above update is given by</p><formula xml:id="formula_49">θ t+1 ← θ t + (X RX) -1 X q (24)</formula><p>where q = 1p is the vector of the probabilities for the incorrect class evaluated at θ t and R = diag( p(1p) is the corresponding matrix. Upon convergence, the final parameters θ satisfy the following:</p><formula xml:id="formula_50">(X RX) -1 X q = 0 (<label>25</label></formula><formula xml:id="formula_51">)</formula><p>where q is the incorrect-class probability vector corresponding to θ .</p><p>The one-step Newton approximation. We estimate the counterfactual parameters θ -i that would have resulted from training on the same training set excluding example i by simply taking a single Newton step starting from the same global optimum θ :</p><formula xml:id="formula_52">θ -i = θ + (X -i R -i X -i ) -1 X -i q -i ,<label>(26)</label></formula><p>where the subscript -i denotes the corresponding matrices and vectors without the i-th training example. Rearranging and using (25),</p><formula xml:id="formula_53">θ -θ -i = -(X -i R -i X -i ) -1 X -i q -i θ -θ -i = (X RX) -1 X q -(X -i R -i X -i ) -1 X -i q -i</formula><p>Using the Sherman-Morrison formula to simplify above, <ref type="foot" target="#foot_24">24</ref> we have</p><formula xml:id="formula_54">θ -θ -i = (X RX) -1 x i 1 -x i (X RX) -1 x i • p i (1 -p i ) q i = (X RX) -1 x i 1 -x i (X RX) -1 x i • p i (1 -p i ) (1 -p i ) (27)</formula><p>The above formula estimates the change in the parameter vector itself. To estimate the change in prediction at a given example x, we take the inner product of the above expression with vector x to get the formula in Definition 3.1. The approximation here is in assuming the updates converge in one step. Prior works [KAT+19] quantify the fidelity of such approximation under some assumptions. The effectiveness of TRAK across a variety of settings suggests that the approximation is accurate in regimes that arise in practice.</p><p>Incorporating bias terms. The above derivation is commonly done for the case of standard logistic regression, but it also directly extends to the case where the individual predictions incorporate example-dependent bias terms b i that are independent of θ. In particular, note that the likelihood function after linearization in Step 1 is given by</p><formula xml:id="formula_55">p(z i ; θ) = σ(-y i • (∇ θ f (z i ; θ ) • θ + b i ))<label>(28)</label></formula><p>where σ(•) is the sigmoid function. Because the Hessian and the gradients of the training loss only depend on θ through p(z i ; θ), and because b i 's are independent of θ, the computation going from Equation (23) to Equation ( <ref type="formula">24</ref>) is not affected. The rest the derivation also remains identical as the bias terms are already incorporated into p and q .</p><p>Generalization to other settings. While our derivations in this paper focus on the case of logistic regression, more generally, TRAK can be easily adapted to any choice of model output function as long as the training loss L is a convex function of the model output f . The corresponding entries in the Q = diag(1p i ) matrix in Definition 3.1 is then replaced by ∂L/∂ f (z i ). The R matrix and the leverage scores also change accordingly, though we do not include them in our estimator (that said, including them may improve the estimator in settings beyond classification).</p><p>However, in general one needs care in choosing an appropriate model output function in order to maximize the performance on the linear datamodeling prediction task. If the chosen model output is not well approximated by a linear function of training examples, then that puts an upper bound on the predictive performance of any attribution method in our framework. We discuss appropriate choices of model output functions further in Appendix C.4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.2 Random projections preserve gradient flow</head><p>In Step 2 of TRAK, we use random projections to reduce the dimension of the gradient vectors. Here, we justify this approximation when our model is trained via gradient descent. Similar analysis has been used prior, e.g., by Malladi et al. <ref type="bibr" target="#b66">[MWY+22]</ref>.</p><p>In the limit of small learning rate, the time-evolution of model output f (z; θ) under gradient descent (or gradient flow) is captured by the following differential equation <ref type="bibr" target="#b45">[JGH18]</ref>:</p><formula xml:id="formula_56">d f (z; θ) dt = ∑ i ∂L(z i ; θ) ∂ f (z i ; θ) • (∇ f (z i ; θ) • ∇ f (z; θ)) ≈ ∑ i ∂L(z i ; θ) ∂ f (z i ; θ) • (g i • g(z))<label>(29)</label></formula><p>where g i and g(z) are the gradients of the final model corresponding to examples z i and z as before.</p><p>The approximation is due to assuming that the gradients do not change over time.</p><p>If we treat the outputs { f (z i ; θ)} i as time-varying variables, then their time evolution is entirely described by the above system of differential equations (one for each i, replacing z with z i above). Importantly, the above equations only depend on the gradients through their inner products. Hence, as long as we preserve the inner products to sufficient accuracy, the resulting system has approximately the same evolution as the original one. This justifies replacing the gradient features with their random projections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.3 Subsampling the training set</head><p>In Step 4 of our algorithm, we ensemble the attribution scores over multiple models. As we investigate in Appendix E.2, this significantly improves TRAK's performance. An important design choice is training each model on a different random subset of the training set. This choice is motivated by the following connection between TRAK scores and empirical influences <ref type="bibr" target="#b26">[FZ20]</ref>. Recall that we designed TRAK to optimize the linear datamodeling score. As we discuss in Section 2, datamodels can be viewed as an "oracle" for optimizing the same metric. Further, as Ilyas et al. <ref type="bibr" target="#b42">[IPE+22]</ref> observes, datamodels can be viewed as a regularized version of empirical influences <ref type="bibr" target="#b26">[FZ20]</ref>, which are defined as a difference-in-means estimator,</p><formula xml:id="formula_57">τ(z j ) i = E S ∼D [ f (z j ; θ (S ))|z i ∈ S ] -E S ∼D [ f (z j ; θ (S ))|z i ∈ S ] (<label>30</label></formula><formula xml:id="formula_58">)</formula><p>where D is the uniform distribution over α-fraction subsets of training set S. Assuming the expectation over α-fraction subsets is identical to that over subsets of one additional element, we can rearrange the above expression as</p><formula xml:id="formula_59">τ(z j ) i = E S ∼D [ f (z j ; θ (S ∪ {z i })) -f (z j ; θ (S ))].<label>(31)</label></formula><p>The above expression is simply the expectation of leave-one-out influence over different random subsets. As the estimate from step 3 of our algorithm is specific to a single training set, we need to average over different subsets in order to approximate the above quantity.</p><p>In principle, the estimates computed from θ (S ) only apply to the training examples included in the subset S , since the underlying formula (Definition 3.1) concerns examples that were included for the original converged parameter θ . Hence, when averaging over the models, each model should only update the TRAK scores corresponding to examples in S . However, we found that the estimates are marginally better when we update the estimates for the entire training set S (i.e., even those that were not trained on).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Generalization across different α's.</head><p>A possible concern is that we overfit to a particular regime of α used in evaluating with the LDS. In Figure <ref type="figure">D</ref>.1, we evaluate TRAK scores (computing using α = 0.5) in other regimes and find that they continue to be highly predictive (though with some degradation in correlation). More generally, our various counterfactual evaluations using the full training set (CIFAR-10 brittleness estimates in Figure <ref type="figure" target="#fig_5">10</ref>, the CLIP counterfactuals in Figure <ref type="figure" target="#fig_3">8</ref>) indicate that TRAK scores remain predictive near the α = 1 regime.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.4 Linearity and model output function</head><p>We study linear predictors derived from attribution scores, as linearity is a latent assumption for many popular attribution methods. Linearity also motivates our choices of model output functions.</p><p>Latent assumption of linearity. Our evaluation of data attribution methods cast them as linear predictors. While not always immediate, linearity is a latent assumption behind most of the prior methods that we evaluate in this paper. Datamodels and Shapley values satisfy additivity by construction [GZ19; JDW+19]. The approach based on influence functions [KL17; KAT+19] typically uses the sum of LOO influences to estimate influences for groups of examples. Similarly, empirical (or subsampled) influences <ref type="bibr" target="#b26">[FZ20]</ref> also correspond to a first-order Taylor approximation of the model output function. The TracIn estimator also implicitly assumes linearity <ref type="bibr" target="#b69">[PLS+20]</ref>.</p><p>That said, others works also incorporate additional corrections beyond the first order linear terms <ref type="bibr" target="#b15">[BYF19]</ref> and find the resulting predictions better approximate the true influences.</p><p>Choice of model output function f . In our experiments, we choose the model output function suitable for the task at hand: for classification and language modeling, we used a notion of margin that is equivalent to the logit function, while for CLIP, we used a similar one based on the CLIP loss.</p><p>Our particular choice of the logit function (log p/(1p)) in the multi-class classification case was motivated by theoretical <ref type="bibr" target="#b81">[SGB+23]</ref> and empirical <ref type="bibr" target="#b42">[IPE+22]</ref> observations from prior works. In particular, this choice of model output function is well approximated by linear datamodels, both in practice and in theory. A slightly different definition of margin used in Ilyas et al. <ref type="bibr" target="#b42">[IPE+22]</ref>-where the margin is computed as the logit for the correct class minus the second highest class-can also be as an approximation to the one used here.</p><p>More generally, choosing a good f boils down to linearizing (w.r.t. θ) as much of the model output as possible, but not too much. On one extreme, choosing f (z) = z (i.e., linearizing nothing, as there is no dependence on θ) means that the one-step Newton approximation has to capture all of the non-linearity in both the model and the dependence of L on f ; this is essentially the same approximation used by the Hessian-based influence function. On the other extreme, if we choose f = L, we linearize too much, which does not work well as L in general is highly non-linear as a function of f .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D Additional Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.1 Correlation distribution</head><p>Generalization across α's. In Figure <ref type="figure">D</ref>.1 left, we compare the linear datamodeling scores (LDS) evaluated on α = 0.5 sub-sampled training sets to those evaluated on α = 0.75. (The numbers are overall lower as these are evaluated on data where only one model was trained on each subset,instead of averaging over 5 models; hence, there is more noise in the data.) As we observe, the LDS scores on different α's are highly correlated, suggesting that TRAK scores computed on a single α generalize well.  We quantify various data attribution methods in terms of both their predictiveness-as measured by the linear datamodeling score-as well as their computational efficiency-as measured by either the total computation time (wall-time measured in minutes on a single A100 GPU; see Appendix A.4 for details) or the number of trained models used to compute the attribution scores. The errors indicate 95% bootstrap confidence intervals. Sampling-based methods (datamodels and empirical influences) can outperform TRAK when allowed to use more computation, but this leads to a significant increase in computational cost.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>LDS correlation between TRAK and datamodels. In</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.2 Table for LDS evaluation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.3 TRAK examples</head><p>We display more examples identified with TRAK scores in  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Q: What percent of household have children under 18?</head><p>A: There were 46,917 households, out of which 7,835 (16.7%) had children under the age of 18 living in them, 13,092 (27.9%) were opposite-sex married couples living together, 3,510 (7.5%) had a female householder with no husband present, 1,327 (2.8%) had a male householder with no wife present. (Yes) Q: Roughly how many same-sex couples were there? A: There were 46,917 households, out of which 7,835 (16.7%) had children under the age of 18 living in them, 13,092 (27.9%) were oppositesex married couples living together, 3,510 (7.5%) had a female householder with no husband present, 1,327 (2.8%) had a male householder with no wife present.  (3) counterfactually testing the inferred feature associated with the subpopulation. Shah et al. <ref type="bibr" target="#b84">[SPI+22]</ref> find that models trained with data augmentation latch onto the presence of spider webs as a spurious correlation to predict the class spider. Here, we recover their result by using TRAK scores instead of datamodel scores in step (1); doing so reduces the computational cost of MODELDIFF by 100x.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E Ablation Studies</head><p>We perform a number of ablation studies to understand how different components of TRAK affect its performance. Specifically, we study the following:</p><p>• The dimension of the random projection, k. Section 3.2).</p><p>• The number of models ensembled, M. Section 3.2).</p><p>• Proxies for ensembles to further improve TRAK's computational efficiency.</p><p>• The role of different terms in the influence estimation formula (Equation ( <ref type="formula" target="#formula_26">17</ref>)).</p><p>• Alternative choice of the kernel (using last layer representations).</p><p>• Alternative methods of ensembling over models.</p><p>As in Section 4, we evaluate the linear datamodeling score (LDS) on models trained on the CIFAR-2, CIFAR-10, and QNLI datasets. Note that the LDS is in some cases lower than the counterparts in Figure <ref type="figure">2</ref> as we use a smaller projected dimension (k) and do not use soft-thresholding in these experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E.1 Dimension of the random projection</head><p>Recall that when we compute TRAK we reduce the dimensionality of the gradient features using random projections (Step 2 of Section 3.2). Intuitively, as the resulting dimension k increases, the corresponding projection better preserves inner products, but is also more expensive to compute. We now study how the choice of the projection dimension k affects TRAK's attribution performance.</p><p>Figure <ref type="figure">E</ref>.1 (Left) shows that as we increase the dimension, the LDS initially increases as expected; random projections to a higher dimension preserve the inner product more accurately, providing a better approximation of the gradient features. However, beyond a certain point, increasing projection dimension decreases the LDS. We hypothesize that using random projections to a lower dimension has a regularizing effect that competes with the increase in approximation error. <ref type="foot" target="#foot_25">25</ref>Finally, the dimension at which LDS peaks increases as we increase the number of models M used to compute TRAK.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E.2 Number of models used in the ensemble</head><p>An important component of computing TRAK is ensembling over multiple independently trained models (Step 4 in Section 3.2). In our experiments, we average TRAK's attribution scores over ensembles of size ranging from 1 to 100. Here, we quantify the importance of this procedure on TRAK's performance. shows that TRAK enjoys a significantly better data attribution performance with more models. That said, even without ensembling (i.e., using a single model), TRAK still performs better (e.g., LDS of 0.096 on CIFAR-2) than all prior gradient-based methods that we evaluate. 0 2,000 4,000 6,000 8,000 Each line corresponds to a different value of M ∈ {10, 20, ..., 100} (the number of models TRAK is averaged over); darker lines correspond to higher M. As we increase the projected dimension, the LDS initially increases. However, beyond a certain dimension, the LDS begins to decrease. The "optimal" dimension (i.e., the peak in the above graph) increases with higher M. Right: The impact of ensembling more models on TRAK's performance on CIFAR-2. The performance of TRAK as a function of the number of models used in the ensembling step. TRAK scores are computed with random projections of dimension k = 4000.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E.3 Proxies for model ensembles in compute-constrained settings</head><p>In Appendix E.2 we saw that ensembling leads to significantly higher efficacy (in terms of LDS). In many settings, however, it is computationally expensive to train several independent models to make an ensemble. Hence, we study whether there is a cheaper alternative to training multiple independent models that does not significantly sacrifice efficacy. To this end, we explore two avenues of approximating the full ensembling step while dramatically reducing the time required for model training. In particular, we investigate:</p><p>1. using multiple checkpoints from each training trajectory;</p><p>2. using checkpoints from early training, long before the model has converged.</p><p>Multiple checkpoints from each training trajectory. We compute TRAK scores using a fixed number of checkpoints, but while varying the number of independently-trained models. For example, for 100 checkpoints, we can use the final checkpoints from 100 independently-trained models, the last two checkpoints from 50 independently-trained models, etc. We observe (see Table <ref type="table" target="#tab_8">E</ref>.3) that TRAK achieves comparable LDS when we use last T checkpoints along the trajectory of the same models as a proxy for independently-trained models in the ensembling step.</p><p>Using checkpoints from early training. We explore whether each of the models in the ensemble has to be fully trained to convergence. In particular, we study the effect of using checkpoints from early epochs on the LDS. While TRAK benefits from using later-epoch gradient features, it maintains its efficacy even when we use gradient features from training runs long before reaching convergence (see </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E.4 Role of different terms.</head><p>The TRAK estimator (Equation ( <ref type="formula" target="#formula_26">17</ref>)) has a number of different components. We label each component (of the single model estimator) as follows:</p><formula xml:id="formula_60">τ(z) i = φ(z) reweighting (Φ RΦ) -1 φ(z i ) • loss gradient 1 1 + e f (z i ) 1 - h i leverage score</formula><p>We ablate each of the terms above and re-evaluate the resulting variant of TRAK on CIFAR-2. Our results in Table <ref type="table" target="#tab_8">E</ref>.4 indicate the following:</p><p>• Reweighting: Experiment 6 shows that this matrix is a critical part of TRAK's performance. Conceptually, this matrix distinguishes our estimator from prior gradient based similarity metrics such as TracIn.</p><p>• Diagonal term R: The full reweighting matrix includes a diagonal term R. Although it is theoretically motivated by Definition 3.1, including this term results in lower LDS, so we do not include it (Experiments 2,4).</p><p>• Loss gradient: This term corresponds to the Q matrix (Equation ( <ref type="formula" target="#formula_22">14</ref>)) and encodes the probability of the incorrect class, 1p i ; the name is based on the derivation in Appendix C.1, where this term corresponds to scalar associated with the gradient of the loss. Intuitively, this term helps reweight training examples based on on models' confidence on them. Experiment 5 shows that this term improves the performance substantially.</p><p>• Leverage score: This term does not impact the LDS meaningfully, so we do not include it (Experiments 1,2).</p><p>• Averaging "out" vs "in": Averaging the estimator and the loss gradient term separately, then re-scaling by the average loss gradient results in higher LDS (Experiment 3). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E.5 Choice of the kernel</head><p>To understand how the choice of the kernel impacts the performance of TRAK, we also compute a version of TRAK using feature representations of the penultimate layer in place of the projected gradients. This choice is equivalent to restricting the gradient features to those of the last linear layer. As Table <ref type="table" target="#tab_8">E</ref>.5 shows, this method significantly improves on all existing baselines based on gradient approximations,<ref type="foot" target="#foot_26">26</ref> but still underperforms significantly relative to TRAK. This gap suggests that the eNTK is capturing additional information that is not captured by penultimate layer representations. Moreover, the larger gap on CIFAR-10 compared to CIFAR-2 and QNLI (both of which are binary classificaiton tasks) hints that the gap will only widen on more complex tasks. We note that TRAK applied only to the last layer is almost equivalent to the influence function approximation. Indeed, they perform similarly (e.g., the influence function approximation also achieves a LDS of 0.19 on QNLI). We compare TRAK computed using the eNTK (i.e., using features derived from full gradients) with TRAK computed using the kernel derived from last layer feature representations. The attribution scores are ensembled over M = 100 models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dataset</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E.6 Ensembling vs. Averaging the eNTK</head><p>There are different ways to ensemble a kernel method given multiple kernels {K i } i : (i) we can average the Gram matrices corresponding to each kernel first and then predict using the averaged</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F Fact Tracing F.1 The FTRACE-TREX Dataset</head><p>The training set of FTRACE-TREX is sourced from the TREX dataset <ref type="bibr" target="#b24">[EVR+18]</ref>, with each training example excerpted from a DBPedia abstract <ref type="bibr" target="#b36">[HLA+13]</ref> and annotated with a list of facts it expresses. <ref type="foot" target="#foot_27">27</ref> The test set of FTRACE-TREX is sourced from the LAMA dataset [PRR+19], and each test example is a sentence that expresses a single fact-every training example that expresses the same fact is called a "proponent" of this test example. Now, given a test example expressing some fact, the goal of fact tracing (as defined by the FTRACE-TREX benchmark) is to correctly identify the corresponding proponents from the training set. More precisely, Akyurek et al. <ref type="bibr" target="#b1">[ABL+22]</ref> propose the following evaluation methodology, which we follow exactly (with the exception that, due to computational constraints, we use a smaller 300M-parameter mt5-small model instead of the 580M-parameter mt5-base). We first finetune the pretrained language model <ref type="bibr" target="#b77">[RSR+20]</ref> on the training set of FTRACE-TREX. Then, we iterate through the FTRACE-TREX test set and find the examples on which the pre-trained model is incorrect and the finetuned model is correct,<ref type="foot" target="#foot_28">28</ref> which Akyurek et al. <ref type="bibr" target="#b1">[ABL+22]</ref> refer to as the "novel facts" learned by the model after finetuning. For each novel fact identified, we collect a set of candidate training examples, comprising all proponents as well as 300 "distractors" from the training set. Akyurek et al. <ref type="bibr" target="#b1">[ABL+22]</ref> propose to evaluate different attribution methods based on how well they identify the ground-truth proponents among each candidate set.</p><p>Concretely, given an attribution method τ(•), we compute attribution scores τ(z) for each of the novel facts in the test set. For each novel fact, we sort the corresponding candidate examples by their score τ(z) i . Finally, we compute the mean reciprocal rank (MRR), a standard information retrieval metric, of ground-truth proponents across the set of novel facts, defined as MRR = ∑ z∈ novel facts 1 min i ∈ proponents(z) rank(τ(z), i) .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F.2 Fine-tuning details</head><p>We finetune the pre-trained language model using the masked language modeling objective <ref type="bibr" target="#b21">[DCL+19]</ref>. In particular, for each training example z i ∈ [K] L (where K is the vocabulary size and L is the maximum passage length), we mask out a subject or object within the passage. (E.g., a training example "Paris is the capital of France" might become an input-label pair ["__ is the capital of France", "Paris"]). We then treat the language modeling problem as multiple separate K-way classification tasks. Each task corresponds to predicting a single token of the masked-out text, given (as input) the entire passage minus the token being predicted. The loss function is the average cross-entropy loss on this sequence of classification tasks.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :Figure 3 :</head><label>23</label><figDesc>Figure2: TRAK achieves state-of-the-art tradeoffs between attribution efficacy and efficiency. We use TRAK to attribute ResNet-9 classifiers trained on CIFAR-2 and CIFAR-10; ResNet-18 classifiers trained on ImageNet; and BERT-base models finetuned on QNLI. The x-axis indicates the computational cost measured as the number of trained models that a given method uses to compute attribution scores. The y-axis indicates the method's efficacy as measured by the linear datamodeling score (LDS). Error bars indicate 95% bootstrap confidence intervals.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>Figure 7: Attributing CLIP trained on MS COCO. The first column shows two target image-caption pairs from the validation set of MS COCO. The second two columns display the nearest neighbors to the target in CLIP embedding space (using the average of image and text cosine similarities). The next two columns show the train set samples that, according to TRAK, are most helpful for aligning the image embedding to the caption embedding. Similarly, the last two columns display the train samples that are the most detracting from aligning the image and caption embeddings. In Appendix D.3, we display more examples and also compare to TracIn.</figDesc><graphic coords="18,84.74,186.40,56.60,56.60" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: Which training inputs can we remove from the training set so as the resulting CLIP model no longer associates a target image with its caption? We measure how the cosine similarity between target image and caption embeddings is affected when we re-train a CLIP model after removing the most influential training examples-as identified by TRAK, TracIn, and CLIP similarity distance. We report the decrease in cosine similarity, averaged over 100 randomly selected image-caption pairs from the validation set. Error bars represent 95% confidence intervals.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9: Identifying counterfactually important examples for learning facts on FTRACE-TREX. Given a set of queries that the language model (mt5-small) originally answers correctly after training, we compare how three different interventions-removing abstracts with the highest TRAK scores, removing the most similar abstracts according to BM25, and removing the ground-truth proponents as indicated by FTRACE-TREX-affect the resulting model's accuracy on the queries. The yaxis shows the decrease in accuracy (on the query set, relative to the original model) after each intervention; results are averaged over 50 queries and eight independent models. Error bars represent 95% confidence intervals.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 10 :</head><label>10</label><figDesc>Figure 10: Using TRAK scores to identify brittle model predictions. Following the methodology of Ilyas et al. [IPE+22], we apply different data attribution methods to estimate the brittleness of model predictions on examples from the CIFAR-10 validation set.The number of models used by each attribution method is specified in parentheses, e.g., TRAK (100) indicates that TRAK scores were computed using an ensemble of 100 trained models.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure D. 1 :</head><label>1</label><figDesc>Figure D.1: (Left)The LDS of CIFAR-2 TRAK scores computed with α = 0.5 models then evaluated on either models trained with either α = 0.5 or α = 0.75. Each point corresponds to a validation example. (Right) The LDS of CIFAR-2 datamodel scores compared with that of TRAK. Here, the LDS is measured on two different estimators.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>Figure D.3 (ImageNet), Figure D.4 (QNLI), and Figure D.5 (CLIP on MS COCO).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>Figure D.4: Top TRAK attributions for QNLI examples. Yes/No indicates the label (entailment vs. no entailment).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>BFigure D. 6 :</head><label>6</label><figDesc>Figure D.5: Top attributions for CLIP models trained on MS COCO. We display random test examples and their corresponding most helpful (highest-scoring) and most detracting (lowest-scoring) training examples according to TRAK, CLIP similarity distance, and TracIn.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure E. 1 (</head><label>1</label><figDesc>Right)  </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure E. 1 :</head><label>1</label><figDesc>Figure E.1: Left: The impact of the dimension of random projection on TRAK's performance on CIFAR-2. Each line corresponds to a different value of M ∈ {10, 20, ..., 100} (the number of models TRAK is averaged over); darker lines correspond to higher M. As we increase the projected dimension, the LDS initially increases. However, beyond a certain dimension, the LDS begins to decrease. The "optimal" dimension (i.e., the peak in the above graph) increases with higher M. Right: The impact of ensembling more models on TRAK's performance on CIFAR-2. The performance of TRAK as a function of the number of models used in the ensembling step. TRAK scores are computed with random projections of dimension k = 4000.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>(Step 4) Ensembling over independently trained models. So</head><label></label><figDesc>;<ref type="bibr" target="#b12">BNL+22]</ref>. As noted in prior works [TBG+21; BNL+22], this approximation is a more convenient choice than the full Hessian as it is guaranteed to be positive semi-definite.</figDesc><table><row><cell>far, our analysis ignores the fact</cell></row><row><cell>that in many modern settings, training is non-deterministic. That is, applying the same learning</cell></row><row><cell>algorithm to the same training dataset (i.e., changing only the random seed) can yield models with</cell></row><row><cell>(often significantly) differing behavior [NRK21; DHM+20]. Non-determinism poses a problem for</cell></row><row><cell>data attribution because by definition, we cannot explain such seed-based differences in terms of</cell></row><row><cell>the training data.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 4 :</head><label>4</label><figDesc>Comparing TRAK and datamodel scores. Recall from Section 2.2 that one can view datamodels<ref type="bibr" target="#b42">[IPE+22]</ref> as an "oracle" of sorts for the linear datamodeling score (LDS) objective. It turns out, as we show in Table4, that TRAK scores correlate with datamodel scores, while scores of other attribution methods do not. (We define correlation here as the Spearman rank correlation between the vectors τ TRAK (z) and τ DM (z), averaged over multiple examples of interest z.) Correlation with datamodel scores. We measure the correlation between the attribution scores computed by different methods τ and those given by datamodels τ DM<ref type="bibr" target="#b42">[IPE+22]</ref> on the CIFAR-10 dataset. Specifically, for each test example of interest z, we compute the Spearman rank correlation (ρ) between τ(z) i and τ DM (z) i over training examples i that have nonzero datamodel weight τ DM (z) i and then average the resulting correlation over 1000 randomly chosen examples of interest.</figDesc><table><row><cell cols="7">Method TRAK 100 TRAK 20 TracIn [PLS+20] IF [KL17] GAS [HL22a] random</cell></row><row><cell>ρ(τ, τ DM )</cell><cell>0.26</cell><cell>0.19</cell><cell>0.00</cell><cell>0.03</cell><cell>0.03</cell><cell>-0.03</cell></row></table><note><p>TRAK N indicates a version of TRAK that uses N trained models in its estimator.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>In particular, we apply TRAK to fact tracing: the problem of tracing a language model's factual assertion back to the corresponding training examples. On the FTRACE-TREX fact tracing benchmark, TRAK significantly outperforms the best gradient-based baseline (TracIn) used in prior work. Furthermore, while TRAK performs worse than an information retrieval baseline (BM25 [RWJ+95]), we demonstrate that this is likely a shortcoming of the benchmark rather than of TRAK. In particular, removing training examples traced by</figDesc><table /><note><p>TRAK (and re-training the model) reduces that model's accuracy on the corresponding facts more than removing training examples traced by BM25-and, in fact, more than removing the ground-truth training examples as indicated by FTRACE-TREX.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>Comparison of different data attribution methods.</figDesc><table><row><cell>Dataset</cell><cell></cell><cell cols="4">TRAK TracIn [PLS+20] Infl. [KL17] Datamodels [IPE+22]</cell></row><row><cell>CIFAR-2</cell><cell># models</cell><cell>5</cell><cell>100</cell><cell>-</cell><cell>1,000</cell></row><row><cell></cell><cell>Time (min.)</cell><cell>3</cell><cell>100</cell><cell>-</cell><cell>500</cell></row><row><cell></cell><cell>LDS</cell><cell>0.203(3)</cell><cell>0.056(2)</cell><cell>-</cell><cell>0.162(5)</cell></row><row><cell cols="2">CIFAR-10 # models</cell><cell>20</cell><cell>20</cell><cell>1</cell><cell>5,000</cell></row><row><cell></cell><cell>Time (min.)</cell><cell>20</cell><cell>60</cell><cell>20,000</cell><cell>2,500</cell></row><row><cell></cell><cell>LDS</cell><cell>0.271(4)</cell><cell>0.056(7)</cell><cell>0.037(13)</cell><cell>0.199(4)</cell></row><row><cell>QNLI</cell><cell># models</cell><cell>10</cell><cell>1</cell><cell>1</cell><cell>20,000</cell></row><row><cell></cell><cell>Time (min.)</cell><cell>640</cell><cell>284</cell><cell>18,000</cell><cell>176,000</cell></row><row><cell></cell><cell>LDS</cell><cell>0.416(10)</cell><cell>0.077(29)</cell><cell>0.114(43)</cell><cell>0.344(32)</cell></row><row><cell cols="2">ImageNet # models</cell><cell>100</cell><cell>1</cell><cell>20</cell><cell>30,000</cell></row><row><cell></cell><cell>Time (min.)</cell><cell>2920</cell><cell>76</cell><cell>&gt;100,000</cell><cell>525,000</cell></row><row><cell></cell><cell>LDS</cell><cell>0.188(6)</cell><cell>0.008(6)</cell><cell>0.037(6)</cell><cell>0.1445(6)</cell></row><row><cell>Table D.2:</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head></head><label></label><figDesc>What words are inscribed on the mace of parliament? A: The words There shall be a Scottish Parliament, which are the first words of the Scotland Act, are inscribed around the head of the mace, which has a formal ceremonial role in the meetings of Parliament, reinforcing the authority of the Parliament in its ability to make laws. (No) Whose name is on the gate-house fronting School Yard? A: His name is borne by the big gate-house in the west range of the cloisters, fronting School Yard, perhaps the most famous image of the school. (No)</figDesc><table><row><cell>Example</cell><cell></cell><cell></cell><cell cols="3">Highest TRAK score (+)</cell><cell cols="3">Lowest TRAK score (-)</cell></row><row><cell cols="3">Q: What was a major success, especially in rebuilding Warsaw? A: Like many cities</cell><cell cols="3">Q: In 1998, the deal was renewed for what amount over four years? A: Tele-</cell><cell cols="3">Q: Who was a controversial figure due to a corked-bat incident? A: Already a</cell></row><row><cell cols="3">in Central and Eastern Europe, infrastruc-</cell><cell cols="3">vision money had also become much</cell><cell cols="3">controversial figure in the clubhouse af-</cell></row><row><cell cols="3">ture in Warsaw suffered considerably dur-</cell><cell cols="3">more important; the Football League re-</cell><cell cols="3">ter his corked-bat incident, Sammy's ac-</cell></row><row><cell cols="6">More positive ing its time as an Eastern Bloc economy -ceived £6.3 million for a two-year agree-though it is worth mentioning that the ini-ment in 1986, but when that deal was re-Held-out Example tial Three-Year Plan to rebuild Poland (es-pecially Warsaw) was a major success, but newed in 1988, the price rose to £44 mil-lion over four years. (Yes)</cell><cell cols="3">tions alienated much of his once strong More negative fan base as well as the few teammates still on good terms with him, (many teammates grew tired of Sosa playing</cell></row><row><cell cols="3">cannon what followed was very much the opposite. cannon cannon (Yes) Q: What is the name associated with the eight areas that make up a part of south-ern California? A: Southern California</cell><cell cols="3">cannon Q: Was was the name given to the cannon sundial Alsace provincinal court? A: The province had a single provincial court</cell><cell cols="3">canoe loud salsa music in the locker room) brass and possibly tarnished his place in Cubs' lore for years to come. (No) sundial Q: What do six of the questions asses? A: For each question on the scale that measures homosexuality there is a cor-</cell></row><row><cell cols="3">black swan consists of one Combined Statistical Area, black swan black swan eight Metropolitan Statistical Areas, one in-ternational metropolitan area, and multiple metropolitan divisions. (Yes)</cell><cell cols="3">black swan (Landgericht) and a central administra-black swan goose tion with its seat at Hagenau. (Yes)</cell><cell cols="3">goose responding question that measures het-goose goose erosexuality giving six matching pairs of questions. (No)</cell></row><row><cell cols="9">Q: Q: What kind of signs were removed form club Barcelona? A: All signs of re-</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">gional nationalism, including language,</cell></row><row><cell>bluetick</cell><cell cols="4">bluetick bluetick bluetick bluetick</cell><cell cols="4">black-and-tan coonhound short-haired German pointer flag and other signs of separatism were English springer Boston bull banned throughout Spain. (Yes)</cell></row><row><cell cols="5">lifeboat Q: What was the percentage of a female lifeboat lifeboat lifeboat lifeboat householder with no husband present? A: There were 158,349 households, of which</cell><cell>drilling platform</cell><cell>tractor</cell><cell>drilling platform</cell><cell>drilling platform</cell></row><row><cell cols="3">68,511 (43.3%) had children under the</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="3">age of 18 living in them, 69,284 (43.8%)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="3">were opposite-sex married couples living to-</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="5">siamang gether, 30,547 (19.3%) had a female house-siamang siamang siamang siamang holder with no husband present, 11,698 (7.4%) had a male householder with no wife present. (Yes)</cell><cell>titi</cell><cell>fur coat</cell><cell>patas</cell><cell>bearskin</cell></row><row><cell>platypus</cell><cell cols="4">platypus platypus platypus platypus</cell><cell>cleaver</cell><cell>electric ray</cell><cell cols="2">cleaver centipede</cell></row><row><cell>sandal</cell><cell>sandal</cell><cell>sandal</cell><cell>sandal</cell><cell>sandal</cell><cell>clog</cell><cell>clog</cell><cell>Band Aid</cell><cell>clog</cell></row><row><cell>cinema</cell><cell>cinema</cell><cell>cinema</cell><cell>cinema</cell><cell>cinema</cell><cell>bakery</cell><cell>tobacco shop</cell><cell>bakery</cell><cell>tobacco shop</cell></row></table><note><p>Figure D.3: TRAK attributions for ResNets trained on ImageNet. We display random test examples and their corresponding most helpful (highest-scoring) and most detracting (lowest-scoring) training examples according to TRAK. Q:</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table E .</head><label>E</label><figDesc>Table E.2). Leveraing this can further improve the computational efficiency of 2: The performance of TRAK on CIFAR-10 as a function of the epoch at which we terminate model training. In all cases, TRAK scores are computed with projection dimension k = 1000 and M = 100 independently trained models.</figDesc><table><row><cell cols="2"># training epochs LDS (M = 100)</cell><cell cols="2"># independent models LDS</cell></row><row><cell>1</cell><cell>0.100</cell><cell>5</cell><cell>0.329</cell></row><row><cell>5</cell><cell>0.204</cell><cell>6</cell><cell>0.340</cell></row><row><cell>10</cell><cell>0.265</cell><cell>10</cell><cell>0.350</cell></row><row><cell>15</cell><cell>0.293</cell><cell>100</cell><cell>0.355</cell></row><row><cell>25</cell><cell>0.308</cell><cell></cell><cell></cell></row><row><cell>TRAK.</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table E .</head><label>E</label><figDesc>3: TRAK maintains its efficacy when we use multiple checkpoints from different epochs of the same training run instead of checkpoints from independently-trained models (CIFAR-10). In all cases, M = 100 checkpoints and projection dimension k = 4000 are used to compute TRAK scores.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head></head><label></label><figDesc>Ablating the contribution of each term in the TRAK estimator. For these experiments, we use random projections of dimenseion k = 2000.</figDesc><table><row><cell cols="3">Experiment Reweighting Loss Diagonal R Leverage Averaging Correlation</cell></row><row><cell>0</cell><cell>out</cell><cell>0.499</cell></row><row><cell>1</cell><cell>out</cell><cell>0.499</cell></row><row><cell>2</cell><cell>out</cell><cell>0.430</cell></row><row><cell>3</cell><cell>in</cell><cell>0.416</cell></row><row><cell>4</cell><cell>out</cell><cell>0.403</cell></row><row><cell>5</cell><cell>out</cell><cell>0.391</cell></row><row><cell>6</cell><cell>out</cell><cell>0.056</cell></row><row><cell>Table E.4:</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head></head><label></label><figDesc>Choice of the kernel in TRAK.</figDesc><table><row><cell></cell><cell cols="2">Kernel representation Linear Datamodeling Score (LDS)</cell></row><row><cell>CIFAR-2</cell><cell>eNTK</cell><cell>0.516</cell></row><row><cell>CIFAR-2</cell><cell>penultimate layer</cell><cell>0.198</cell></row><row><cell>CIFAR-10</cell><cell>eNTK</cell><cell>0.413</cell></row><row><cell>CIFAR-10</cell><cell>penultimate layer</cell><cell>0.120</cell></row><row><cell>QNLI</cell><cell>eNTK</cell><cell>0.589</cell></row><row><cell>QNLI</cell><cell>penultimate layer</cell><cell>0.195</cell></row><row><cell>Table E.5:</cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>We make the notion of "importance" more precise later (in Definition</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1"><p>2.3).</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_2"><p>In many settings, the non-determinism of training makes this model output function a random variable, but we treat it as deterministic to simplify our notation. We handle non-determinism explicitly in Section</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_3"><p>3.2.3  Note that this additivity assumption can be explicit or implicit. Shapley values<ref type="bibr" target="#b82">[Sha51]</ref> and datamodels<ref type="bibr" target="#b42">[IPE+22]</ref>, for example, take additivity as an axiom. Meanwhile, attribution methods based on influence functions [HRR+11; KL17; KAT+19] implicitly use a first-order Taylor approximation of the loss function with respect to the vector of training example loss weights, which is precisely equivalent to an additivity assumption.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_4"><p>In practice, we can estimate the LDS with 100-500 models, as the average rank correlation (over a sufficient number of test examples) converges fairly quickly with sample size.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_5"><p>Note that we focus on logistic regression for simplicity-more generally one can adapt TRAK to any setting where the training loss is convex in the model output; see Appendix C.1.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_6"><p>Note that for the special case of binary classifiers, the model output function that we define (i.e., f (z; θ) = f ((x, y); θ)) depends only on the input x, and not on the label y. When we generalize TRAK to more complex losses in Section 3.3, the model output function will involve both x and y.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_7"><p>In Appendix C.2 we discuss why preserving inner products suffices to preserve the structure of the logistic regression.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_8"><p>Note that in our linearization (10), the predicted probability is also a function of the bias terms b i . We can avoid having to compute these bias terms by simply using the predicted probability from the true model (i.e., the neural network) instead of the linearized one.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_9"><p>Note that the corresponding "labels" for this logistic regression are actually identically equal to one-to see this, compare (21) to (18). This does not change the resulting attributions, however, as Definition 3.1 only depends on labels through its dependence on the correct-class probability p * i .</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="10" xml:id="foot_10"><p>For many data attribution methods, such as influence function-based methods or TRAK, there is an extra step of computing per-example gradients through the model of interest. However, this step is generally fully parallelizable, and usually bounded by the time it takes to train a model from scratch.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="11" xml:id="foot_11"><p>We use the average of cosine similarities between the image embeddings and between the text embeddings.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="12" xml:id="foot_12"><p>In masked language modeling<ref type="bibr" target="#b77">[RSR+20]</ref>, the language model is asked to predict the tokens corresponding to a masked-out portion of the input. In FTRACE-TREX, either a subject or object in the abstract is masked out.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="13" xml:id="foot_13"><p>Note that while our finding that BM25 outperforms TracIn matches that of Akyurek et al.<ref type="bibr" target="#b1">[ABL+22]</ref>, our exact numbers are incomparable due to the mismatch in model classes.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="14" xml:id="foot_14"><p>See Appendix F.4 for a detailed account of our experiment.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="15" xml:id="foot_15"><p>https://github.com/wbaek/torchskeleton/blob/master/bin/dawnbench/cifar10.py</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="16" xml:id="foot_16"><p>https://github.com/MadryLab/trak/blob/main/examples/cifar2_correlation.ipynb</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="17" xml:id="foot_17"><p>https://huggingface.co/bert-base-cased</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="18" xml:id="foot_18"><p>https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_ glue.py</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="19" xml:id="foot_19"><p>https://github.com/mlfoundations/open_clip</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="20" xml:id="foot_20"><p>https://github.com/alstonlo/torch-influence</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="21" xml:id="foot_21"><p>https://github.com/google-research/jax-influence</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="22" xml:id="foot_22"><p>https://github.com/google-research/jax-influence</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="23" xml:id="foot_23"><p>https://github.com/MadryLab/trak</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="24" xml:id="foot_24"><p>This is used also, for instance, to derive the LOO formulas for standard linear regression.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="25" xml:id="foot_25"><p>Indeed, we can view our approach of first projecting features to a lower dimension and then performing linear regression in the compressed feature space, as an instance of compressed linear regression<ref type="bibr" target="#b64">[MM09]</ref> and also related to principal components regression<ref type="bibr" target="#b89">[THM17]</ref>. These approaches are known to have a regularizing effect, so TRAK may also benefit from that effect.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="26" xml:id="foot_26"><p>Note that as with the eNTK, the use of multiple models here is crucial: only using a single model gives a correlation of 0.006.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="27" xml:id="foot_27"><p>See<ref type="bibr" target="#b1">[ABL+22]</ref> for more details on the annotation methodology.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="28" xml:id="foot_28"><p>To decide whether a model is "correct" on a given test example, we use MT5 as a conditional generation model. That is, we feed in a masked version of the query, e.g., "__ is the capital of France," and mark the model as "correct" if the conditional generation matches the masked word.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="29" xml:id="foot_29"><p>In particular, recall that in order for a test example to be categorized as a "novel fact," it must be both (a) incorrectly handled by the pre-trained mt5-small model and (b) correctly handled by a finetuned model.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="30" xml:id="foot_30"><p>https://chat.openai.com/</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>We thank <rs type="person">Ekin Akyurek</rs> for help installing and using the FTRACE-TREX benchmark.</p><p>Work supported in part by the <rs type="funder">NSF</rs> grants <rs type="grantNumber">CNS-1815221</rs> and <rs type="grantNumber">DMS-2134108</rs>, and <rs type="funder">Open Philanthropy</rs>. This material is based upon work supported by the <rs type="funder">Defense Advanced Research Projects Agency (DARPA)</rs> under Contract No. <rs type="grantNumber">HR001120C0015</rs>.</p><p>Research was sponsored by the <rs type="funder">United States Air Force Research Laboratory</rs> and the <rs type="funder">United States Air Force Artificial Intelligence Accelerator</rs> and was accomplished under Cooperative Agreement Number <rs type="grantNumber">FA8750-19-2-1000</rs>. The views and conclusions contained in this document are those of the authors and should not be interpreted as representing the official policies, either expressed or implied, of the <rs type="institution">United States Air Force</rs> or the <rs type="institution">U.S. Government. The U.S. Government</rs> is authorized to reproduce and distribute reprints for Government purposes notwithstanding any copyright notation herein.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_FKTWTW6">
					<idno type="grant-number">CNS-1815221</idno>
				</org>
				<org type="funding" xml:id="_gXVzEnK">
					<idno type="grant-number">DMS-2134108</idno>
				</org>
				<org type="funding" xml:id="_V3Pndtw">
					<idno type="grant-number">HR001120C0015</idno>
				</org>
				<org type="funding" xml:id="_ZxpHT3g">
					<idno type="grant-number">FA8750-19-2-1000</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendices</head><p>kernel (i.e., work with K = 1 n ∑ K i ), (ii) we can average their induced features (with respect to some fixed basis of functions) and use the corresponding kernel, or (iii) we can average the predictions derived from each kernel <ref type="bibr" target="#b3">[ABS+23]</ref>. TRAK's algorithm follows the third approach (Step 4).</p><p>Here we ensemble using the first approach instead (i.e., using the averaged eNTK). We do this by first averaging the Gram matrices corresponding to each models' eNTK, using the Cholesky decomposition to extract features from the averaged Gram matrix (G = LL ), then using resulting features L into the same influence formula (Step 3). We find that computing TRAK with this average eNTK gives a significantly underperforming estimator (LDS of 0.120 on CIFAR-2) than averaging after computing the estimator from each eNTK (LDS of 0.499). This gap suggests that the underlying model is better approximated as an ensemble of kernel predictors rather than a predictor based on a single kernel.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E.7 Summary</head><p>To summarize the results of our ablation, TRAK performs best when averaging over a sufficient number of models (though computationally cheaper alternatives also work); gradients computed at later epochs; and random projections to sufficiently high-but not too high-dimension. Using the reweighting matrix in Equation ( <ref type="formula">17</ref>), as well as deriving the features from the full model gradient are also both critical to TRAK's predictive performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F.3 Computing TRAK for masked language modeling</head><p>The model output function we use, more precisely, is given by:</p><p>In particular, to compute this model output function, we compute the model output function (19) for each one of the V-way classification problems separately, then define our model output function as the sum of these computed outputs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F.4 Counterfactual experiment setup</head><p>To understand the possible roots of TRAK's underperformance relative to BM25 on FTRACE-TREX, we carry out a counterfactual analysis. Specifically, for a subset of the FTRACE-TREX test set, we create three corresponding counterfactual training sets. Then, starting from a pre-trained mt5-small model (the same model that we finetuned in (B) above to identify novel facts), we finetune several models on each counterfactual training set, and compute their average accuracy on the selected subset of 50 novel facts. Note that, by construction, we know that on this subset (i) the pre-trained model has an accuracy of 0%; and (ii) finetuning on the entire FTRACE-TREX training set (i.e., with no examples removed) yields models with 100% accuracy. 29  As for the counterfactual training sets, one should note that:</p><p>• Counterfactual training set (c) is missing all of the proponents for our subset of 50 novel factswe would thus expect the corresponding finetuned model to have very low accuracy. In particular, there is ostensibly no direct evidence for any of the novel facts of interest anywhere in this counterfactual training set.</p><p>• Being constructed with BM25, counterfactual training set (b) has high lexical overlap with the novel facts of interest. Since BM25 performs well on the FTRACE-TREX benchmark, we would also expect the resulting models to have low accuracy.</p><p>In Figure <ref type="figure">9</ref>, we report the resulting models' average performance on the set of 50 selected novel facts. What we find is that, counter to the above intuition, only the TRAK-based counterfactual training set is able to significantly change model behavior. That is, the counterfactual effect of removing the most important images as identified by TRAK on the selected subset of novel facts is significantly higher than both (a) that of removing the most important images according to BM25; and (b) that of removing the ground-truth proponents of the facts as indicated by the FTRACE-TREX benchmark.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G Future Work</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G.1 Further applications of TRAK</head><p>Prior works have demonstrated the potential of leveraging data attribution for a variety of downstream applications, ranging from explaining predictions [KL17; KSH22], cleaning datasets <ref type="bibr" target="#b44">[JDW+19]</ref>, removing poisoned examples <ref type="bibr" target="#b60">[LZL+22]</ref> to quantifying uncertainty <ref type="bibr" target="#b7">[AV20]</ref>. Given the effectiveness of TRAK, we expect that using it in place of existing attribution methods will improve the performance in many of these downstream applications. Moreover, given its computational efficiency, TRAK can expand the settings in which these prior data attribution methods are feasible. Indeed, we already saw some examples in Section 5.3. We highlight a few promising directions in particular:</p><p>Fact tracing and attribution for generative models. Fact tracing, which we studied in Section 5.2, is a problem of increasing relevancy as large language models are widely deployed. Leveraging TRAK for fact tracing, or attribution more broadly, may help understand the capabilities or improve the trustworthiness of recent models such as GPT-3 [BMR+20] and ChatGPT, 30 by tracing their outputs back to sources in a way that is faithful to the actual model. More broadly, attribution for generative models (e.g., stable diffusion [HJA20; RBL+22]) is an interesting direction for future work.</p><p>Optimizing datasets. TRAK scores allow one to quantify the impact of individual training examples on model predictions on a given target example. By aggregating this information, we can optimize what data we train the models on, for instance, to choose coresets or to select new data for active learning. Given the trend of training models on ever increasing size of datasets <ref type="bibr" target="#b32">[HBM+22]</ref>, filtering data based on their TRAK scores can also help models achieve with the benefits of scale without the computational cost.</p><p>Another advantage of TRAK is that it is fully differentiable in the input (note that the associated gradients are different from the gradients with respect to model parameters that we use when computing TRAK). One potential direction is to leverage this differentiability for dataset distillation. Given the effectiveness of the NTK for this problem <ref type="bibr" target="#b67">[NNX+21]</ref>, there is potential in leveraging TRAK-which uses the eNTK-in this setting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G.2 Understanding and improving the TRAK estimator</head><p>Empirical NTK. TRAK leverages the empirical NTK to approximate the original model. Better understanding of when this approximation is accurate may give insights into improving TRAK's efficacy. For example, incorporating higher order approximations [HY20; BL20] beyond the linear approximation used in TRAK is a possible direction.</p><p>Training dynamics and optimization. Prior works [LM20; LBD+20] suggest that neural network training can exhibit two stages or regimes: in the first stage, the features learned by the network evolve rapidly; in the second stage, the features remain approximately invariant and the overall optimization trajectory is more akin a convex setting. We can view our use of the final eNTK as modeling this second stage. Understanding the extent to which the first stage (which TRAK does not model) accounts for the remaining gap between true model outputs and TRAK's predictions may help us understand the limits of method as well as improve Another direction is to study whether properly accounting for other optimization components used during training, such as mini-batches, momentum, or weight decay, can improve our estimator.</p><p>Ensembles. As we saw in Appendix E.2, computing TRAK over an ensemble of models significantly improves its efficacy. In particular, our results suggest that the eNTK's derived from independently trained models capture non-overlapping information. Better understanding of the role of ensembling here may us better understand the mechanisms underlying ensembles in other contexts and can also provide practical insights for improving TRAK's efficiency. For instance, understanding when model checkpoints from a single trajectory can approximate the full ensemble (Appendix E.3) can be valuable in settings where it is expensive to even finetune several models.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Second-order stochastic optimization for machine learning in linear time</title>
		<author>
			<persName><forename type="first">Naman</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brian</forename><surname>Bullins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elad</forename><surname>Hazan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Naman Agarwal, Brian Bullins, and Elad Hazan. &quot;Second-order stochastic optimiza- tion for machine learning in linear time&quot;. In: The Journal of Machine Learning Research. 2017.</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Towards Tracing Factual Knowledge in Language Models Back to the Training Data</title>
		<author>
			<persName><forename type="first">Ekin</forename><surname>Akyurek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tolga</forename><surname>Bolukbasi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frederick</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Binbin</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ian</forename><surname>Tenney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Andreas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kelvin</forename><surname>Guu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of EMNLP</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Ekin Akyurek, Tolga Bolukbasi, Frederick Liu, Binbin Xiong, Ian Tenney, Jacob An- dreas, and Kelvin Guu. &quot;Towards Tracing Factual Knowledge in Language Models Back to the Training Data&quot;. In: Findings of EMNLP. 2022.</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Neural networks as kernel learners: The silent alignment effect</title>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Atanasov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Blake</forename><surname>Bordelon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cengiz</forename><surname>Pehlevan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICLR</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Alexander Atanasov, Blake Bordelon, and Cengiz Pehlevan. &quot;Neural networks as kernel learners: The silent alignment effect&quot;. In: ICLR. 2022.</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The Onset of Variance-Limited Behavior for Networks in the Lazy and Rich Regimes</title>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Atanasov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Blake</forename><surname>Bordelon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sabarish</forename><surname>Sainathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cengiz</forename><surname>Pehlevan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICLR</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Alexander Atanasov, Blake Bordelon, Sabarish Sainathan, and Cengiz Pehlevan. &quot;The Onset of Variance-Limited Behavior for Networks in the Lazy and Rich Regimes&quot;. In: ICLR. 2023.</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Fine-Grained Analysis of Optimization and Generalization for Overparameterized Two-Layer Neural Networks</title>
		<author>
			<persName><forename type="first">Sanjeev</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simon</forename><forename type="middle">S</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiyuan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruosong</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Sanjeev Arora, Simon S. Du, Wei Hu, Zhiyuan Li, and Ruosong Wang. &quot;Fine-Grained Analysis of Optimization and Generalization for Overparameterized Two-Layer Neu- ral Networks&quot;. In: International Conference on Machine Learning (ICML). 2019.</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Lqf: Linear quadratic fine-tuning</title>
		<author>
			<persName><forename type="first">Alessandro</forename><surname>Achille</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Golatkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Avinash</forename><surname>Ravichandran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marzia</forename><surname>Polito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefano</forename><surname>Soatto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Alessandro Achille, Aditya Golatkar, Avinash Ravichandran, Marzia Polito, and Stefano Soatto. &quot;Lqf: Linear quadratic fine-tuning&quot;. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2021.</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">The principle of minimized iterations in the solution of the matrix eigenvalue problem</title>
		<author>
			<persName><forename type="first">Walter</forename><surname>Edwin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arnoldi</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Quarterly of applied mathematics</title>
		<imprint>
			<date type="published" when="1951">1951</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Walter Edwin Arnoldi. &quot;The principle of minimized iterations in the solution of the matrix eigenvalue problem&quot;. In: Quarterly of applied mathematics. 1951.</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Discriminative jackknife: Quantifying uncertainty in deep learning via higher-order influence functions</title>
		<author>
			<persName><forename type="first">Ahmed</forename><surname>Alaa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mihaela</forename><surname>Van</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Der</forename><surname>Schaar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Ahmed Alaa and Mihaela Van Der Schaar. &quot;Discriminative jackknife: Quantifying uncertainty in deep learning via higher-order influence functions&quot;. In: International Conference on Machine Learning. 2020.</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Generalization through the lens of leave-one-out error</title>
		<author>
			<persName><forename type="first">Gregor</forename><surname>Bachmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Hofmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aurélien</forename><surname>Lucchi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2203.03443.2022</idno>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note type="raw_reference">Gregor Bachmann, Thomas Hofmann, and Aurélien Lucchi. &quot;Generalization through the lens of leave-one-out error&quot;. In: arXiv preprint arXiv:2203.03443. 2022.</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Beyond linearization: On quadratic and higher-order approximation of wide neural networks</title>
		<author>
			<persName><forename type="first">Yu</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><forename type="middle">D</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICLR</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Yu Bai and Jason D Lee. &quot;Beyond linearization: On quadratic and higher-order ap- proximation of wide neural networks&quot;. In: ICLR. 2020.</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Random projection, margins, kernels, and feature-selection</title>
		<author>
			<persName><forename type="first">Avrim</forename><surname>Blum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Lecture notes in computer science</title>
		<imprint>
			<date type="published" when="2006">2006</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
	<note type="raw_reference">Avrim Blum. &quot;Random projection, margins, kernels, and feature-selection&quot;. In: Lecture notes in computer science. Springer, 2006.</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Language models are few-shot learners</title>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Tom B Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nick</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Melanie</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jared</forename><surname>Subbiah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prafulla</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arvind</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pranav</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Girish</forename><surname>Shyam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amanda</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName><surname>Askell</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.14165</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note type="raw_reference">Tom B Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. &quot;Language models are few-shot learners&quot;. In: arXiv preprint arXiv:2005.14165 (2020).</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">If Influence Functions are the Answer, Then What is the Question?</title>
		<author>
			<persName><forename type="first">Juhan</forename><surname>Bae</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nathan</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alston</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marzyeh</forename><surname>Ghassemi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roger</forename><surname>Grosse</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2209.05364.2022</idno>
		<imprint/>
	</monogr>
	<note type="report_type">ArXiv preprint</note>
	<note type="raw_reference">Juhan Bae, Nathan Ng, Alston Lo, Marzyeh Ghassemi, and Roger Grosse. &quot;If In- fluence Functions are the Answer, Then What is the Question?&quot; In: ArXiv preprint arXiv:2209.05364. 2022.</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Influence Functions in Deep Learning Are Fragile</title>
		<author>
			<persName><forename type="first">Samyadeep</forename><surname>Basu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Phillip</forename><surname>Pope</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Soheil</forename><surname>Feizi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<publisher>ICLR</publisher>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Samyadeep Basu, Phillip Pope, and Soheil Feizi. &quot;Influence Functions in Deep Learn- ing Are Fragile&quot;. In: International Conference on Learning Representations (ICLR). 2021.</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Attributed Question Answering: Evaluation and Modeling for Attributed Large Language Models</title>
		<author>
			<persName><forename type="first">Bernd</forename><surname>Bohnet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pat</forename><surname>Vinh Q Tran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roee</forename><surname>Verga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Aharoni</surname></persName>
		</author>
		<author>
			<persName><surname>Andor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Baldini</forename><surname>Livio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Soares</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kuzman</forename><surname>Eisenstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Ganchev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai</forename><surname>Herzig</surname></persName>
		</author>
		<author>
			<persName><surname>Hui</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2212.08037.2022</idno>
		<imprint/>
	</monogr>
	<note type="report_type">Arxiv preprint</note>
	<note type="raw_reference">Bernd Bohnet, Vinh Q Tran, Pat Verga, Roee Aharoni, Daniel Andor, Livio Baldini Soares, Jacob Eisenstein, Kuzman Ganchev, Jonathan Herzig, Kai Hui, et al. &quot;At- tributed Question Answering: Evaluation and Modeling for Attributed Large Lan- guage Models&quot;. In: Arxiv preprint arXiv:2212.08037. 2022.</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Second-Order Group Influence Functions for Black-Box Predictions</title>
		<author>
			<persName><forename type="first">Samyadeep</forename><surname>Basu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuchen</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Soheil</forename><surname>Feizi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Samyadeep Basu, Xuchen You, and Soheil Feizi. &quot;Second-Order Group Influence Functions for Black-Box Predictions&quot;. In: International Conference on Machine Learning (ICML). 2019.</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Reproducible scaling laws for contrastive language-image learning</title>
		<author>
			<persName><forename type="first">Mehdi</forename><surname>Cherti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Romain</forename><surname>Beaumont</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ross</forename><surname>Wightman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mitchell</forename><surname>Wortsman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gabriel</forename><surname>Ilharco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cade</forename><surname>Gordon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christoph</forename><surname>Schuhmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ludwig</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jenia</forename><surname>Jitsev</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2212.07143.2022</idno>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note type="raw_reference">Mehdi Cherti, Romain Beaumont, Ross Wightman, Mitchell Wortsman, Gabriel Il- harco, Cade Gordon, Christoph Schuhmann, Ludwig Schmidt, and Jenia Jitsev. &quot;Re- producible scaling laws for contrastive language-image learning&quot;. In: arXiv preprint arXiv:2212.07143. 2022.</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Quantifying memorization across neural language models</title>
		<author>
			<persName><forename type="first">Nicholas</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daphne</forename><surname>Ippolito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Jagielski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katherine</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Florian</forename><surname>Tramer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chiyuan</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2202.07646.2022</idno>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note type="raw_reference">Nicholas Carlini, Daphne Ippolito, Matthew Jagielski, Katherine Lee, Florian Tramer, and Chiyuan Zhang. &quot;Quantifying memorization across neural language models&quot;. In: arXiv preprint arXiv:2202.07646. 2022.</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Careful Data Curation Stabilizes In-context Learning</title>
		<author>
			<persName><forename type="first">Ting-Yun</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robin</forename><surname>Jia</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2212.10378.2022</idno>
		<imprint/>
	</monogr>
	<note type="report_type">Arxiv preprint</note>
	<note type="raw_reference">Ting-Yun Chang and Robin Jia. &quot;Careful Data Curation Stabilizes In-context Learning&quot;. In: Arxiv preprint arXiv:2212.10378. 2022.</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<author>
			<persName><forename type="first">Dennis</forename><surname>Cook</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sanford</forename><surname>Weisberg</surname></persName>
		</author>
		<title level="m">Residuals and influence in regression</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Chapman and Hall</publisher>
			<date type="published" when="1982">1982</date>
		</imprint>
	</monogr>
	<note type="raw_reference">R Dennis Cook and Sanford Weisberg. Residuals and influence in regression. New York: Chapman and Hall, 1982.</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">A linearized framework and a new benchmark for model selection for fine-tuning</title>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Deshpande</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alessandro</forename><surname>Achille</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Avinash</forename><surname>Ravichandran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luca</forename><surname>Zancato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charless</forename><surname>Fowlkes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rahul</forename><surname>Bhotika</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefano</forename><surname>Soatto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pietro</forename><surname>Perona</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2102.00084.2021</idno>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note type="raw_reference">Aditya Deshpande, Alessandro Achille, Avinash Ravichandran, Hao Li, Luca Zancato, Charless Fowlkes, Rahul Bhotika, Stefano Soatto, and Pietro Perona. &quot;A linearized framework and a new benchmark for model selection for fine-tuning&quot;. In: arXiv preprint arXiv:2102.00084. 2021.</note>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Bert: Pretraining of deep bidirectional transformers for language understanding</title>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. &quot;Bert: Pre- training of deep bidirectional transformers for language understanding&quot;. In: (2019).</note>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Underspecification Presents Challenges for Credibility in Modern Machine Learning</title>
		<author>
			<persName><forename type="first">Katherine</forename><forename type="middle">A</forename><surname>Alexander D'amour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Heller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>Moldovan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Babak</forename><surname>Adlam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Alipanahi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christina</forename><surname>Beutel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Deaton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><forename type="middle">D</forename><surname>Eisenstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Farhad</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Neil</forename><surname>Hormozdiari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shaobo</forename><surname>Houlsby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ghassen</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alan</forename><surname>Jerfel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mario</forename><surname>Karthikesalingam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi-An</forename><surname>Lucic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cory</forename><forename type="middle">Y</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diana</forename><surname>Mclean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Akinori</forename><surname>Mincu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrea</forename><surname>Mitani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zachary</forename><surname>Montanari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vivek</forename><surname>Nado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Natarajan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><forename type="middle">F</forename><surname>Nielson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rajiv</forename><surname>Osborne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kim</forename><surname>Raman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rory</forename><surname>Ramasamy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jessica</forename><surname>Sayres</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Schrouff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shannon</forename><surname>Seneviratne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Harini</forename><surname>Sequeira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Victor</forename><surname>Suresh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Veitch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuezhi</forename><surname>Vladymyrov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kellie</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steve</forename><surname>Webster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Taedong</forename><surname>Yadlowsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaohua</forename><surname>Yun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName><surname>Sculley</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2011.03395.2020</idno>
		<imprint/>
	</monogr>
	<note type="report_type">Arxiv preprint</note>
	<note type="raw_reference">Alexander D&apos;Amour, Katherine A. Heller, Dan Moldovan, Ben Adlam, Babak Ali- panahi, Alex Beutel, Christina Chen, Jonathan Deaton, Jacob Eisenstein, Matthew D. Hoffman, Farhad Hormozdiari, Neil Houlsby, Shaobo Hou, Ghassen Jerfel, Alan Karthikesalingam, Mario Lucic, Yi-An Ma, Cory Y. McLean, Diana Mincu, Akinori Mitani, Andrea Montanari, Zachary Nado, Vivek Natarajan, Christopher Nielson, Thomas F. Osborne, Rajiv Raman, Kim Ramasamy, Rory Sayres, Jessica Schrouff, Mar- tin Seneviratne, Shannon Sequeira, Harini Suresh, Victor Veitch, Max Vladymyrov, Xuezhi Wang, Kellie Webster, Steve Yadlowsky, Taedong Yun, Xiaohua Zhai, and D. Sculley. &quot;Underspecification Presents Challenges for Credibility in Modern Machine Learning&quot;. In: Arxiv preprint arXiv:2011.03395. 2020.</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">De-noising by soft-thresholding</title>
		<author>
			<persName><forename type="first">L</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName><surname>Donoho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Theory</title>
		<imprint>
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
	<note type="raw_reference">David L Donoho. &quot;De-noising by soft-thresholding&quot;. In: IEEE Transactions on Informa- tion Theory. 1995.</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">T-rex: A large scale alignment of natural language with knowledge base triples</title>
		<author>
			<persName><forename type="first">Hady</forename><surname>Elsahar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pavlos</forename><surname>Vougiouklis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arslen</forename><surname>Remaci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christophe</forename><surname>Gravier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathon</forename><surname>Hare</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frederique</forename><surname>Laforest</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elena</forename><surname>Simperl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC 2018)</title>
		<meeting>the Eleventh International Conference on Language Resources and Evaluation (LREC 2018)</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Hady Elsahar, Pavlos Vougiouklis, Arslen Remaci, Christophe Gravier, Jonathon Hare, Frederique Laforest, and Elena Simperl. &quot;T-rex: A large scale alignment of natural language with knowledge base triples&quot;. In: Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC 2018). 2018.</note>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Data Determines Distributional Robustness in Contrastive Language Image Pre-training (CLIP)</title>
		<author>
			<persName><forename type="first">Alex</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gabriel</forename><surname>Ilharco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mitchell</forename><surname>Wortsman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuhao</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vaishaal</forename><surname>Shankar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Achal</forename><surname>Dave</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ludwig</forename><surname>Schmidt</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
			<publisher>ICML</publisher>
		</imprint>
	</monogr>
	<note type="raw_reference">Alex Fang, Gabriel Ilharco, Mitchell Wortsman, Yuhao Wan, Vaishaal Shankar, Achal Dave, and Ludwig Schmidt. &quot;Data Determines Distributional Robustness in Con- trastive Language Image Pre-training (CLIP)&quot;. In: ICML. 2022.</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">What Neural Networks Memorize and Why: Discovering the Long Tail via Influence Estimation</title>
		<author>
			<persName><forename type="first">Vitaly</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chiyuan</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="2881" to="2891" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Vitaly Feldman and Chiyuan Zhang. &quot;What Neural Networks Memorize and Why: Discovering the Long Tail via Influence Estimation&quot;. In: Advances in Neural Information Processing Systems (NeurIPS). Vol. 33. 2020, pp. 2881-2891.</note>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Convergence of Adversarial Training in Overparametrized Networks</title>
		<author>
			<persName><forename type="first">Ruiqi</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianle</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haochuan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liwei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cho-Jui</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><forename type="middle">D</forename><surname>Lee</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.07916</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note type="raw_reference">Ruiqi Gao, Tianle Cai, Haochuan Li, Liwei Wang, Cho-Jui Hsieh, and Jason D Lee. &quot;Convergence of Adversarial Training in Overparametrized Networks&quot;. In: arXiv preprint arXiv:1906.07916 (2019).</note>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Badnets: Identifying Vulnerabilities in the Machine Learning Model Supply Chain</title>
		<author>
			<persName><forename type="first">Tianyu</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brendan</forename><surname>Dolan-Gavitt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siddharth</forename><surname>Garg</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.06733</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note type="raw_reference">Tianyu Gu, Brendan Dolan-Gavitt, and Siddharth Garg. &quot;Badnets: Identifying Vulnera- bilities in the Machine Learning Model Supply Chain&quot;. In: arXiv preprint arXiv:1708.06733 (2017).</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">ImageNet-trained CNNs are biased towards texture; increasing shape bias improves accuracy and robustness</title>
		<author>
			<persName><forename type="first">Robert</forename><surname>Geirhos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patricia</forename><surname>Rubisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Claudio</forename><surname>Michaelis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthias</forename><surname>Bethge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Felix</forename><forename type="middle">A</forename><surname>Wichmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wieland</forename><surname>Brendel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Robert Geirhos, Patricia Rubisch, Claudio Michaelis, Matthias Bethge, Felix A. Wich- mann, and Wieland Brendel. &quot;ImageNet-trained CNNs are biased towards texture; increasing shape bias improves accuracy and robustness.&quot; In: International Conference on Learning Representations (ICLR). 2019.</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Data shapley: Equitable valuation of data for machine learning</title>
		<author>
			<persName><forename type="first">Amirata</forename><surname>Ghorbani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Zou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Amirata Ghorbani and James Zou. &quot;Data shapley: Equitable valuation of data for machine learning&quot;. In: International Conference on Machine Learning (ICML). 2019.</note>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">What makes ImageNet good for transfer learning?</title>
		<author>
			<persName><forename type="first">Minyoung</forename><surname>Huh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pulkit</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexei</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1608.08614</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note type="raw_reference">Minyoung Huh, Pulkit Agrawal, and Alexei A Efros. &quot;What makes ImageNet good for transfer learning?&quot; In: arXiv preprint arXiv:1608.08614 (2016).</note>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Training compute-optimal large language models</title>
		<author>
			<persName><forename type="first">Jordan</forename><surname>Hoffmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Borgeaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arthur</forename><surname>Mensch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elena</forename><surname>Buchatskaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Trevor</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eliza</forename><surname>Rutherford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diego</forename><surname>De Las</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lisa</forename><forename type="middle">Anne</forename><surname>Casas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Johannes</forename><surname>Hendricks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aidan</forename><surname>Welbl</surname></persName>
		</author>
		<author>
			<persName><surname>Clark</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2203.15556.2022</idno>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note type="raw_reference">Jordan Hoffmann, Sebastian Borgeaud, Arthur Mensch, Elena Buchatskaya, Trevor Cai, Eliza Rutherford, Diego de Las Casas, Lisa Anne Hendricks, Johannes Welbl, Aidan Clark, et al. &quot;Training compute-optimal large language models&quot;. In: arXiv preprint arXiv:2203.15556. 2022.</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Denoising Diffusion Probabilistic Models</title>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ajay</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Jonathan Ho, Ajay Jain, and Pieter Abbeel. &quot;Denoising Diffusion Probabilistic Models&quot;. In: Neural Information Processing Systems (NeurIPS). 2020.</note>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Identifying a Training-Set Attack&apos;s Target Using Renormalized Influence Estimation</title>
		<author>
			<persName><forename type="first">Zayd</forename><surname>Hammoudeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Lowd</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2201.10055.2022</idno>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note type="raw_reference">Zayd Hammoudeh and Daniel Lowd. &quot;Identifying a Training-Set Attack&apos;s Target Using Renormalized Influence Estimation&quot;. In: arXiv preprint arXiv:2201.10055. 2022.</note>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Training Data Influence Analysis and Estimation: A Survey</title>
		<author>
			<persName><forename type="first">Zayd</forename><surname>Hammoudeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Lowd</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2212.04612.2022</idno>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note type="raw_reference">Zayd Hammoudeh and Daniel Lowd. &quot;Training Data Influence Analysis and Estima- tion: A Survey&quot;. In: arXiv preprint arXiv:2212.04612. 2022.</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Integrating NLP using linked data</title>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Hellmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jens</forename><surname>Lehmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sören</forename><surname>Auer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Brümmer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Semantic Web-ISWC 2013: 12th International Semantic Web Conference</title>
		<meeting><address><addrLine>Sydney, NSW, Australia</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013">October 21-25, 2013. 2013</date>
			<biblScope unit="page" from="98" to="113" />
		</imprint>
	</monogr>
	<note>Part II 12</note>
	<note type="raw_reference">Sebastian Hellmann, Jens Lehmann, Sören Auer, and Martin Brümmer. &quot;Integrating NLP using linked data&quot;. In: The Semantic Web-ISWC 2013: 12th International Semantic Web Conference, Sydney, NSW, Australia, October 21-25, 2013, Proceedings, Part II 12. Springer. 2013, pp. 98-113.</note>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Robust statistics: the approach based on influence functions</title>
		<author>
			<persName><surname>Frank R Hampel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Elvezio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><forename type="middle">J</forename><surname>Ronchetti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Werner</forename><forename type="middle">A</forename><surname>Rousseeuw</surname></persName>
		</author>
		<author>
			<persName><surname>Stahel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
			<publisher>John Wiley &amp; Sons</publisher>
			<biblScope unit="volume">196</biblScope>
		</imprint>
	</monogr>
	<note type="raw_reference">Frank R Hampel, Elvezio M Ronchetti, Peter J Rousseeuw, and Werner A Stahel. Robust statistics: the approach based on influence functions. Vol. 196. John Wiley &amp; Sons, 2011.</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Dynamics of Deep Neural Networks and Neural Tangent Hierarchy</title>
		<author>
			<persName><forename type="first">Jiaoyang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Horng-Tzer</forename><surname>Yau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 37th International Conference on Machine Learning</title>
		<meeting>the 37th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Jiaoyang Huang and Horng-Tzer Yau. &quot;Dynamics of Deep Neural Networks and Neural Tangent Hierarchy&quot;. In: Proceedings of the 37th International Conference on Machine Learning. 2020.</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Evaluation of similaritybased explanations</title>
		<author>
			<persName><forename type="first">Kazuaki</forename><surname>Hanawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sho</forename><surname>Yokoi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Satoshi</forename><surname>Hara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kentaro</forename><surname>Inui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<publisher>ICLR</publisher>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Kazuaki Hanawa, Sho Yokoi, Satoshi Hara, and Kentaro Inui. &quot;Evaluation of similarity- based explanations&quot;. In: International Conference on Learning Representations (ICLR). 2021.</note>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">A framework and benchmark for deep batch active learning for regression</title>
		<author>
			<persName><forename type="first">David</forename><surname>Holzmüller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Johannes</forename><surname>Viktor Zaverkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ingo</forename><surname>Kästner</surname></persName>
		</author>
		<author>
			<persName><surname>Steinwart</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2203.09410</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note type="raw_reference">David Holzmüller, Viktor Zaverkin, Johannes Kästner, and Ingo Steinwart. &quot;A frame- work and benchmark for deep batch active learning for regression&quot;. In: arXiv preprint arXiv:2203.09410 (2022).</note>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Deep Residual Learning for Image Recognition</title>
		<author>
			<persName><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep Residual Learning for Image Recognition. 2015.</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Datamodels: Predicting Predictions from Training Data</title>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Ilyas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Min</forename><surname>Sung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Logan</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guillaume</forename><surname>Engstrom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aleksander</forename><surname>Leclerc</surname></persName>
		</author>
		<author>
			<persName><surname>Madry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Andrew Ilyas, Sung Min Park, Logan Engstrom, Guillaume Leclerc, and Aleksander Madry. &quot;Datamodels: Predicting Predictions from Training Data&quot;. In: International Conference on Machine Learning (ICML). 2022.</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Adversarial Examples Are Not Bugs, They Are Features</title>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Ilyas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shibani</forename><surname>Santurkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dimitris</forename><surname>Tsipras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Logan</forename><surname>Engstrom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brandon</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aleksander</forename><surname>Madry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Information Processing Systems</title>
		<imprint>
			<publisher>NeurIPS</publisher>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Andrew Ilyas, Shibani Santurkar, Dimitris Tsipras, Logan Engstrom, Brandon Tran, and Aleksander Madry. &quot;Adversarial Examples Are Not Bugs, They Are Features&quot;. In: Neural Information Processing Systems (NeurIPS). 2019.</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Towards Efficient Data Valuation Based on the Shapley Value</title>
		<author>
			<persName><forename type="first">Ruoxi</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Dao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Boxin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frances</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Ann</forename><surname>Hubis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nick</forename><surname>Hynes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nezihe</forename><forename type="middle">Merve</forename><surname>Gürel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bo</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ce</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dawn</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Costas</forename><forename type="middle">J</forename><surname>Spanos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Second International Conference on Artificial Intelligence and Statistics</title>
		<meeting>the Twenty-Second International Conference on Artificial Intelligence and Statistics</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Ruoxi Jia, David Dao, Boxin Wang, Frances Ann Hubis, Nick Hynes, Nezihe Merve Gürel, Bo Li, Ce Zhang, Dawn Song, and Costas J. Spanos. &quot;Towards Efficient Data Val- uation Based on the Shapley Value&quot;. In: Proceedings of the Twenty-Second International Conference on Artificial Intelligence and Statistics. 2019.</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Neural Tangent Kernel: Convergence and Generalization in Neural Networks</title>
		<author>
			<persName><forename type="first">Arthur</forename><surname>Jacot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Franck</forename><surname>Gabriel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clement</forename><surname>Hongler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Arthur Jacot, Franck Gabriel, and Clement Hongler. &quot;Neural Tangent Kernel: Con- vergence and Generalization in Neural Networks&quot;. In: Neural Information Processing Systems (NeurIPS). 2018.</note>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Extensions of Lipschitz mappings into a Hilbert space</title>
		<author>
			<persName><forename type="first">B</forename><surname>William</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joram</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><surname>Lindenstrauss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Contemporary mathematics</title>
		<imprint>
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
	<note type="raw_reference">William B Johnson and Joram Lindenstrauss. &quot;Extensions of Lipschitz mappings into a Hilbert space&quot;. In: Contemporary mathematics. 1984.</note>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Scalability vs. Utility: Do We Have to Sacrifice One for the Other in Data Importance Quantification?</title>
		<author>
			<persName><forename type="first">Ruoxi</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuehui</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiacen</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Dao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bhavya</forename><surname>Kailkhura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ce</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bo</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dawn</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Ruoxi Jia, Fan Wu, Xuehui Sun, Jiacen Xu, David Dao, Bhavya Kailkhura, Ce Zhang, Bo Li, and Dawn Song. &quot;Scalability vs. Utility: Do We Have to Sacrifice One for the Other in Data Importance Quantification?&quot; In: Proceedings of the 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). 2021.</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">On the accuracy of influence functions for measuring group effects</title>
		<author>
			<persName><forename type="first">Pang</forename><surname>Wei Koh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai-Siang</forename><surname>Ang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hubert Hk</forename><surname>Teo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Information Processing Systems</title>
		<imprint>
			<publisher>NeurIPS</publisher>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Pang Wei Koh, Kai-Siang Ang, Hubert HK Teo, and Percy Liang. &quot;On the accuracy of influence functions for measuring group effects&quot;. In: Neural Information Processing Systems (NeurIPS). 2019.</note>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Interpreting black box predictions using fisher kernels</title>
		<author>
			<persName><forename type="first">Rajiv</forename><surname>Khanna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Been</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joydeep</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sanmi</forename><surname>Koyejo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 22nd International Conference on Artificial Intelligence and Statistics</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Rajiv Khanna, Been Kim, Joydeep Ghosh, and Sanmi Koyejo. &quot;Interpreting black box predictions using fisher kernels&quot;. In: The 22nd International Conference on Artificial Intelligence and Statistics. 2019.</note>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Understanding Black-box Predictions via Influence Functions</title>
		<author>
			<persName><forename type="first">Pang</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Koh</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Pang Wei Koh and Percy Liang. &quot;Understanding Black-box Predictions via Influence Functions&quot;. In: International Conference on Machine Learning. 2017.</note>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Learning Multiple Layers of Features from Tiny Images</title>
		<author>
			<persName><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
	<note type="raw_reference">Alex Krizhevsky. &quot;Learning Multiple Layers of Features from Tiny Images&quot;. In: Technical report. 2009.</note>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Resolving Training Biases via Influence-based Data Relabeling</title>
		<author>
			<persName><forename type="first">Shuming</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanyan</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Linpeng</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Shuming Kong, Yanyan Shen, and Linpeng Huang. &quot;Resolving Training Biases via Influence-based Data Relabeling&quot;. In: International Conference on Learning Representa- tions (ICLR). 2022.</note>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">The large learning rate phase of deep learning: the catapult mechanism</title>
		<author>
			<persName><forename type="first">Aitor</forename><surname>Lewkowycz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yasaman</forename><surname>Bahri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ethan</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jascha</forename><surname>Sohl-Dickstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guy</forename><surname>Gur-Ari</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.02218.2020</idno>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note type="raw_reference">Aitor Lewkowycz, Yasaman Bahri, Ethan Dyer, Jascha Sohl-Dickstein, and Guy Gur- Ari. &quot;The large learning rate phase of deep learning: the catapult mechanism&quot;. In: arXiv preprint arXiv:2003.02218. 2020.</note>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Influence Selection for Active Learning</title>
		<author>
			<persName><forename type="first">Zhuoming</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huaping</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weijia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jifeng</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Conghui</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Zhuoming Liu, Hao Ding, Huaping Zhong, Weijia Li, Jifeng Dai, and Conghui He. &quot;Influence Selection for Active Learning&quot;. In: ICCV. 2021.</note>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Deduplicating Training Data Makes Language Models Better</title>
		<author>
			<persName><forename type="first">Katherine</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daphne</forename><surname>Ippolito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Nystrom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chiyuan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Douglas</forename><surname>Eck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicholas</forename><surname>Carlini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Katherine Lee, Daphne Ippolito, Andrew Nystrom, Chiyuan Zhang, Douglas Eck, Chris Callison-Burch, and Nicholas Carlini. &quot;Deduplicating Training Data Makes Language Models Better&quot;. In: Annual Meeting of the Association for Computational Linguistics (ACL). 2022.</note>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">A unified approach to interpreting model predictions</title>
		<author>
			<persName><forename type="first">Scott</forename><surname>Lundberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Su-In</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Scott Lundberg and Su-In Lee. &quot;A unified approach to interpreting model predictions&quot;. In: Neural Information Processing Systems (NeurIPS). 2017.</note>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">The two regimes of deep network training</title>
		<author>
			<persName><forename type="first">Guillaume</forename><surname>Leclerc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aleksander</forename><surname>Madry</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.10376.2020</idno>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note type="raw_reference">Guillaume Leclerc and Aleksander Madry. &quot;The two regimes of deep network train- ing&quot;. In: arXiv preprint arXiv:2002.10376. 2020.</note>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Microsoft coco: Common objects in context</title>
		<author>
			<persName><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pietro</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Deva</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Piotr</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lawrence</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zitnick</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision (ECCV)</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva Ra- manan, Piotr Dollár, and C Lawrence Zitnick. &quot;Microsoft coco: Common objects in context&quot;. In: European conference on computer vision (ECCV). 2014.</note>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<title level="m" type="main">Properties of the after kernel</title>
		<author>
			<persName><forename type="first">M</forename><surname>Philip</surname></persName>
		</author>
		<author>
			<persName><surname>Long</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2105.10585.2021</idno>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note type="raw_reference">Philip M Long. &quot;Properties of the after kernel&quot;. In: arXiv preprint arXiv:2105.10585. 2021.</note>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title level="m" type="main">Measuring the Effect of Training Data on Deep Learning Predictions via Randomized Experiments</title>
		<author>
			<persName><forename type="first">Jinkun</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anqi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mathias</forename><surname>Lecuyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinyang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aurojit</forename><surname>Panda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siddhartha</forename><surname>Sen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2206.10013</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note type="raw_reference">Jinkun Lin, Anqi Zhang, Mathias Lecuyer, Jinyang Li, Aurojit Panda, and Siddhartha Sen. &quot;Measuring the Effect of Training Data on Deep Learning Predictions via Ran- domized Experiments&quot;. In: arXiv preprint arXiv:2206.10013 (2022).</note>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">New insights and perspectives on the natural gradient method</title>
		<author>
			<persName><forename type="first">James</forename><surname>Martens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="raw_reference">James Martens. &quot;New insights and perspectives on the natural gradient method&quot;. In: The Journal of Machine Learning Research. 2020.</note>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<title level="m" type="main">Behind the Scenes of Gradient Descent: A Trajectory Analysis via Basis Function Decomposition</title>
		<author>
			<persName><forename type="first">Jianhao</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lingjun</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Salar</forename><surname>Fattahi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2210.00346.2022</idno>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note type="raw_reference">Jianhao Ma, Lingjun Guo, and Salar Fattahi. &quot;Behind the Scenes of Gradient De- scent: A Trajectory Analysis via Basis Function Decomposition&quot;. In: arXiv preprint arXiv:2210.00346. 2022.</note>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Gradients as features for deep representation learning</title>
		<author>
			<persName><forename type="first">Fangzhou</forename><surname>Mu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yingyu</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yin</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICLR</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Fangzhou Mu, Yingyu Liang, and Yin Li. &quot;Gradients as features for deep representa- tion learning&quot;. In: ICLR. 2020.</note>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Compressed least-squares regression</title>
		<author>
			<persName><forename type="first">Odalric</forename><surname>Maillard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rémi</forename><surname>Munos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Odalric Maillard and Rémi Munos. &quot;Compressed least-squares regression&quot;. In: Ad- vances in Neural Information Processing Systems. 2009.</note>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Fast adaptation with linearized neural networks</title>
		<author>
			<persName><forename type="first">Wesley</forename><surname>Maddox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuai</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pablo</forename><surname>Moreno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Gordon Wilson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Damianou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Artificial Intelligence and Statistics</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Wesley Maddox, Shuai Tang, Pablo Moreno, Andrew Gordon Wilson, and Andreas Damianou. &quot;Fast adaptation with linearized neural networks&quot;. In: International Con- ference on Artificial Intelligence and Statistics. 2021.</note>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
		<title level="m" type="main">A kernel-based view of language model fine-tuning</title>
		<author>
			<persName><forename type="first">Sadhika</forename><surname>Malladi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Wettig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dingli</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sanjeev</forename><surname>Arora</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2210.05643.2022</idno>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note type="raw_reference">Sadhika Malladi, Alexander Wettig, Dingli Yu, Danqi Chen, and Sanjeev Arora. &quot;A kernel-based view of language model fine-tuning&quot;. In: arXiv preprint arXiv:2210.05643. 2022.</note>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Dataset distillation with infinitely wide convolutional networks</title>
		<author>
			<persName><forename type="first">Timothy</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roman</forename><surname>Novak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lechao</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaehoon</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="5186" to="5198" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Timothy Nguyen, Roman Novak, Lechao Xiao, and Jaehoon Lee. &quot;Dataset distillation with infinitely wide convolutional networks&quot;. In: Advances in Neural Information Processing Systems 34 (2021), pp. 5186-5198.</note>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Do Wide and Deep Networks Learn the Same Things? Uncovering How Neural Network Representations Vary with Width and Depth</title>
		<author>
			<persName><forename type="first">Thao</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maithra</forename><surname>Raghu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simon</forename><surname>Kornblith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<publisher>ICLR</publisher>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Thao Nguyen, Maithra Raghu, and Simon Kornblith. &quot;Do Wide and Deep Networks Learn the Same Things? Uncovering How Neural Network Representations Vary with Width and Depth&quot;. In: International Conference on Learning Representations (ICLR). 2021.</note>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Estimating Training Data Influence by Tracing Gradient Descent</title>
		<author>
			<persName><forename type="first">Garima</forename><surname>Pruthi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frederick</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mukund</forename><surname>Sundararajan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Satyen</forename><surname>Kale</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Garima Pruthi, Frederick Liu, Mukund Sundararajan, and Satyen Kale. &quot;Estimating Training Data Influence by Tracing Gradient Descent&quot;. In: Neural Information Processing Systems (NeurIPS). 2020.</note>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Logistic Regression Diagnostics</title>
		<author>
			<persName><forename type="first">Daryl</forename><surname>Pregibon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Annals of Statistics</title>
		<imprint>
			<date type="published" when="1981">1981</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Daryl Pregibon. &quot;Logistic Regression Diagnostics&quot;. In: The Annals of Statistics. 1981.</note>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Language Models as Knowledge Bases?</title>
		<author>
			<persName><forename type="first">Fabio</forename><surname>Petroni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Rocktäschel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anton</forename><surname>Bakhtin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxiang</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Fabio Petroni, Tim Rocktäschel, Sebastian Riedel, Patrick Lewis, Anton Bakhtin, Yuxiang Wu, and Alexander Miller. &quot;Language Models as Knowledge Bases?&quot; In: Pro- ceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP). 2019.</note>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">High-resolution image synthesis with latent diffusion models</title>
		<author>
			<persName><forename type="first">Robin</forename><surname>Rombach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Blattmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dominik</forename><surname>Lorenz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Esser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Björn</forename><surname>Ommer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="10684" to="10695" />
		</imprint>
	</monogr>
	<note type="raw_reference">Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Björn Om- mer. &quot;High-resolution image synthesis with latent diffusion models&quot;. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2022, pp. 10684- 10695.</note>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">ImageNet Large Scale Visual Recognition Challenge</title>
		<author>
			<persName><forename type="first">Olga</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sanjeev</forename><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sean</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiheng</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrej</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision (IJCV</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, Alexander C. Berg, and Li Fei-Fei. &quot;ImageNet Large Scale Visual Recognition Challenge&quot;. In: International Journal of Computer Vision (IJCV). 2015.</note>
</biblStruct>

<biblStruct xml:id="b74">
	<monogr>
		<title level="m" type="main">Learning transferable visual models from natural language supervision</title>
		<author>
			<persName><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jong</forename><forename type="middle">Wook</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Hallacy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gabriel</forename><surname>Goh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sandhini</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Girish</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amanda</forename><surname>Askell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pamela</forename><surname>Mishkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jack</forename><surname>Clark</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.00020.2021</idno>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note type="raw_reference">Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, et al. &quot;Learning transferable visual models from natural language supervision&quot;. In: arXiv preprint arXiv:2103.00020. 2021.</note>
</biblStruct>

<biblStruct xml:id="b75">
	<monogr>
		<title level="m" type="main">A scalable estimate of the extra-sample prediction error via approximate leave-one-out</title>
		<author>
			<persName><forename type="first">Kamiar</forename><surname>Rahnama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rad</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Arian</forename><surname>Maleki</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1801.10243.2018</idno>
		<imprint/>
	</monogr>
	<note type="report_type">ArXiv preprint</note>
	<note type="raw_reference">Kamiar Rahnama Rad and Arian Maleki. &quot;A scalable estimate of the extra-sample prediction error via approximate leave-one-out&quot;. In: ArXiv preprint arXiv:1801.10243. 2018.</note>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Random features for large-scale kernel machines</title>
		<author>
			<persName><forename type="first">Ali</forename><surname>Rahimi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Recht</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Ali Rahimi and Benjamin Recht. &quot;Random features for large-scale kernel machines&quot;. In: Advances in neural information processing systems. 2007.</note>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer</title>
		<author>
			<persName><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katherine</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sharan</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Matena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanqi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><forename type="middle">J</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<publisher>JMLR</publisher>
		</imprint>
	</monogr>
	<note type="raw_reference">Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J. Liu. &quot;Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer&quot;. In: Journal of Machine Learning Research (JMLR) (2020).</note>
</biblStruct>

<biblStruct xml:id="b78">
	<monogr>
		<title level="m" type="main">Okapi at TREC-3</title>
		<author>
			<persName><forename type="first">Steve</forename><surname>Stephen E Robertson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Susan</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Micheline</forename><forename type="middle">M</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mike</forename><surname>Hancock-Beaulieu</surname></persName>
		</author>
		<author>
			<persName><surname>Gatford</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995">1995</date>
			<publisher>Nist Special Publication</publisher>
		</imprint>
	</monogr>
	<note type="raw_reference">Stephen E Robertson, Steve Walker, Susan Jones, Micheline M Hancock-Beaulieu, Mike Gatford, et al. &quot;Okapi at TREC-3&quot;. In: Nist Special Publication. 1995.</note>
</biblStruct>

<biblStruct xml:id="b79">
	<monogr>
		<title level="m" type="main">Is a caption worth a thousand images? a controlled study for representation learning</title>
		<author>
			<persName><forename type="first">Shibani</forename><surname>Santurkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yann</forename><surname>Dubois</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rohan</forename><surname>Taori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tatsunori</forename><surname>Hashimoto</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2207.07635.2022</idno>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note type="raw_reference">Shibani Santurkar, Yann Dubois, Rohan Taori, Percy Liang, and Tatsunori Hashimoto. &quot;Is a caption worth a thousand images? a controlled study for representation learning&quot;. In: arXiv preprint arXiv:2207.07635. 2022.</note>
</biblStruct>

<biblStruct xml:id="b80">
	<monogr>
		<title level="m" type="main">Empirical analysis of the hessian of over-parametrized neural networks</title>
		<author>
			<persName><forename type="first">Levent</forename><surname>Sagun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Utku</forename><surname>Evci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Ugur Güney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yann</forename><surname>Dauphin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Léon</forename><surname>Bottou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.04454.2017</idno>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note type="raw_reference">Levent Sagun, Utku Evci, V Ugur Güney, Yann Dauphin, and Léon Bottou. &quot;Empirical analysis of the hessian of over-parametrized neural networks&quot;. In: arXiv preprint arXiv:1706.04454. 2017.</note>
</biblStruct>

<biblStruct xml:id="b81">
	<monogr>
		<title level="m" type="main">Understanding Influence Functions and Datamodels via Harmonic Analysis</title>
		<author>
			<persName><forename type="first">Nikunj</forename><surname>Saunshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arushi</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Braverman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sanjeev</forename><surname>Arora</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
	<note type="raw_reference">Nikunj Saunshi, Arushi Gupta, Mark Braverman, and Sanjeev Arora. &quot;Understanding Influence Functions and Datamodels via Harmonic Analysis&quot;. In: ICLR. 2023.</note>
</biblStruct>

<biblStruct xml:id="b82">
	<monogr>
		<title level="m" type="main">Notes on the n-Person Game-II: The Value of an n-Person Game, The RAND Corporation, The RAND Corporation</title>
		<author>
			<persName><surname>Ls Shapley</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1951">1951</date>
		</imprint>
	</monogr>
	<note>Research Memorandum</note>
	<note type="raw_reference">LS Shapley. &quot;Notes on the n-Person Game-II: The Value of an n-Person Game, The RAND Corporation, The RAND Corporation&quot;. In: Research Memorandum. 1951.</note>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">The Proof and Measurement of Association between Two Things</title>
		<author>
			<persName><forename type="first">Charles</forename><surname>Spearman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The American Journal of Psychology</title>
		<imprint>
			<date type="published" when="1904">1904</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Charles Spearman. &quot;The Proof and Measurement of Association between Two Things&quot;. In: The American Journal of Psychology. 1904.</note>
</biblStruct>

<biblStruct xml:id="b84">
	<monogr>
		<title level="m" type="main">ModelDiff: A Framework for Comparing Learning Algorithms</title>
		<author>
			<persName><forename type="first">Harshay</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sung</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Min</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Ilyas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aleksander</forename><surname>Madry</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2211.12491.2022</idno>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note type="raw_reference">Harshay Shah, Sung Min Park, Andrew Ilyas, and Aleksander Madry. &quot;ModelDiff: A Framework for Comparing Learning Algorithms&quot;. In: arXiv preprint arXiv:2211.12491. 2022.</note>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Breeds: Benchmarks for subpopulation shift</title>
		<author>
			<persName><forename type="first">Shibani</forename><surname>Santurkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dimitris</forename><surname>Tsipras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aleksander</forename><surname>Madry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<publisher>ICLR</publisher>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Shibani Santurkar, Dimitris Tsipras, and Aleksander Madry. &quot;Breeds: Benchmarks for subpopulation shift&quot;. In: International Conference on Learning Representations (ICLR). 2021.</note>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">Scaling up influence functions</title>
		<author>
			<persName><forename type="first">Andrea</forename><surname>Schioppa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Polina</forename><surname>Zablotskaia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Vilar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Artem</forename><surname>Sokolov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="8179" to="8186" />
		</imprint>
	</monogr>
	<note type="raw_reference">Andrea Schioppa, Polina Zablotskaia, David Vilar, and Artem Sokolov. &quot;Scaling up influence functions&quot;. In: Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 36. 8. 2022, pp. 8179-8186.</note>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">Interactive label cleaning with example-based explanations</title>
		<author>
			<persName><forename type="first">Stefano</forename><surname>Teso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrea</forename><surname>Bontempelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fausto</forename><surname>Giunchiglia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrea</forename><surname>Passerini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Stefano Teso, Andrea Bontempelli, Fausto Giunchiglia, and Andrea Passerini. &quot;In- teractive label cleaning with example-based explanations&quot;. In: Advances in Neural Information Processing Systems. 2021.</note>
</biblStruct>

<biblStruct xml:id="b88">
	<monogr>
		<title level="m" type="main">Lamda: Language models for dialog applications</title>
		<author>
			<persName><forename type="first">Romal</forename><surname>Thoppilan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><forename type="middle">De</forename><surname>Freitas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jamie</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Apoorv</forename><surname>Kulshreshtha</surname></persName>
		</author>
		<author>
			<persName><surname>Heng-Tze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alicia</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Taylor</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leslie</forename><surname>Bos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName><surname>Du</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2201.08239.2022</idno>
		<imprint/>
	</monogr>
	<note type="report_type">ArXiv preprint</note>
	<note type="raw_reference">Romal Thoppilan, Daniel De Freitas, Jamie Hall, Noam Shazeer, Apoorv Kulshreshtha, Heng-Tze Cheng, Alicia Jin, Taylor Bos, Leslie Baker, Yu Du, et al. &quot;Lamda: Language models for dialog applications&quot;. In: ArXiv preprint arXiv:2201.08239. 2022.</note>
</biblStruct>

<biblStruct xml:id="b89">
	<analytic>
		<title level="a" type="main">Random projections for large-scale regression</title>
		<author>
			<persName><forename type="first">Gian-Andrea</forename><surname>Thanei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christina</forename><surname>Heinze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicolai</forename><surname>Meinshausen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Big and Complex Data Analysis: Methodologies and Applications</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Gian-Andrea Thanei, Christina Heinze, and Nicolai Meinshausen. &quot;Random projec- tions for large-scale regression&quot;. In: Big and Complex Data Analysis: Methodologies and Applications. 2017.</note>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">Attention is All you Need</title>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Łukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. &quot;Attention is All you Need&quot;. In: Advances in Neural Information Processing Systems (2017).</note>
</biblStruct>

<biblStruct xml:id="b91">
	<analytic>
		<title level="a" type="main">Influence sketching: Finding influential samples in large-scale regressions</title>
		<author>
			<persName><forename type="first">Mike</forename><surname>Wojnowicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>Cruz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuan</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brian</forename><surname>Wallace</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matt</forename><surname>Wolff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jay</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Caleb</forename><surname>Crable</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 IEEE International Conference on Big Data (Big Data)</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Mike Wojnowicz, Ben Cruz, Xuan Zhao, Brian Wallace, Matt Wolff, Jay Luan, and Caleb Crable. &quot;Influence sketching: Finding influential samples in large-scale regres- sions&quot;. In: 2016 IEEE International Conference on Big Data (Big Data). 2016.</note>
</biblStruct>

<biblStruct xml:id="b92">
	<analytic>
		<title level="a" type="main">More Than a Toy: Random Matrix Models Predict How Real-World Neural Representations Generalize</title>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Steinhardt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Alexander Wei, Wei Hu, and Jacob Steinhardt. &quot;More Than a Toy: Random Matrix Models Predict How Real-World Neural Representations Generalize&quot;. In: ICML. 2022.</note>
</biblStruct>

<biblStruct xml:id="b93">
	<analytic>
		<title level="a" type="main">Regularization matters: Generalization and optimization of neural nets vs their induced kernel</title>
		<author>
			<persName><forename type="first">Colin</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><forename type="middle">D</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tengyu</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Colin Wei, Jason D Lee, Qiang Liu, and Tengyu Ma. &quot;Regularization matters: Gen- eralization and optimization of neural nets vs their induced kernel&quot;. In: Advances in Neural Information Processing Systems. 2019.</note>
</biblStruct>

<biblStruct xml:id="b94">
	<monogr>
		<title level="m" type="main">GLUE: A multi-task benchmark and analysis platform for natural language understanding</title>
		<author>
			<persName><forename type="first">Alex</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amanpreet</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julian</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Felix</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><surname>Samuel R Bowman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1804.07461</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note type="raw_reference">Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and Samuel R Bowman. &quot;GLUE: A multi-task benchmark and analysis platform for natural language understanding&quot;. In: arXiv preprint arXiv:1804.07461 (2018).</note>
</biblStruct>

<biblStruct xml:id="b95">
	<analytic>
		<title level="a" type="main">mT5: A massively multilingual pre-trained text-to-text transformer</title>
		<author>
			<persName><forename type="first">Linting</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><surname>Constant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mihir</forename><surname>Kale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rami</forename><surname>Al-Rfou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Siddhant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Barua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics</title>
		<meeting>the 2021 Conference of the North American Chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Human Language Technologies</publisher>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Linting Xue, Noah Constant, Adam Roberts, Mihir Kale, Rami Al-Rfou, Aditya Sid- dhant, Aditya Barua, and Colin Raffel. &quot;mT5: A massively multilingual pre-trained text-to-text transformer&quot;. In: Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. 2021.</note>
</biblStruct>

<biblStruct xml:id="b96">
	<analytic>
		<title level="a" type="main">Representer Point Selection for Explaining Deep Neural Networks</title>
		<author>
			<persName><forename type="first">Chih-Kuan</forename><surname>Yeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joon Sik</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ian</forename><forename type="middle">E H</forename><surname>Yen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pradeep</forename><surname>Ravikumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Information Processing Systems</title>
		<imprint>
			<publisher>NeurIPS</publisher>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Chih-Kuan Yeh, Joon Sik Kim, Ian E. H. Yen, and Pradeep Ravikumar. &quot;Represen- ter Point Selection for Explaining Deep Neural Networks&quot;. In: Neural Information Processing Systems (NeurIPS). 2018.</note>
</biblStruct>

<biblStruct xml:id="b97">
	<analytic>
		<title level="a" type="main">Tensor Programs IIb: Architectural Universality Of Neural Tangent Kernel Training Dynamics</title>
		<author>
			<persName><forename type="first">Greg</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Etai</forename><surname>Littwin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 38th International Conference on Machine Learning</title>
		<meeting>the 38th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Greg Yang and Etai Littwin. &quot;Tensor Programs IIb: Architectural Universality Of Neural Tangent Kernel Training Dynamics&quot;. In: Proceedings of the 38th International Conference on Machine Learning. 2021.</note>
</biblStruct>

<biblStruct xml:id="b98">
	<monogr>
		<title level="m" type="main">TCT: Convexifying federated learning using bootstrapped neural tangent kernels</title>
		<author>
			<persName><forename type="first">Yaodong</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Praneeth</forename><surname>Sai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Karimireddy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">I</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><surname>Jordan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
			<publisher>NeurIPS</publisher>
		</imprint>
	</monogr>
	<note type="raw_reference">Yaodong Yu, Alexander Wei, Sai Praneeth Karimireddy, Yi Ma, and Michael I Jordan. &quot;TCT: Convexifying federated learning using bootstrapped neural tangent kernels&quot;. In: NeurIPS. 2022.</note>
</biblStruct>

<biblStruct xml:id="b99">
	<analytic>
		<title level="a" type="main">Holographic Feature Representations of Deep Networks</title>
		<author>
			<persName><forename type="first">Alex</forename><surname>Martin A Zinkevich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dale</forename><surname>Davies</surname></persName>
		</author>
		<author>
			<persName><surname>Schuurmans</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">UAI. 2017</title>
		<imprint/>
	</monogr>
	<note type="raw_reference">Martin A Zinkevich, Alex Davies, and Dale Schuurmans. &quot;Holographic Feature Representations of Deep Networks.&quot; In: UAI. 2017.</note>
</biblStruct>

<biblStruct xml:id="b100">
	<analytic>
		<title level="a" type="main">The unreasonable effectiveness of deep features as a perceptual metric</title>
		<author>
			<persName><forename type="first">Richard</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Phillip</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexei</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eli</forename><surname>Shechtman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oliver</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition</title>
		<imprint>
			<publisher>CVPR</publisher>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Richard Zhang, Phillip Isola, Alexei A Efros, Eli Shechtman, and Oliver Wang. &quot;The unreasonable effectiveness of deep features as a perceptual metric&quot;. In: Computer Vision and Pattern Recognition (CVPR). 2018.</note>
</biblStruct>

<biblStruct xml:id="b101">
	<analytic>
		<title level="a" type="main">Rethinking Influence Functions of Neural Networks in the Over-Parameterized Regime</title>
		<author>
			<persName><forename type="first">Rui</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shihua</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Rui Zhang and Shihua Zhang. &quot;Rethinking Influence Functions of Neural Networks in the Over-Parameterized Regime&quot;. In: Proceedings of the AAAI Conference on Artificial Intelligence. 2022.</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
